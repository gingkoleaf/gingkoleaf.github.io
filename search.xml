<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[linux文件系统]]></title>
    <url>%2F2023%2F01%2F14%2Fkernel%2Ffilesystem%2F</url>
    <content type="text"><![CDATA[内核版本 5.15 官方文档 Filesystems in the Linux kernel 概述VFS(Virtual File System / Virtual Filesystem Switch)是内核中对用户空间的程序提供文件系统接口的一个抽象的软件层，它对用户空间的程序屏蔽了不同的具体文件系统的实现差异。 VFS的系统调用都是在进程上下文中调用的。 源文件 包含的系统调用 fs/d_path.c getcwd fs/exec.c execve, execveat fs/fcntl.c fcntl fs/file.c dup fs/filesystems.c sysfs fs/ioctl.c ioctl fs/locks.c flock fs/namei.c mknod, mkdir, rmdir, unlink, link, syslink, rename fs/namespace.c mount, umount fs/open.c truncate, acess, chdir, chroot, chmod, open, create, close fs/pipe.c pipe fs/read_write.c lseek, read, write, fs/select.c select, poll fs/stat.c stat, fstat, lstat fs/sync.c sync fs/utimes.c utime, utimes, futimes, lutimes 关键全局变量 全局变量 所在文件 说明 struct list_head super_blocks fs/super.c 保存系统中所有的super_block struct file_system_type* file_systems fs/filesystem.c 保存了系统中所有的file_system_type信息 关键数据结构 数据结构 所在文件 struct super_block include/linux/fs.h struct dentry include/linux/dcache.h struct inode include/linux/fs.h strucr file include/linux/fs.h struct file_system_type include/linux/fs.h struct vfsmount include/linux/mount.h struct mount include/linux/mount.h 数据结构之间的关联关系(相同颜色表示指向同一个对象) super_block存储一个已挂载的文件系统的相关信息，实例在文件系统挂载的时候产生。 对于磁盘类文件系统，相关信息会持久化到磁盘中。superblock保存了一个文件系统的最基础的元信息，一般都保存在底层存储设备的开头；文件系统挂载之后会读取文件系统的superblock并常驻内存，部分字段是动态创建时设置的。 同一个文件系统可能会有多个super_block。 super_block存在于两个链表中,一个是系统所有super_block的链表（全局变量super_blocks）, 一个是对于特定的文件系统的super_block链表(file_system_type.fs_supers). 1234567891011121314151617181920212223242526272829303132333435363738394041424344struct super_block &#123; struct list_head s_list; /* Keep this first --- 挂在全局变量 struct list_head super_blocks链表上*/ dev_t s_dev; /* search index; _not_ kdev_t 对应的设备描述符 */ unsigned char s_blocksize_bits; /* 以位为单位的块的大小 */ unsigned long s_blocksize; /* 以字节为单位的块大小 */ loff_t s_maxbytes; /* 文件大小的上限 */ struct file_system_type *s_type; /* 文件系统类型 */ const struct super_operations *s_op; /* super_block的操作函数 */ const struct dquot_operations *dq_op; /* 磁盘限额方法 */ const struct quotactl_ops *s_qcop; /* 限额控制方法 */ const struct export_operations *s_export_op; /* 导出方法 */ unsigned long s_flags; /* 文件系统的mount标记 */ unsigned long s_magic; /* 文件系统的魔术字 */ struct dentry *s_root; /* 根目录的dentry */ struct hlist_bl_head s_roots; /* alternate root dentries for NFS */ struct list_head s_mounts; /* list of mounts; _not_ for fs use */ struct block_device *s_bdev; /* 相关的块设备 */ struct hlist_node s_instances; /* 挂在对应的文件系统结构体 file_system_type 的fs_supers链表 */ // 指向具体文件系统私有结构体，如 xfs_mount, ramfs_fs_info, ext4_sb_info, proc_fs_info等 void *s_fs_info; /* Filesystem private info */ const struct dentry_operations *s_d_op; /* default d_op for dentries */ /* * Owning user namespace and default context in which to * interpret filesystem uids, gids, quotas, device nodes, * xattrs and security labels. */ struct user_namespace *s_user_ns; /* * The list_lru structure is essentially just a pointer to a table * of per-node lru lists, each of which has its own spinlock. * There is no need to put them into separate cachelines. */ struct list_lru s_dentry_lru; // 未使用的dentry列表 struct list_lru s_inode_lru; // 未使用的inode列表 struct rcu_head rcu; struct work_struct destroy_work; struct list_head s_inodes; /* all inodes 所有的inode列表*/ struct list_head s_inodes_wb; /* writeback inodes 需要回写的inode列表*/&#125; __randomize_layout; dentry目录项（directory entry），保存了文件（目录）名称和具体的inode的对应关系，同时也实现目录与其包含的文件/目录之间的映射关系；引入dentry的概念主要是为了方便查找文件/目录，path中的每个目录和文件都有对应的dentry。 用来保存文件路径和inode之间的映射，从而支持在文件系统中移动。dentry 由 VFS 维护，所有文件系统共享，不和具体的进程关联。 dentry没有在磁盘等底层持久化存储设备上存储，是一个动态创建的内存数据结构，主要是为了构建出树状组织结构而设计，用来进行文件、目录的查找。 通过从文件系统根开始的目录项进行连接，所有的目录项会形成一个树状结构；查找时通过这个树状结构来找到对应的文件/目录。 虚拟文件系统维护了一个 DEntry Cache缓存（全局变量 struct hlist_bl_head *dentry_hashtable），用来保存最近使用的 dentry，加速查询操作。当调用open()函数打开一个文件时，内核会第一时间根据文件路径到 DEntry Cache里面寻找相应的dentry，找到了就直接构造一个struct file对象并返回。如果该文件不在缓存中，那么 VFS 会根据找到的最近目录一级一级地向下加载，直到找到相应的文件。期间 VFS 会缓存所有被加载生成的dentry。 1234567891011121314151617181920212223242526272829303132struct dentry &#123; /* RCU lookup touched fields */ unsigned int d_flags; /* protected by d_lock */ seqcount_spinlock_t d_seq; /* per dentry seqlock */ struct hlist_bl_node d_hash; /* lookup hash list */ struct dentry *d_parent; /* parent directory */ reserve struct qstr d_name; reserve struct inode *d_inode; /* Where the name belongs to - NULL is negative */ reserve unsigned char d_iname[DNAME_INLINE_LEN]; /* small names */ /* Ref lookup also touches following */ struct lockref d_lockref; /* per-dentry lock and refcount */ const struct dentry_operations *d_op; struct super_block *d_sb; /* The root of the dentry tree */ unsigned long d_time; /* used by d_revalidate */ void *d_fsdata; /* fs-specific data */ union &#123; struct list_head d_lru; /* LRU list */ wait_queue_head_t *d_wait; /* in-lookup ones only */ &#125;; struct list_head d_child; /* child of parent list 链到d_parent的d_subdirs链表中 */ reserve struct list_head d_subdirs; /* our children 当前dentry中的子dentry链表 */ reserve /* * d_alias and d_rcu can share memory */ union &#123; struct hlist_node d_alias; /* inode alias list */ struct hlist_bl_node d_in_lookup_hash; /* only for in-lookup ones */ struct rcu_head d_rcu; &#125; d_u;&#125; __randomize_layout; inode索引节点（index node）记录了文件或目录的属性信息。文件和inode是一一对应的。一个 inode可能被多个 dentry 所关联（通常是为文件建立硬连接）。 当创建一个文件时会对应的生成一个struct inode实例，并且该信息会持久化保存到磁盘中，由具体的文件系统进行组织。 当磁盘上的文件被访问时，才会由文件系统从磁盘上加载相应的数据并构造inode。虚拟文件系统维护了一个 Inode-cache缓存（全局变量 struct hlist_head *inode_hashtable），用来保存最近使用的inode，加速查询操作。 inode存在于两个双向链表, inode所在文件系统的 super_block 的 s_inodes 和 s_inodes_wb 链表中。 ls -li 命令结果的第一列就是文件的 inode 号 1234567baoze@baoze:~/workspace$ ls -litotal 12812441444216 drwxrwxr-x 2 baoze baoze 4096 Jan 14 04:28 c 524309 -rw-rw-r-- 1 baoze baoze 59243820 Jan 6 22:58 compile_commands.json 533495 drwxrwxr-x 28 baoze baoze 4096 Jan 7 00:26 linux-5.15.86 533494 -rw-rw-r-- 1 baoze baoze 195477769 Jan 5 15:40 linux-5.15.86.tar.gz 557446 -rw-rw-r-- 1 baoze baoze 1057254056 Jan 14 01:07 linux-image-unsigned-5.15.0-58-generic-dbgsym_5.15.0-58.64_amd64.ddeb 硬链接与软连接 硬链接： 指向原始文件 inode 的指针，系统不为它分配新的inode。我们每添加一个硬链接，该文件的 innode 连接数就会增加 1 ； 而且只有当该文件的 inode 连接数为 0 时，才算彻底被将它删除。因此即便删除原始文件，依然可以通过硬链接文件来访问。需要注意的是，我们不能跨分区对文件进行链接。软链接： 链接文件会生成新的inode。因此能链接目录，也能跨文件系统链接。但是，当删除原始文件后，链接文件也将失效。 inode的状态通常有三种 存在内存中，未关联到任何文件，也不处于活动使用状态; 存在内存中，正在由一个或多个进程使用，正在由一个或多个进程使用，通常表示一个文件。两个计数器（i_count和i_nlink）的值都必须大于0。文件内容和inode元数据都与底层块设备上的信息相同。也就是表示从上一次与介质同步依赖，该inode没有改变过; 处于活动使用状态。其数据内容已经改变，与存储介质上的内容不同。这种状态的inode被称作脏的。 1234567891011121314151617181920212223242526272829303132333435363738394041424344struct inode &#123; umode_t i_mode; //访问权限控制 unsigned int i_flags; //文件系统标志 const struct inode_operations *i_op; //指向索引结点操作结构体的指针 struct super_block *i_sb; //指向inode所属文件系统的超级块的指针 // 这个结构目的是缓存文件的内容，对文件的读写操作首先要在i_mapping包含的缓存里寻找文件的内容。 // 如果有缓存，对文件的读就可以直接从缓存中获得，而不用再去物理硬盘读取，从而大大加速了文件的读操作。 // 写操作也要首先访问缓存，写入到文件的缓存。然后等待合适的机会，再从缓存写入硬盘 struct address_space *i_mapping; //相关的地址映射 unsigned long i_ino; //索引结点号。通过ls -i命令可以查看文件的索引节点号 dev_t i_rdev; loff_t i_size; /* 以字节为单位的文件长度 */ struct timespec64 i_atime; //最后访问时间 struct timespec64 i_mtime; //最后修改时间 struct timespec64 i_ctime; //最后改变时间 blkcnt_t i_blocks; //文件的块数 struct hlist_node i_hash; struct list_head i_io_list; /* backing dev IO list */ struct list_head i_lru; /* inode LRU list */ struct list_head i_sb_list; /* 链接到 super_block 中的 inode 链表 */ struct list_head i_wb_list; /* backing dev writeback list */ union &#123; struct hlist_head i_dentry; struct rcu_head i_rcu; &#125;; union &#123; const struct file_operations *i_fop; /* former -&gt;i_op-&gt;default_file_ops */ void (*free_inode)(struct inode *); &#125;; struct address_space i_data; //设备地址映射 struct list_head i_devices; //块设备链表 union &#123; struct pipe_inode_info *i_pipe; struct cdev *i_cdev; char *i_link; unsigned i_dir_seq; &#125;; void *i_private; /* fs or device private pointer */&#125; __randomize_layout; filefile是内核中的数据结构，描述的是进程已经打开的文件，和进程是关联的。 因为一个文件可以被多个进程打开，所以一个文件可以存在多个文件对象，但多个文件对象其对应的索引节点和目录项对象肯定是唯一的。 每个进程都持有一个fd[]数组，数组里面存放的是指向file结构体的指针，同一进程的不同fd可以指向同一个file对象。 当应用程序调用open()函数的时候，VFS就会创建相应的file对象，打开文件的过程也就是对file结构体的初始化的过程。在打开文件的过程中会将inode部分关键信息填充到file中，特别是文件操作的函数指针。在task_struct中保存着一个file类型的数组，而用户态的文件描述符其实就是数组的下标。这样通过文件描述符就可以很容易到找到file，然后通过其中的函数指针访问数据。 123456789101112131415161718struct file &#123; # include/linux/fs.h // f_path.dentry 指向该file对应的dentry // f_path.mnt指向该file对应的vfsmount struct path f_path; struct inode *f_inode; /* cached value */ const struct file_operations *f_op; //指向文件操作表的指针 atomic_long_t f_count; //文件对象的使用计数 unsigned int f_flags; //打开文件时所指定的标志 fmode_t f_mode; //文件的访问模式 loff_t f_pos; //文件当前的位移量 u64 f_version; void *private_data; struct address_space *f_mapping; //页缓存映射&#125; filesystemfs/filesystem.c 文件中定义了全局变量 static struct file_system_type *file_systems，保存了系统中所有的file_system_type信息。 对file_systems全局变量list的遍历必须要通过 file_systems_lock 来进行保护 文件系统module卸载时，必须调用 unregister_filesystem()接口 访问list中的某一个成员时，可以在加锁（file_systems_lock）的代码段中进行，或者获取file_system_type-&gt;owner的引用计数。获取引用计数可以通过try_module_get()函数实现，该函数返回0表示获取失败。 如下面代码示例12345678910111213141516171819static int fs_name(unsigned int index, char __user * buf)&#123; struct file_system_type * tmp; int len, res; read_lock(&amp;file_systems_lock); # 加锁 for (tmp = file_systems; tmp; tmp = tmp-&gt;next, index--) if (index &lt;= 0 &amp;&amp; try_module_get(tmp-&gt;owner)) # 获取引用计数 break; read_unlock(&amp;file_systems_lock); # 解锁 if (!tmp) return -EINVAL; /* OK, we got the reference, so we can safely block */ len = strlen(tmp-&gt;name) + 1; res = copy_to_user(buf, tmp-&gt;name, len) ? -EFAULT : 0; put_filesystem(tmp); return res;&#125; file_system_type结构体 1234567891011struct file_system_type &#123; const char *name; // 文件系统名称 int fs_flags; int (*init_fs_context)(struct fs_context *); const struct fs_parameter_spec *parameters; struct dentry *(*mount) (struct file_system_type *, int, const char *, void *); void (*kill_sb) (struct super_block *); struct module *owner; struct file_system_type * next; /* 挂在全局变量 file_systems链表上 */ struct hlist_head fs_supers; /* 表示给定类型的已安装文件系统所对应的super_block链表的头 */&#125;; vfsmount123456struct vfsmount &#123; // include/linux/mount.h struct dentry *mnt_root; /* root of the mounted tree */ struct super_block *mnt_sb; /* pointer to superblock */ int mnt_flags; struct user_namespace *mnt_userns;&#125; mount1234567891011121314151617181920212223242526272829303132333435struct mount &#123; // fs/mount.h struct hlist_node mnt_hash; struct mount *mnt_parent; struct dentry *mnt_mountpoint; struct vfsmount mnt; union &#123; struct rcu_head mnt_rcu; struct llist_node mnt_llist; &#125;; struct list_head mnt_mounts; /* list of children, anchored here */ struct list_head mnt_child; /* and going through their mnt_child */ struct list_head mnt_instance; /* mount instance on sb-&gt;s_mounts */ const char *mnt_devname; /* Name of device e.g. /dev/dsk/hda1 */ struct list_head mnt_list; struct list_head mnt_expire; /* link in fs-specific expiry list */ struct list_head mnt_share; /* circular list of shared mounts */ struct list_head mnt_slave_list;/* list of slave mounts */ struct list_head mnt_slave; /* slave list entry */ struct mount *mnt_master; /* slave is on master-&gt;mnt_slave_list */ struct mnt_namespace *mnt_ns; /* containing namespace */ struct mountpoint *mnt_mp; /* where is it mounted */ union &#123; struct hlist_node mnt_mp_list; /* list mounts with the same mountpoint */ struct hlist_node mnt_umount; &#125;; struct list_head mnt_umounting; /* list entry for umount propagation */ int mnt_id; /* mount identifier */ int mnt_group_id; /* peer group identifier */ int mnt_expiry_mark; /* true if marked for expiry */ struct hlist_head mnt_pins; struct hlist_head mnt_stuck_children;&#125; mnt_namespace123456789101112131415161718struct mnt_namespace &#123; // fs/mount.h struct ns_common ns; struct mount * root; /* * Traversal and modification of .list is protected by either * - taking namespace_sem for write, OR * - taking namespace_sem for read AND taking .ns_lock. */ struct list_head list; spinlock_t ns_lock; struct user_namespace *user_ns; struct ucounts *ucounts; u64 seq; /* Sequence number to prevent loops */ wait_queue_head_t poll; u64 event; unsigned int mounts; /* # of mounts in the namespace */ unsigned int pending_mounts;&#125; mountpoint123456struct mountpoint &#123; // fs/mount.h struct hlist_node m_hash; struct dentry *m_dentry; struct hlist_head m_list; int m_count;&#125;; nameidata1234567891011121314151617181920212223struct nameidata &#123; struct path path; struct qstr last; struct path root; struct inode *inode; /* path.dentry.d_inode */ unsigned int flags, state; unsigned seq, m_seq, r_seq; int last_type; unsigned depth; int total_link_count; struct saved &#123; struct path link; struct delayed_call done; const char *name; unsigned seq; &#125; *stack, internal[EMBEDDED_LEVELS]; struct filename *name; struct nameidata *saved; unsigned root_seq; int dfd; kuid_t dir_uid; umode_t dir_mode;&#125; __randomize_layout; 初始化流程 全局变量 缓存池名称 对象 说明 dentry_hashtable Dentry Cache struct hlist_bl_head alloc_large_system_hash inode_hashtable Inode-cache struct hlist_head alloc_large_system_hash names_cachep names_cache 4K的char(path_name) slab dentry_cache dentry struct dentry slab inode_cache inode_cache struct inode slab filp_cachep filep struct file slab mnt_cache mnt_cache struct mount slab mount_hashtable Mount-cache struct hlist_head alloc_large_system_hash mountpoint_hashtable Mountpoint-cache struct hlist_head alloc_large_system_hash kernfs_node_cache kernfs_node_cache struct kernfs_node slab kernfs_iattrs_cache kernfs_iattrs_cache struct kernfs_iattrs slab shmem_inode_cachep shmem_inode_cache struct shmem_inode_info slab bdev_cachep bdev_cache struct bdev_inode slab 在dcache_init，inode_init同dcache_init_early， inode_init_early函数中分别创建struct entry 和 struct inode的slab cache和hash table在slab cache中保存数据，使用hash table为其建立索引表，典型的以空间换时间方式这里使用有early后缀和没有early后缀的函数是根据hash是否分布在NUMA上来选择hash table的创建时机是否推迟到vmalloc空间可以使用 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172start_kernel() |--- vfs_caches_init_early() # fs/dcache.c | |--- dcache_init_early() | | |--- # fs/dcache.c | | |--- # 全局变量 struct hlist_bl_head *dentry_hashtable 分配内存(alloc_large_system_hash) | | |--- # table name: Dentry cache, 对象 struct hlist_bl_head | |--- inode_init_early() | | |--- # fs/inode.c | | |--- # 全局变量 struct hlist_head *inode_hashtable 分配内存(alloc_large_system_hash) | | |--- # table name: Inode-cache, 对象 struct hlist_head |--- mm_init() # 内存初始化，kmem_cache_init |--- vfs_caches_init() | |--- # fs/dentry.c | |--- # 全局变量 struct kmem_cache *names_cachep 分配内存, slab name: names_cache, 对象 4K的char(path_name) | |--- dcache_init() | | |--- # fs/dcache.c | | |--- # 全局变量 struct kmem_cache *dentry_cache 分配内存, slab name: dentry, 对象 struct dentry | |--- inode_init() | | |--- # fs/inode.c | | |--- # 全局变量 struct kmem_cache *inode_cache 分配内存, slab name: inode_cache, 对象 struct inode | |--- files_init() | | |--- # fs/file_table.c | | |--- # 全局变量 struct kmem_cache *filp_cachep 分配内存, slab name: filp, 对象 struct file | | |--- # 全局变量 struct percpu_counter nr_files初始化 | |--- files_maxfiles_init() | | |--- # fs/file_table.c | | |--- # 全局变量 struct files_stat_struct files_stat.max_files 初始化 | |--- mnt_init() | | |--- # fs/namespace.c | | |--- # 全局变量 struct kmem_cache *mnt_cache 分配内存，slab name: mnt_cache, 对象 struct mount | | |--- # 全局变量 struct hlist_head *mount_hashtable 分配内存(alloc_large_system_hash), name: Mount-cache, 对象 struct hlist_head | | |--- # 全局变量 struct hlist_head *mountpoint_hashtable 分配内存(alloc_large_system_hash), name: Mountpoint-cache, 对象 struct hlist_head | | |--- kernfs_init() | | | |--- # fs/kernfs/mount.c | | | |--- # 全局变量 kernfs_node_cache 分配slab内存，name: kernfs_node_cache, 对象 struct kernfs_node | | | |--- # 全局变量 kernfs_iattrs_cache 分配slab内存，name: kernfs_iattrs_cache, 对象 struct kernfs_iattrs | | |--- sysfs_init() | | | |--- # fs/sysfs/mount.c | | | |--- kernfs_create_root() # 创建一个新的kernfs层次结构，返回值保存在全局变量 struct kernfs_root *sysfs_root | | | |--- # 全局变量 struct kernfs_node *sysfs_root_kn 初始化为 sysfs_root-&gt;kn | | | |--- register_filesystem(&amp;sysfs_fs_type) # 注册文件系统，名称 sysfs | | |--- kobject_create_and_add(&quot;fs&quot;, NULL) | | | |--- # lib/kobject.c | | | |--- # 创建一个结构kobject，并将其注册到sysfs中，呈现为fs目录，返回值保存在全局变量struct kobject *fs_kobj中 | | |--- shmem_init() | | | |--- # mm/shmem.c | | | |--- # 全局变量 shmem_inode_cachep 分配slab内存， name: shmem_inode_cache, 对象 struct shmem_inode_info | | | |--- register_filesystem(&amp;shmem_fs_type) | | | |--- kern_mount(&amp;shmem_fs_type) | | | | |--- # fs/namespace.c | | | | |--- # 返回值保存在全局变量 struct vfsmount *shm_mnt 中 | | |--- init_rootfs() | | | |--- # init/do_mounts.c | | | |--- # 根据条件设置全局变量 bool is_tmpfs的值是否为ture， 该变量在 rootfs_init_fs_context 中使用 | | |--- init_mount_tree() # 安装rootfs文件系统， 见下面单独展开 | |--- bdev_cache_init() | | |--- # block/bdev.c | | |--- # 全局变量 bdev_cachep 分配slab内存， name： bdev_cache， 对象 struct bdev_inode | | |--- register_filesystem(&amp;bd_type) | |--- chdev_init() # fs/char_dev.c 全局变量 struct kobj_map *cdev_map 分配内存（kmalloc）并初始化 |--- arch_call_rest_init() |--- rest_init() | |--- kernel_thread(kernel_init, NULL, CLONE_FS) | | |--- kernel_init_freeable() | | | |--- kernel_init_freeable() | | | | |--- do_basic_setup() | | | | | |--- driver_init() | | | | | |--- do_initcalls() | | | | | | |--- rootfs_initcall(populate_rootfs) | | | | | | | |--- do_populate_rootfs() | | | | | | | | |--- # init/initramfs.c unpack_to_rootfs 解压initrd到rootfs | | | |--- run_init_process(ramdisk_execute_command) # 执行rootfs中的 /init 程序 init_mount_tree()函数123456789101112131415161718192021222324252627282930313233static void __init init_mount_tree(void) # fs/namespace.c&#123; struct vfsmount *mnt; struct mount *m; struct mnt_namespace *ns; struct path root; # 挂在rootfs文件系统，期间会创建super_block mnt = vfs_kern_mount(&amp;rootfs_fs_type, 0, "rootfs", NULL); if (IS_ERR(mnt)) panic("Can't create rootfs"); # 创建namespace ns = alloc_mnt_ns(&amp;init_user_ns, false); if (IS_ERR(ns)) panic("Can't allocate initial namespace"); m = real_mount(mnt); m-&gt;mnt_ns = ns; ns-&gt;root = m; ns-&gt;mounts = 1; list_add(&amp;m-&gt;mnt_list, &amp;ns-&gt;list); init_task.nsproxy-&gt;mnt_ns = ns; get_mnt_ns(ns); root.mnt = mnt; root.dentry = mnt-&gt;mnt_root; mnt-&gt;mnt_flags |= MNT_LOCKED; # 将根目录和当前工作目录都设为rootfs文件系统根目录，即init_task进程可以看见整个内核根文件系统。 # init_task进程创建子进程时，其根目录和当前工作目录信息会传递给子进程。 set_fs_pwd(current-&gt;fs, &amp;root); # current-&gt;fs-&gt;pwd = root set_fs_root(current-&gt;fs, &amp;root); # current-&gt;fs-&gt;root = root&#125; vfs_kern_mount()的主要流程 创建fs_context -&gt; 创建super_block -&gt; 创建inode -&gt; 创建dentry -&gt; 创建vfs_mount/mount此时内核还不存在根文件系统，因此无法关联挂载点。实际上此时创建的rootfs文件系统根目录项，就是初始内核根文件系统的根目录项。此时rootfs文件系统的内容为空，内核在启动后期，初始化子系统时调用populate_rootfs()函数将initramfs中的内容解压至rootfs文件系统。 12345678910111213141516171819202122vfs_kern_mount(type: &amp;rootfs_fs_type, flags: 0, name: &quot;rootfs&quot;, data: NULL) |--- struct fs_context *fc; |--- struct vfsmount *mnt; |--- fc = fs_context_for_mount(rootfs_fs_type, 0); | |--- alloc_fs_context(rootfs_fs_type, reference: NULL, 0, 0, FS_CONTEXT_FOR_MOUNT); | | |--- fc-&gt;fs_type-&gt;init_fs_context(fc); //rootfs_init_fs_context | | | |--- ramfs_init_fs_context(fc); | | | | |--- fc-&gt;ops = &amp;ramfs_context_ops; |--- mnt = fc_mount(fc); | |--- vfs_get_tree(fc); | | |--- fc-&gt;ops-&gt;get_tree(fc); // ramfs_context_ops-&gt;get_tree -&gt; ramfs_get_tree | | | |--- ramfs_get_tree(fc); | | | | |--- get_tree_nodev(fc, ramfs_fill_super); | | | | | |--- vfs_get_super(fc, vfs_get_independent_super, fill_super); | | | | | | |--- struct super_block *sb = sget_fc(fc, test, set_anon_super_fc); | | | | | | | |--- # fs/super.c 根据fs_context 创建super_block | | | | | | |--- fill_super(sb, fc); -&gt; ramfs_fill_super(sb, fc); | | | | | | | |--- struct inode *inode = ramfs_get_inode() # fs/ramfs/inode 创建inode | |--- vfs_create_mount(fc); | | |--- struct mount *mnt = alloc_vfsmnt(fc-&gt;source ?: &quot;none&quot;); | | |--- return &amp;mnt-&gt;mnt; |--- return mnt; 123456789101112131415161718static const struct fs_context_operations ramfs_context_ops = &#123; # fs/ramfs/inode.c .free = ramfs_free_fc, .parse_param = ramfs_parse_param, .get_tree = ramfs_get_tree,&#125;;static int rootfs_init_fs_context(struct fs_context *fc) # init/do_mounts.c&#123; if (IS_ENABLED(CONFIG_TMPFS) &amp;&amp; is_tmpfs) return shmem_init_fs_context(fc); return ramfs_init_fs_context(fc);&#125;struct file_system_type rootfs_fs_type = &#123; # init/do_mounts.c .name = "rootfs", .init_fs_context = rootfs_init_fs_context, .kill_sb = kill_litter_super,&#125;; 系统日志中可以看到相关的初始化打印信息12345678910[ 0.123936] Dentry cache hash table entries: 1048576 (order: 11, 8388608 bytes, linear)[ 0.123936] Inode-cache hash table entries: 524288 (order: 10, 4194304 bytes, linear)[ 0.811286] Mount-cache hash table entries: 16384 (order: 5, 131072 bytes, linear)[ 0.815888] Mountpoint-cache hash table entries: 16384 (order: 5, 131072 bytes, linear)[ 1.150965] devtmpfs: initialized[ 10.327085] VFS: Disk quotas dquot_6.6.0[ 10.328635] VFS: Dquot-cache hash table entries: 512 (order 0, 4096 bytes)[ 11.294724] Trying to unpack rootfs image as initramfs...[ 15.765063] Freeing initrd memory: 104932K[ 16.347904] Run /init as init process 常用的文件系统ramfs基于内存的简易文件系统类型，是完全基于虚拟文件系统数据结构实例的文件系统，文件系统没有大小限制，文件内容不能交换至外部交换区 tmpfsramfs文件系统类型的增强版，对文件大小进行限制，文件内容可交换至交换区。需选择CONFIG_TMPFS配置选项，不仅可用于内核根文件系统，还可用于进程间通信的共享内存机制等 rootfs内核启动时的初始根文件系统类型，可以是ramfs或tmpfs其中之一。内核在以下条件同时都成立时选择tmpfs作为初始根文件系统类型，否则选用ramfs文件系统类型：（1）选择了CONFIG_TMPFS配置选项，支持tmpfs文件系统（2）命令行参数rootfstype=tmpfs或未定义（3）命令行参数root=未定义 该判断逻辑在 init_rootfs() 函数中命令行参数可以通过/proc/cmdline 或 /boot/grub/grub.cfg 文件中查看 initramfs保存初始根文件系统内容，它是一个.cpio类型的文件，链接内核时保存在内核镜像的初始化段中。内核在do_basic_setup()函数中，初始化子系统时调用populate_rootfs()函数（/init/initramfs.c）将initramfs的内容解压至根文件系统中。initramf具有默认的内容（/usr/），用户可通过配置选项指定编入其中的文件夹，编译内核时会将指文件夹的内容编译入initramfs内，目标文件格式为.cpio。使用initramfs传递根文件系统内容需要选择BLK_DEV_INITRD配置选项，并指定”initrd= xxx”。 procfssysfssysfs是一个基于内存的文件系统，它的作用是将内核信息以文件的方式提供给用户程序使用。sysfs 文件系统被挂载在 /sys 挂载点上。 devtmpfsxfsnfs进程与文件系统的关联每个进程有一个根目录和当前工作目录（由fs_struct结构体表示），这两个目录指向内核根文件系统中的一个目录。根目录是进程能看见内核根文件系统的起点，也就是说此目录以上的部分对进程不可见，进程只能看到此目录以下的部分。进程能看到的文件系统是内核根文件系统的一部分。当前工作目录，即在不指定的情况下，进程在当前工作目录下搜索、打开文件等。]]></content>
      <tags>
        <tag>kernel</tag>
        <tag>filesystem</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[crash]]></title>
    <url>%2F2023%2F01%2F14%2Fkernel%2Fcrash%2F</url>
    <content type="text"><![CDATA[ubuntu 版本: Ubuntu 22.04.1 LTS 5.15.0-58.64-generic 5.15.74 crash白皮书crash githubUbuntu安装Kernel-debuginfo配置安装源12345678910111213141516baoze@baoze:~/workspace$ cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/ddebs.listdeb http://ddebs.ubuntu.com $(lsb_release -cs) main restricted universe multiverse#deb http://ddebs.ubuntu.com $(lsb_release -cs)-security main restricted universe multiversedeb http://ddebs.ubuntu.com $(lsb_release -cs)-updates main restricted universe multiversedeb http://ddebs.ubuntu.com $(lsb_release -cs)-proposed main restricted universe multiverseEOFbaoze@baoze:~/workspace$ sudo apt update #### 更新时提示没有公钥无法验证签名，需要添加公钥信息......W: GPG error: http://ddebs.ubuntu.com jammy Release: The following signatures couldn&apos;t be verified because the public key is not available: NO_PUBKEY C8CAB6595FDFF622E: The repository &apos;http://ddebs.ubuntu.com jammy Release&apos; is not signed.N: Updating from such a repository can&apos;t be done securely, and is therefore disabled by default.N: See apt-secure(8) manpage for repository creation and user configuration details.......baoze@baoze:~/workspace$ sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C8CAB6595FDFF622baoze@baoze:~/workspace$ sudo apt updatebaoze@baoze:~/workspace$ sudo apt install linux-image-unsigned-$(uname -r)-dbgsym 直接下载安装到网站 http://ddebs.ubuntu.com/pool/main/l/linux/ 下载对应的debug-info包，然后进行安装，vmlinux默认安装在/usr/lib/debug/boot/vmlinux-5.15.0-58-generic 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253baoze@baoze:~/workspace$ wget http://ddebs.ubuntu.com/pool/main/l/linux/linux-image-unsigned-5.15.0-58-generic-dbgsym_5.15.0-58.64_amd64.ddebbaoze@baoze:~/workspace$ sudo dpkg -i linux-image-unsigned-5.15.0-58-generic-dbgsym_5.15.0-58.64_amd64.ddebbaoze@baoze:~/workspace$ sudo crash /usr/lib/debug/boot/vmlinux-5.15.0-58-generic crash 8.0.0Copyright (C) 2002-2021 Red Hat, Inc.Copyright (C) 2004, 2005, 2006, 2010 IBM CorporationCopyright (C) 1999-2006 Hewlett-Packard CoCopyright (C) 2005, 2006, 2011, 2012 Fujitsu LimitedCopyright (C) 2006, 2007 VA Linux Systems Japan K.K.Copyright (C) 2005, 2011, 2020-2021 NEC CorporationCopyright (C) 1999, 2002, 2007 Silicon Graphics, Inc.Copyright (C) 1999, 2000, 2001, 2002 Mission Critical Linux, Inc.Copyright (C) 2015, 2021 VMware, Inc.This program is free software, covered by the GNU General Public License,and you are welcome to change it and/or distribute copies of it undercertain conditions. Enter &quot;help copying&quot; to see the conditions.This program has absolutely no warranty. Enter &quot;help warranty&quot; for details. GNU gdb (GDB) 10.2Copyright (C) 2021 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Type &quot;show copying&quot; and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-pc-linux-gnu&quot;.Type &quot;show configuration&quot; for configuration details.Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type &quot;help&quot;.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;... KERNEL: /usr/lib/debug/boot/vmlinux-5.15.0-58-generic DUMPFILE: /proc/kcore CPUS: 2 DATE: Sat Jan 14 03:00:56 UTC 2023 UPTIME: 00:33:55LOAD AVERAGE: 0.77, 0.64, 0.56 TASKS: 441 NODENAME: baoze RELEASE: 5.15.0-58-generic VERSION: #64-Ubuntu SMP Thu Jan 5 11:43:13 UTC 2023 MACHINE: x86_64 (2399 Mhz) MEMORY: 8 GB PID: 3333 COMMAND: &quot;crash&quot; TASK: ffff9a01d1994b00 [THREAD_INFO: ffff9a01d1994b00] CPU: 1 STATE: TASK_RUNNING (ACTIVE)crash&gt; 安装crash12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152baoze@baoze:~/workspace$ sudo apt install crashbaoze@baoze:~/workspace$ sudo crash /usr/lib/debug/boot/vmlinux-5.15.0-58-generic crash 8.0.0Copyright (C) 2002-2021 Red Hat, Inc.Copyright (C) 2004, 2005, 2006, 2010 IBM CorporationCopyright (C) 1999-2006 Hewlett-Packard CoCopyright (C) 2005, 2006, 2011, 2012 Fujitsu LimitedCopyright (C) 2006, 2007 VA Linux Systems Japan K.K.Copyright (C) 2005, 2011, 2020-2021 NEC CorporationCopyright (C) 1999, 2002, 2007 Silicon Graphics, Inc.Copyright (C) 1999, 2000, 2001, 2002 Mission Critical Linux, Inc.Copyright (C) 2015, 2021 VMware, Inc.This program is free software, covered by the GNU General Public License,and you are welcome to change it and/or distribute copies of it undercertain conditions. Enter &quot;help copying&quot; to see the conditions.This program has absolutely no warranty. Enter &quot;help warranty&quot; for details. GNU gdb (GDB) 10.2Copyright (C) 2021 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Type &quot;show copying&quot; and &quot;show warranty&quot; for details.This GDB was configured as &quot;x86_64-pc-linux-gnu&quot;.Type &quot;show configuration&quot; for configuration details.Find the GDB manual and other documentation resources online at: &lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type &quot;help&quot;.Type &quot;apropos word&quot; to search for commands related to &quot;word&quot;... KERNEL: /usr/lib/debug/boot/vmlinux-5.15.0-58-generic DUMPFILE: /proc/kcore CPUS: 2 DATE: Sat Jan 14 03:00:56 UTC 2023 UPTIME: 00:33:55LOAD AVERAGE: 0.77, 0.64, 0.56 TASKS: 441 NODENAME: baoze RELEASE: 5.15.0-58-generic VERSION: #64-Ubuntu SMP Thu Jan 5 11:43:13 UTC 2023 MACHINE: x86_64 (2399 Mhz) MEMORY: 8 GB PID: 3333 COMMAND: &quot;crash&quot; TASK: ffff9a01d1994b00 [THREAD_INFO: ffff9a01d1994b00] CPU: 1 STATE: TASK_RUNNING (ACTIVE)crash&gt; crash常用调试命令 命令 说明 help 查看&lt;某个命令&gt;帮助信息 log 查看系统的日志 bt 查看堆栈信息 set 切换调试进程 struct task_struct ffff8b7df3cdae00 -x 把指定地址的内容以task_struct结构体解析打印，如果不带地址会显示结构体定义和大小 dis -r ffffffff9a6010ae dis命令进行返汇编，查看对应地址的代码逻辑 ps 查看所有进程信息 mod 查看当前加载的module，通过其他参数也可以加载对应的module files 查看打开的文件信息 p init_task 查看init_task变量的值 vm 查看虚拟内存 list 查看链表信息，可以遍历数据结构中的链表数据 list命令使用 list [[-o] offset][-e end][-[s|S] struct[.member[,member] [-l offset]] -[x|d]] [-r|-B] [-h [-O head_offset]|-H] start list命令解析链表的内容。内核中链表的方式通常有两种 包含next指针的单链表 使用struct list_head的双链表 -o参数： 结构体中执行next指针的偏移量（默认为0），通常可以采用struct.member来表示。-o可以省略输入-e参数： list的结束地址，通常情况下crash根据链表的规则自动结束-s参数： 需要输出的结构体中的成员，采用struct.member1,member2来表示，需要输出多个成员时，用,隔开。如果不输入该参数，则只打印地址信息。-S参数： 类似于-s，但不是解析gdb输出，而是直接从内存中读取成员值，因此该命令对于1-、2-、4-和8字节成员的工作速度要快得多-x参数： 将默认输出格式改为十六进制格式-d参数： 使用十进制格式覆盖默认输出格式-r参数： 对于一个链接到list_head结构的列表，使用“prev”指针而不是“next”，以相反的顺序遍历列表start参数： 第一个数据结构的地址。可以用十六进制的形式表示，也可以用表达式求值为一个地址，它取决于-h或-h选项是否在前面-h start参数： 包含嵌入list_head的数据结构的地址。-H start参数： list_head结构的地址，通常是外部独立的list_head()的地址。 示例一 全局变量struct file_system_type file_systems通过next指针来保存下一个文件系统的类型的数据 123struct file_system_type &#123; struct file_system_type * next;&#125; 12345678910111213crash&gt; p file_systemsfile_systems = $5 = (struct file_system_type *) 0xffffffffa3065620 &lt;sysfs_fs_type&gt;crash&gt; list file_system_type.next -s file_system_type.name,fs_flags 0xffffffffa3065620ffffffffa3065620 name = 0xffffffffa264a1c8 &quot;sysfs&quot;, fs_flags = 8,ffffffffa300b760 name = 0xffffffffa267e0ef &quot;tmpfs&quot;, fs_flags = 8200,ffffffffa30aebc0 name = 0xffffffffa260b14a &quot;bdev&quot;, fs_flags = 0,...... 示例二： 全局变量super_blocks是struct list_head类型，链表中保存的是struct super_block类型的数据。 123456static LIST_HEAD(super_blocks);struct super_block &#123; struct list_head s_list; struct file_system_type *s_type; ......&#125; 1234567891011crash&gt; p super_blockssuper_blocks = $7 = &#123; next = 0xffff9a01c004b800, prev = 0xffff9a01cbe74800&#125;crash&gt; list super_block.s_list -s super_block.s_type -H super_blocksffff9a01c004b800 s_type = 0xffffffffa300b760 &lt;shmem_fs_type&gt;,ffff9a01c004c000 s_type = 0xffffffffa2e1aea0 &lt;rootfs_fs_type&gt;,...... 示例三： struct super_block中有个成员 struct list_head s_mounts，该成员作为链表头，通过struct mount-&gt;mnt_instance成员挂了struct mount结构体。 12345678910111213crash&gt; list -o mount.mnt_instance -s mount.mnt_mp,mnt_mountpoint -O super_block.s_mounts -h 0xffff90ab00b06800ffff90ab001ff3c0 mnt_mp = 0x0, mnt_mountpoint = 0xffff90ab00440240,ffff90ab00b2cc80 mnt_mp = 0xffff90ab00b30d00, mnt_mountpoint = 0xffff90ab00440840,ffff90ab00b2c640 mnt_mp = 0xffff90ab01293640, mnt_mountpoint = 0xffff90ab1bb3e600,ffff90ab1ac48280 mnt_mp = 0xffff90ab01293640, mnt_mountpoint = 0xffff90ab1bb3e600,]]></content>
      <tags>
        <tag>kernel</tag>
        <tag>crash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ubuntu系统使用总结]]></title>
    <url>%2F2023%2F01%2F14%2Fubuntu%2Fubuntu%2F</url>
    <content type="text"><![CDATA[ubuntu 版本: Ubuntu 22.04.1 LTS 5.15.0-58.64-generic 5.15.74 官网wikicrash调试查看包内容ddeb包: dpkg-deb -c xxx.deb123456789101112131415baoze@baoze:~/workspace$ dpkg-deb -c ./linux-image-unsigned-5.15.0-58-generic-dbgsym_5.15.0-58.64_amd64.ddeb drwxr-xr-x root/root 0 2023-01-05 11:07 ./drwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/drwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/lib/drwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/lib/debug/drwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/lib/debug/boot/-rw-r--r-- root/root 737158008 2023-01-05 11:07 ./usr/lib/debug/boot/vmlinux-5.15.0-58-genericdrwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/lib/debug/lib/drwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/lib/debug/lib/modules/drwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/lib/debug/lib/modules/5.15.0-58-generic/drwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/lib/debug/lib/modules/5.15.0-58-generic/kernel/drwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/lib/debug/lib/modules/5.15.0-58-generic/kernel/arch/drwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/lib/debug/lib/modules/5.15.0-58-generic/kernel/arch/x86/drwxr-xr-x root/root 0 2023-01-05 11:07 ./usr/lib/debug/lib/modules/5.15.0-58-generic/kernel/arch/x86/crypto/-rw-r--r-- root/root 258513 2023-01-05 11:07 ./usr/lib/debug/lib/modules/5.15.0-58-generic/kernel/arch/x86/crypto/aegis128-aesni.ko 关闭自动更新修改 /etc/apt/apt.conf.d/10periodic 和 /etc/apt/apt.conf.d/20auto-upgrades 文件，将所有值修改为 0 1234567baoze@baoze:~$ cat /etc/apt/apt.conf.d/20auto-upgrades APT::Periodic::Update-Package-Lists &quot;1&quot;;APT::Periodic::Unattended-Upgrade &quot;1&quot;;baoze@baoze:~$ cat /etc/apt/apt.conf.d/10periodic APT::Periodic::Update-Package-Lists &quot;1&quot;;APT::Periodic::Download-Upgradeable-Packages &quot;0&quot;;APT::Periodic::AutocleanInterval &quot;0&quot;; 确认ubuntu使用的上游内核版本方法一：查看 /proc/verison_signature 文件12baoze@baoze:~$ cat /proc/version_signature Ubuntu 5.15.0-58.64-generic 5.15.74 第一个字段总是Ubuntu，第二个字段表示 Ubuntu kernel version，第三个字段表示 Ubuntu依赖的上游kernel主干版本 方法二：在ubuntu的kernel git中查看对应tag的Makefile文件https://git.launchpad.net/~ubuntu-kernel/ubuntu/+source/linux/+git/jammy/tree/Makefile?h=Ubuntu-5.15.0-58.64 123456# SPDX-License-Identifier: GPL-2.0VERSION = 5PATCHLEVEL = 15SUBLEVEL = 74EXTRAVERSION =NAME = Trick or Treat apt常用命令apt remove –auto-remove gcc-aarch64-linux-gnu 自动卸载gcc-aarch64-linux-gnu软件及依赖gcc-aarch64-linux-gnu的软件]]></content>
      <tags>
        <tag>总结</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kernel 进程初始化]]></title>
    <url>%2F2023%2F01%2F05%2Fkernel%2Fkernel-thread-init%2F</url>
    <content type="text"><![CDATA[内核版本： 5.15.86]]></content>
      <tags>
        <tag>kernel</tag>
        <tag>init</tag>
        <tag>processing</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[内核代码阅读与调试]]></title>
    <url>%2F2022%2F12%2F18%2Fkernel%2Fkernel-read-tool%2F</url>
    <content type="text"><![CDATA[环境: Ubuntu 22.04.1编译kernel版本: 5.15.86 官网资料clangd官网busybox官网qemu官网最新文档qemu 6.2.0文档代码阅读vscode + RemoteSSH插件/WSL插件 + clangd插件 + 编译数据库 编译数据库采用bear工具，在执行内核编译的make命令前添加bear命令即可（编译kernel前，先使用make menuconfig选择各种特性）。 注意clangd与vscode默认推荐的microsoft的c/c++插件C/C++ Extension Pack有冲突，如果有安装该插件，请先禁用。clangd依赖后台的clangd server，通常情况下vscode会自动提示下载。 clangd配置12345--compile-commands-dir=$&#123;workspaceFolder&#125;--background-index--completion-style=detailed--header-insertion=never-log=info qemu模拟内核启动安装交叉编译工具链apt install gcc-aarch64-linux-gnu (x86环境编译kernel的arm64版本需要) 在下面编译 busybox 和 kernel的 arm64版本时，在编译前要先配置ARCH和CROSS_COMPILE环境变量export ARCH=arm64export CROSS_COMPILE=aarch64-linux-gnu- busybox的编译busybox官网下载稳定版本，如https://busybox.net/downloads/busybox-1.33.2.tar.bz2 ，解压后执行 make menuconfig，并修改为编译静态文件 12Settings ---&gt; [*] Build BusyBox as a static binary (no shared libs) 然后执行make和make install命令，会在busybox根目录下生成 _install 目录，rootfs就是基于该目录制作。 x86_64的rootfs制作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152baoze@baoze:~/workspace/debug/busybox-1.33.2-x86$ dd if=/dev/zero of=rootfs.img bs=1M count=1010+0 records in10+0 records out10485760 bytes (10 MB, 10 MiB) copied, 0.00630844 s, 1.7 GB/sbaoze@baoze:~/workspace/debug/busybox-1.33.2-x86$ mkfs.ext4 rootfs.img mke2fs 1.46.5 (30-Dec-2021)Discarding device blocks: done Creating filesystem with 2560 4k blocks and 2560 inodesAllocating group tables: done Writing inode tables: done Creating journal (1024 blocks): doneWriting superblocks and filesystem accounting information: donebaoze@baoze:~/workspace/debug/busybox-1.33.2-x86$ mkdir fsbaoze@baoze:~/workspace/debug/busybox-1.33.2-x86$ sudo mount -o loop rootfs.img fsbaoze@baoze:~/workspace/debug/busybox-1.33.2-x86$ cd fsbaoze@baoze:~/workspace/debug/busybox-1.33.2-x86/fs$ sudo cp -rf ../_install/* . -rfbaoze@baoze:~/workspace/debug/busybox-1.33.2-x86/fs$ sudo mkdir proc dev etc home mntbaoze@baoze:~/workspace/debug/busybox-1.33.2-x86/fs$ sudo cp -r ../examples/bootfloppy/etc/* etc/baoze@baoze:~/workspace/debug/busybox-1.33.2-x86/fs$ cat etc/fstab proc /proc proc defaults 0 0baoze@baoze:~/workspace/debug/busybox-1.33.2-x86/fs$ cat etc/inittab ::sysinit:/etc/init.d/rcS::respawn:-/bin/shtty2::askfirst:-/bin/sh::ctrlaltdel:/bin/umount -a -rbaoze@baoze:~/workspace/debug/busybox-1.33.2-x86/fs$ cat etc/profile # /etc/profile: system-wide .profile file for the Bourne shellsechoecho -n &quot;Processing /etc/profile... &quot;# no-opecho &quot;Done&quot;echobaoze@baoze:~/workspace/debug/busybox-1.33.2-x86/fs$ cat etc/init.d/rcS #! /bin/sh/bin/mount -abaoze@baoze:~/workspace/debug/busybox-1.33.2-x86/fs$ sudo chmod 777 ./* -Rbaoze@baoze:~/workspace/debug/busybox-1.33.2-x86/fs$ cat &lt;&lt; EOF &gt; etc/profile#!/bin/shexport HOSTNAME=qemuexport USER=rootexport HOME=/rootexport PS1=&quot;[$USER@$HOSTNAME \W]# &quot;PATH=/bin:/sbin:/usr/bin:/usr/sbinLD_LIBRARY_PATH=/lib:/usr/lib:$LD_LIBRARY_PATHexport PATH LD_LIBRARY_PATHEOFbaoze@baoze:~/workspace/debug/busybox-1.33.2-x86/fs$ cd ..baoze@baoze:~/workspace/debug/busybox-1.33.2-x86$ sudo umount fs rootfs.imag就是x86的rootfs文件 arm64的rootfs制作在busybox的_install目录中，创建 etc dev lib 目录 创建etc/profile文件12345678#!/bin/shexport HOSTNAME=qemuexport USER=rootexport HOME=/rootexport PS1=&quot;[$USER@$HOSTNAME \W]# &quot;PATH=/bin:/sbin:/usr/bin:/usr/sbinLD_LIBRARY_PATH=/lib:/usr/lib:$LD_LIBRARY_PATHexport PATH LD_LIBRARY_PATH 创建etc/inittab文件1234::sysinit:/etc/init.d/rcS::respawn:-/bin/sh::askfirst:-/bin/sh::ctrlaltdel:/bin/umount -a -r 创建etc/fstab文件1234567#device mount-point type options dump fsck orderproc /proc proc defaults 0 0tmpfs /tmp tmpfs defaults 0 0sysfs /sys sysfs defaults 0 0tmpfs /dev tmpfs defaults 0 0debugfs /sys/kernel/debug debugfs defaults 0 0kmod_mount /mnt 9p trans=virtio 0 0 创建etc/init.d/rcS文件，并修改文件权限为777123456789mkdir -p /sysmkdir -p /tmpmkdir -p /procmkdir -p /mnt/bin/mount -amkdir -p /dev/ptsmount -t devpts devpts /dev/ptsecho /sbin/mdev &gt; /proc/sys/kernel/hotplugmdev -s 在dev目录下执行mknod console c 5 1命令 拷贝lib文件 cp -a /usr/aarch64-linux-gnu/lib/*.so* lib/ arm64的rootfs采用initramfs方式编译到内核文件中，剩余操作在内核时执行 x86_64内核编译拷贝ubuntu系统的config文件到内核根目录 cp /boot/config-5.15.0-58-generic .config 执行 make menuconfig 命令 1234567891011Processor type and features--&gt; [ ] Randomize the address of the kernel image (KASLR) Kernel hacking ---&gt; [*] Kernel debugging Compile-time checks and compiler options ---&gt; [*] Compile the kernel with debug info [*] Provide GDB scripts for kernel debugging-*- Cryptographic API ---&gt; Certificates for signature checking ---&gt; () Additional X.509 keys for default system keyrin () X.509 certificates to be preloaded into the system blacklist keyring 执行 make 命令 arm64内核编译通过make defconfig获取arm64的默认配置 执行make menuconfig修改编译配置123456789101112General setup ---&gt; [*] Initial RAM filesystem and RAM disk (initramfs/initrd) support (./root) Initramfs source file(s) (0) User ID to map to 0 (user root) (0) Group ID to map to 0 (group root)Kernel Features ---&gt; [ ] Randomize the address of the kernel imageKernel hacking ---&gt; [*] Kernel debugging Compile-time checks and compiler options ---&gt; [*] Compile the kernel with debug info [*] Provide GDB scripts for kernel debugging 在根目录创建root目录，将busybox中_install目录内容拷贝过来，然后执行make即可。 如果dev目录下的conole文件copy失败，需要在root下重新创建。 qemu启动内核 安装qemu，apt install qemu-system-arm qemu-system-x86_64，版本为6.2.0 qemu启动arm内核 qemu-system-aarch64 -m 2G -smp 1 -cpu cortex-a57 -machine virt --nographic -kernel arch/arm64/boot/Image -append &quot;rdinit=/linuxrc nokaslr console=ttyAMA0 loglevel=8&quot; qemu启动x86_64内核 qemu-system-x86_64 -m 2G -smp 1 -kernel arch/x86_64/boot/bzImage -hda ./rootfs.img -append &quot;root=/dev/sda console=ttyS0&quot; -nographic 内核调试安装多架构的gdb apt install gdb-multiarch qemu启动内核时调试qemu启动内核时，添加 -S 和 -s 参数 qemu-system-aarch64 -m 512M -smp 1 -cpu cortex-a57 -machine virt -kernel arch/arm64/boot/Image -append &quot;rdinit=/linuxrc nokaslr earlyprintk console=ttyAMA0 loglevel=8&quot; -nographic -S -s -s shorthand for -gdb tcp::1234-S freeze CPU at startup (use ‘c’ to start execution) 打开另外一个窗口1234baoze@baoze:~/workspace/kernel/linux-5.15.86-arm64$ gdb-multiarch -tui ./vmlinux(gdb)target remote localhost:1234(gbd)b start_kernel(gdb)c qemu正常启动内核后调试qemu根据命令（不带-S 和 -s）正常启动内核后，可以通过组合键 ctrl + a -&gt; c 进入qemu的monitor控制台，然后执行gdbserver命令 在另外一个窗口中执行gdb-multiarch命令，然后链接到qemu端就可以了，操作同前。 从monitor控制台切换回终端也是 ctrl + a -&gt; c组合键 vscode调试安装C/C++插件，在.vscode/launch.json中添加以下内容 123456789101112131415&#123; "version": "0.2.0", "configurations": [ &#123; "name": "kernel debug", "type": "cppdbg", "request": "launch", "program": "$&#123;workspaceFolder&#125;/vmlinux", "cwd": "$&#123;workspaceFolder&#125;", "MIMode": "gdb", "miDebuggerPath":"/usr/bin/gdb-multiarch", "miDebuggerServerAddress": "localhost:1234" &#125; ]&#125; 在vscode启动debug，打断点后，再执行qemu命令。 C/C++ 插件与clangd插件冲突，使用C/C++插件的时候要先将clangd插件禁用。 常见问题手动在远端服务器安装clangd服务下载最新的clangd软件，如clangd-linux-15.0.6.zip 在远端机器解压后，在vscode的clangd配置中，修改Clangd: Path到远端机器的解压目录，如/usr/local/clangd-15.0.6/bin/clangd。 arm64版本编译数据库不生效，clangd日志打印E[02:47:40.208] Failed to prepare a compiler instance: unknown target ABI &#39;lp64&#39;修改compile_commands.json文件，删除&quot;-mabi=lp64&quot;,行，然后reload window。 参考文章参考0参考1参考2]]></content>
      <tags>
        <tag>vscode</tag>
        <tag>kernel</tag>
        <tag>qemu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[获取linux系统限制]]></title>
    <url>%2F2022%2F09%2F13%2Fc%2Fsystem-limits%2F</url>
    <content type="text"><![CDATA[OS: Ubuntu 22.04.1gcc: 11.2.0glibc: 2.35 概述资源是有限的，所以在程序运行时，操作系统会对程序的很多行为都做了限制，可以把这些限制内容硬编码到程序中，但是很明显会影响程序的可移植性。因为在不同的场景下，某些限制的大小可能是不一样的。 系统限制类型可以分为以下两种： 编译时限制。例如，int类型的最大值取决于硬件和编译器的设计。这种限制通常都记录在头文件中（如&lt;limits.h&gt;）。 运行时限制。这类限制在程序运行时可能会变化，POSIX标准提供了sysconf()/pathconf()/fpathconf()三个函数来获取运行时限制。 在 shell 中，可以使用 getconf 命令获取特定 UNIX 系统中已然实现的限制和选项。参见man getconf 函数说明1234#include &lt;unistd.h&gt;long sysconf(int name);long pathconf(const char* pathname, int name);long fpathconf(int fd, int name); pathconf和fpathconf的区别: 前者以路径名为参数，后者以文件描述符为参数 三个函数中的name参数用于标识待查询的系统限制名称。sysconf函数中，name以_SC_开头，pathconf和fpathconf中name以_PC_开头 三个函数的返回值： 1) 如果name参数无效，函数返回-1，并把errno设置为EINVAL。 2) 如果返回-1，且不改变errno的值，表示该值是不确定的，因此在查询前最好先设置errno为0。 3) 返回&gt;=0的值为正常返回。 通常情况下，POSIX要求调用sysconf()获取的值在调用进程的生命周期内应保持不变（在linux系统中，有些合理的例外，如进程能够使用setrlimit来修改进程的资源限制）；POSIX没有要求pathconf和fpathconf在进程的生命周期内保持不变。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293$ cat -n 006_sys_limits.c #include &lt;unistd.h&gt;#include &lt;limits.h&gt;#include &quot;../util_err.h&quot;static void pr_sysconf(char* msg, int name) &#123; long val; fputs(msg, stdout); errno = 0; if ((val = sysconf(name)) &lt; 0) &#123; if (errno != 0)&#123; if (errno == EINVAL) &#123; fputs(&quot; (not supported)\n&quot;, stdout); &#125; else &#123; err_sys(&quot;sysconf error&quot;); &#125; &#125; else &#123; fputs(&quot; (no limit)\n&quot;, stdout); &#125; &#125; else &#123; printf(&quot; %ld\n&quot;, val); &#125;&#125;static void pr_pathconf(char* msg, char* path, int name) &#123; long val; fputs(msg, stdout); errno = 0; if ((val = pathconf(path, name)) &lt; 0) &#123; if (errno != 0)&#123; if (errno == EINVAL) &#123; fputs(&quot; (not supported)\n&quot;, stdout); &#125; else &#123; err_sys(&quot;pathconf error, path: %s&quot;, path); &#125; &#125; else &#123; fputs(&quot; (no limit)\n&quot;, stdout); &#125; &#125; else &#123; printf(&quot; %ld\n&quot;, val); &#125;&#125;void main() &#123; printf(&quot;_POSIX_ARG_MAX: %d\n&quot;, _POSIX_ARG_MAX); printf(&quot;_POSIX_OPEN_MAX: %d\n&quot;, _POSIX_OPEN_MAX); printf(&quot;_POSIX_CHILD_MAX: %d\n&quot;, _POSIX_CHILD_MAX); printf(&quot;-------\n&quot;); pr_sysconf(&quot;arg max:&quot;, _SC_ARG_MAX); pr_sysconf(&quot;open max:&quot;, _SC_OPEN_MAX); pr_sysconf(&quot;child max:&quot;, _SC_CHILD_MAX); pr_sysconf(&quot;pagesize:&quot;, _SC_PAGESIZE); pr_sysconf(&quot;clock ticks:&quot;, _SC_CLK_TCK); pr_sysconf(&quot;phy pages:&quot;, _SC_PHYS_PAGES); pr_sysconf(&quot;avphy pages:&quot;, _SC_AVPHYS_PAGES); pr_sysconf(&quot;processor conf:&quot;, _SC_NPROCESSORS_CONF); pr_sysconf(&quot;processor online:&quot;, _SC_NPROCESSORS_ONLN); printf(&quot;===========\n&quot;); pr_pathconf(&quot;name max:&quot;, &quot;.&quot;, _PC_NAME_MAX); pr_pathconf(&quot;path max:&quot;, &quot;.&quot;, _PC_PATH_MAX); pr_pathconf(&quot;pipe buff:&quot;, &quot;.&quot;, _PC_PIPE_BUF); printf(&quot;_POSIX_NAME_MAX: %d\n&quot;, _POSIX_NAME_MAX); printf(&quot;_POSIX_PATH_MAX: %d\n&quot;, _POSIX_PATH_MAX); printf(&quot;_POSIX_PIPE_BUF: %d\n&quot;, _POSIX_PIPE_BUF);&#125; $ gcc 006_sys_limits.c ../util_err.c $ ./a.out _POSIX_ARG_MAX: 4096_POSIX_OPEN_MAX: 20_POSIX_CHILD_MAX: 25-------arg max: 2097152open max: 1024child max: 15114pagesize: 4096clock ticks: 100phy pages: 995797avphy pages: 686847processor conf: 2processor online: 2===========name max: 255path max: 4096pipe buff: 4096_POSIX_NAME_MAX: 14_POSIX_PATH_MAX: 256_POSIX_PIPE_BUF: 512$ 运行时限制选项说明POSIX标准中，对于各选项定义了一个最小值，要求所有的实现都必须大于等于该值，这些宏定义通常以_POSIX_开头，通常包含在&lt;limits.h&gt;头文件中 限制名称 name参数 POSIX最小值 Ubuntu 22.04.1实际值 说明 ARG_MAX _SC_ARG_MAX _POSIX_ARG_MAX(4096) 2097152 exec函数中argv和环境变量environ的最大字节数 CHILD_MAX _SC_CHILD_MAX _POSIX_CHILD_MAX(25) 15114 每个real user ID下的最大进程数 OPEN_MAX _SC_OPEN_MAX _POSIX_OPEN_MAX(20) 1024 每个进程可以同时打开的文件描述符的数量 PAGESIZE _SC_PAGESIZE NA 4096 系统的页大小，单位byte 时钟每秒滴答数 _SC_CLK_TCK NA 100 _SC_NPROCESSORS_CONF NA 无参考意义 配置的处理器个数 _SC_NPROCESSORS_ONLN NA 无参考意义 当前可获得的处理器个数 _SC_PHYS_PAGES NA 无参考意义 物理内存总page数 _SC_AVPHYS_PAGES NA 无参考意义 当前可获得的物理内存page数 NAME_MAX _PC_NAME_MAX _POSIX_NAME_MAX(14) 255 针对目录有效，返回该目录下文件命名的最大长度，对于其他文件类型，则未作规定 PATH_MAX _PC_PATH_MAX _POSIX_PATH_MAX(256) 4096 针对目录有效，返回该目录中相对路径名的最大长度，对于其他文件类型，则未作规定 PIPE_BUF _PC_PIPE_BUF _POSIX_PIPE_BUF(512) 4096 针对目录、FIFO或管道有效，对于 FIFO 或者管道，返回一个应用于对应FIFO或管道的值。对于目录，返回的值应用于在该目录下创建的任一FIFO的限制值。对于其他文件类型，则未作规定 不确定的运行时限制]]></content>
      <tags>
        <tag>c</tag>
        <tag>sysconf</tag>
        <tag>pathconf</tag>
        <tag>fpathconf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言blog列表]]></title>
    <url>%2F2022%2F09%2F11%2Fc%2Fc%2F</url>
    <content type="text"><![CDATA[C语言标准gcc头文件搜索系统限制]]></content>
      <tags>
        <tag>总结</tag>
        <tag>c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gcc头文件搜索]]></title>
    <url>%2F2022%2F09%2F11%2Fc%2Fheader-search%2F</url>
    <content type="text"><![CDATA[OS: Ubuntu 22.04.1gcc: 11.2.0glibc: 2.35 #include “header.h” 与 #include &lt;header.h&gt; 区别#include “header.h” 引入的头文件，默认会首先在 .c 当前目录查找；而#include &lt;header.h&gt; 则不会。 1234567891011121314151617181920212223242526272829303132$ cat 004_header_search.c #include &lt;stdio.h&gt;#include &quot;my_header.h&quot;void main() &#123; printf(&quot;macro: %s\n&quot;, MY_TEST_MACRO_0911);&#125;$ cat my_header.h #ifndef __MY_HEADER__#define __MY_HEADER__#define MY_TEST_MACRO_0911 &quot;in current dir&quot;#endif //__MY_HEADER__$ gcc 004_header_search.c $ ./a.out macro: in current dir$ $ vim 004_header_search.c $ cat 004_header_search.c #include &lt;stdio.h&gt;#include &lt;my_header.h&gt;void main() &#123; printf(&quot;macro: %s\n&quot;, MY_TEST_MACRO_0911);&#125;$ gcc 004_header_search.c 004_header_search.c:2:10: fatal error: my_header.h: No such file or directory 2 | #include &lt;my_header.h&gt; | ^~~~~~~~~~~~~compilation terminated.$ 头文件搜索相关的command option 和环境变量 -I dir: 可以同时指定多个，优先级从左到右，可以使用.表示当前目录(-I. -I/special/include) -iquota dir: 只适用于以引号 “” 导入的头文件 -isystem dir -idirafter dir CPATH: 可以指定多个，优先级从左到右，冒号分割，适用于C/C++/objc语言；可以包含空的元素(:/special/include)表示当前目录 C_INCLUDE_PATH: 只适用于C语言 CPLUS_INCLUDE_PATH: 只适用于C++语言 OBJC_INCLUDE_PATH: 只适用于objc语言 查找顺序为： 对于用 #include “” 引号形式引入的头文件，首先搜索当前程序文件所在的目录，其次再前往 -iquote 选项指定的目录中查找； 搜索 -I 选项指定的目录 搜索 CPATH 环境变量指定的目录 搜索 -isystem 选项指定的目录 搜索C_INCLUDE_PATH/CPLUS_INCLUDE_PATH/OBJC_INCLUDE_PATH 环境变量指定的目录 搜索默认的系统路径； 1) /usr/lib/gcc/x86_64-linux-gnu/11/include 2) /usr/local/include/x86_64-linux-gnu 3) /usr/local/include 4) /usr/lib/gcc/x86_64-linux-gnu/11/include-fixed 5) /usr/x86_64-linux-gnu/include 6) /usr/include/x86_64-linux-gnu 7) /usr/include 搜索-idirafter 选项指定的目录。 如果默认的系统路径或-isystem指定的路径，也被指定在了-I的参数中时，-I里面的不生效。 gcc编译命令查看头文件查找顺序gcc 命令的-v参数可以显示编译过程中的调用的程序以及相关的日志信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253$ cat 004_header_search.c #include &lt;stdio.h&gt;#include &quot;my_header.h&quot;void main() &#123; printf(&quot;macro: %s\n&quot;, MY_TEST_MACRO_0911);&#125;$ ls include |xargs -I dir -t cat include/dir/my_header.h |grep -i macrocat include/c_include_path/my_header.h#define MY_TEST_MACRO_0911 &quot;in c_include_path dir&quot;cat include/c_path/my_header.h#define MY_TEST_MACRO_0911 &quot;in c_path dir&quot;cat include/cplus_include_path/my_header.h#define MY_TEST_MACRO_0911 &quot;in cplus_include_path dir&quot;cat include/dirafter/my_header.h#define MY_TEST_MACRO_0911 &quot;in dirafter dir&quot;cat include/include_1/my_header.h#define MY_TEST_MACRO_0911 &quot;in -I dir1&quot;cat include/include_2/my_header.h#define MY_TEST_MACRO_0911 &quot;in -I dir2&quot;cat include/objc_include_path/my_header.h#define MY_TEST_MACRO_0911 &quot;in objc_include_path dir&quot;cat include/quote/my_header.h#define MY_TEST_MACRO_0911 &quot;in quote dir&quot;cat include/system/my_header.h#define MY_TEST_MACRO_0911 &quot;in system dir&quot;$ $ CPATH=./include/c_path/ C_INCLUDE_PATH=./include/c_include_path/ CPLUS_INCLUDE_PATH=./include/cplus_include_path/ OBJC_INCLUDE_PATH=./include/objc_include_path/ gcc 004_header_search.c -I ./include/include_1/ -I ./include/include_2/ -iquote ./include/quote/ -isystem ./include/system/ -idirafter ./include/dirafter/ -v......#include &quot;...&quot; search starts here: ./include/quote/#include &lt;...&gt; search starts here: ./include/include_1/ ./include/include_2/ ./include/c_path/ ./include/system/ ./include/c_include_path/ /usr/lib/gcc/x86_64-linux-gnu/11/include /usr/local/include/x86_64-linux-gnu /usr/local/include /usr/lib/gcc/x86_64-linux-gnu/11/include-fixed /usr/x86_64-linux-gnu/include /usr/include/x86_64-linux-gnu /usr/include ./include/dirafter/End of search list.......$ $ CPATH=./include/c_path/ gcc 004_header_search.c -I ./include/system/ -isystem ./include/system/$ ./a.out macro: in c_path dir$]]></content>
      <tags>
        <tag>c</tag>
        <tag>gcc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux内核总结]]></title>
    <url>%2F2022%2F09%2F11%2Fkernel%2Fkernel%2F</url>
    <content type="text"><![CDATA[kernel官网Linux Kernel MapThe Linux Kernel Documentation(latest))The Linux Kernel Documentation(v5.15)kernel代码阅读工具crash调试文件系统总结]]></content>
      <tags>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[glibc的版本确认]]></title>
    <url>%2F2022%2F09%2F11%2FGNU%2Fglibc-version%2F</url>
    <content type="text"><![CDATA[运行环境为 Ubuntu 22.04 查看系统中安装的libc的软件包12$ dpkg -l |grep -i libc-binii libc-bin 2.35-0ubuntu3.1 amd64 GNU C Library: Binaries 采用gnu的接口查询 可以通过man gnu_get_libc_version查看接口的详细信息 12345678910111213$ cat 003_glibc_verison.c -n 1 #include &lt;stdio.h&gt; 2 #include &lt;gnu/libc-version.h&gt; 3 4 void main() &#123; 5 printf(&quot;GNU C library version: %s\n&quot;, gnu_get_libc_version()); 6 printf(&quot;GNU C library release: %s\n&quot;, gnu_get_libc_release()); 7 &#125;$ gcc 003_glibc_verison.c $ ./a.out GNU C library version: 2.35GNU C library release: stable$ ldd命令1234567$ ldd --versionldd (Ubuntu GLIBC 2.35-0ubuntu3.1) 2.35Copyright (C) 2022 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.Written by Roland McGrath and Ulrich Drepper.$ 执行libc.so libc.so是可以直接运行的，如果不能运行，chmod +x添加下执行权限ldd 一个当前系统中 C 库编写的动态可执行程序，可以查找到使用的libc.so的位置 12345678910111213$ ldd `which top`|grep -i libc.so libc.so.6 =&gt; /lib/x86_64-linux-gnu/libc.so.6 (0x00007f3a024b2000)$ /lib/x86_64-linux-gnu/libc.so.6 GNU C Library (Ubuntu GLIBC 2.35-0ubuntu3.1) stable release version 2.35.Copyright (C) 2022 Free Software Foundation, Inc.This is free software; see the source for copying conditions.There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR APARTICULAR PURPOSE.Compiled by GNU CC version 11.2.0.libc ABIs: UNIQUE IFUNC ABSOLUTEFor bug reporting instructions, please see:&lt;https://bugs.launchpad.net/ubuntu/+source/glibc/+bugs&gt;.$]]></content>
      <tags>
        <tag>glibc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[glibc总结]]></title>
    <url>%2F2022%2F09%2F11%2FGNU%2Fglibc%2F</url>
    <content type="text"><![CDATA[glibc官网glibc版本确认]]></content>
      <tags>
        <tag>总结</tag>
        <tag>glibc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言标准]]></title>
    <url>%2F2022%2F09%2F10%2Fc%2Fstandard%2F</url>
    <content type="text"><![CDATA[ISO: International Organization for Standardization，国际化标准组织IEC: International Electrotechnical Commission，国际电子技术委员会ANSI: American National Standards Institute，美国国家标准学会。ANSI是ISO中代表美国的成员。IEEE: Institute of Electrical and Electronics Engineers，电子和电气工程师学会。POSIX: Portable Operating System Interface，可移植操作系统接口。SUS: Single UNIX Specification，单一UNIX规范。 ISO C标准概述ISO C标准现在由ISO/IEC的C程序设计语言国际标准工作组维护和开发，该工作组称为ISO/IEC JTC1/SC22/WG14，简称WG14，WG14项目官网。 ISO C标准的目的是为了保证C程序的可移植性，使其可以运行在大量不同的操作系统（Unix/linux/windows等） ISO C标准定义了C程序设计语言的语法、语义和标准库（见标准第7章）和相关的约束限制。其只定义了C标准函数库的函数原型、函数功能，而并未定义函数的具体实现。标准库的实现由其他组织实现，如GNU C Library(glibc，当然glibc还包含了除ISO C标准库之外的自己的扩展内容)。 演进历史 ANSI X3.159-1989 (C89/ANSI C)：1983年ANSI成立了一个X3J11委员会，来创立C语言的标准，因为这个标准在1989年发布，所以也简称C89标准。有些人也把C89成为 ANSI C。 ISO/IEC 9899:1990 Programming languages — C (C90)：1990年，ISO采纳了ANSI的C89标准，然后做了一些修改再发布，就变成ISO的C90标准了，因此，C89和C90通常指同一个标准。 ISO/IEC 9899:1999 Programming languages — C (C99) ISO/IEC 9899:2011 Information technology — Programming languages — C (C11)：C11相对于C99的修改，参见标准文档的前言部分，他人总结 ISO/IEC 9899:2018 Information technology — Programming languages — C (C17/C18)：C17只是解决了针对C11报告的许多缺陷，还包含TC（技术勘误 ISO/IEC 9899:2011/Cor 1:2012），并未引入新的语言功能。 查看和指定使用的C标准(gcc)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859$ cat 002_standard.c -n 1 #include &lt;stdio.h&gt; 2 3 void main() &#123; 4 printf(&quot;C standard: %ld\n&quot;, __STDC_VERSION__); 5 &#125;$ gcc 002_standard.c $ ./a.out C standard: 201710$ gcc --versiongcc (Ubuntu 11.2.0-19ubuntu1) 11.2.0Copyright (C) 2021 Free Software Foundation, Inc.This is free software; see the source for copying conditions. There is NOwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.$ gcc -std=c11 002_standard.c $ ./a.out C standard: 201112$ gcc -std=gnu11 002_standard.c $ ./a.out C standard: 201112$ gcc -std=c99 002_standard.c $ ./a.out C standard: 199901$ gcc -std=c89 002_standard.c // __STDC_VERSION__是在 ISO/IEC 9899/AMD1:1995 中才引入的002_standard.c: In function ‘main’:002_standard.c:4:33: error: ‘__STDC_VERSION__’ undeclared (first use in this function) 4 | printf(&quot;C standard: %ld\n&quot;, __STDC_VERSION__); | ^~~~~~~~~~~~~~~~002_standard.c:4:33: note: each undeclared identifier is reported only once for each function it appears in// 查看gcc默认的标准$ gcc -E -dM - &lt;/dev/null |grep -i std|sort#define __GNUC_STDC_INLINE__ 1#define __STDC__ 1#define __STDC_HOSTED__ 1#define __STDC_IEC_559__ 1#define __STDC_IEC_559_COMPLEX__ 1#define __STDC_IEC_60559_BFP__ 201404L#define __STDC_IEC_60559_COMPLEX__ 201404L#define __STDC_ISO_10646__ 201706L#define _STDC_PREDEF_H 1#define __STDC_UTF_16__ 1#define __STDC_UTF_32__ 1#define __STDC_VERSION__ 201710L$ gcc -std=c11 -E -dM - &lt;/dev/null |grep -i std|sort#define __GNUC_STDC_INLINE__ 1#define __STDC__ 1#define __STDC_HOSTED__ 1#define __STDC_IEC_559__ 1#define __STDC_IEC_559_COMPLEX__ 1#define __STDC_IEC_60559_BFP__ 201404L#define __STDC_IEC_60559_COMPLEX__ 201404L#define __STDC_ISO_10646__ 201706L#define _STDC_PREDEF_H 1#define __STDC_UTF_16__ 1#define __STDC_UTF_32__ 1#define __STDC_VERSION__ 201112L ISO C标准头文件 序号 头文件 C99 C11 备注 1 &lt;assert.h&gt; Y Y 程序断言 2 &lt;complex.h&gt; Y Y 复数运算 3 &lt;ctype.h&gt; Y Y 字符分类（如isalpha）和映射功能（如toupper） 4 &lt;errno.h&gt; Y Y 错误码 5 &lt;fenv.h&gt; Y Y 浮点环境 6 &lt;float.h&gt; Y Y 浮点常量以及特性 7 &lt;inttypes.h&gt; Y Y 包含并扩展了stdint.h 8 &lt;iso646.h&gt; Y Y 逻辑和位操作运算符的宏形式（如and/xor) 9 &lt;limits.h&gt; Y Y 整数类型的极限值（如INT_MAX/INT_MIN) 10 &lt;locale.h&gt; Y Y 本地化相关（如LC_TIME/setlocale()) 11 &lt;math.h&gt; Y Y 浮点实数的数学函数、相关宏和类型 12 &lt;setjmp.h&gt; Y Y 非局部性的goto跳转（setjmp()/longjmp()） 13 &lt;signal.h&gt; Y Y 信号 14 &lt;stdarg.h&gt; Y Y 可变参数 15 &lt;stdbool.h&gt; Y Y bool类型(bool/true/false宏) 16 &lt;stddef.h&gt; Y Y 类型（ptrdiff_t/size_t/wchar_t）和宏（NULL/offsetof） 17 &lt;stdint.h&gt; Y Y 特定位长的整数类型 18 &lt;stdio.h&gt; Y Y 标准输入输出(I/O)库 19 &lt;stdlib.h&gt; Y Y 实用程序库函数 20 &lt;string.h&gt; Y Y 字符串相关函数 21 &lt;tgmath.h&gt; Y Y 包含math.h和complex.h，并且定义类型特定的宏 22 &lt;time.h&gt; Y Y 时间和日期 23 &lt;wchar.h&gt; Y Y 扩充的多字节和宽字符支持 24 &lt;wctype.h&gt; Y Y 宽字符分类与转换 25 &lt;stdalign.h&gt; N Y 结构体对其相关功能 26 &lt;stdatomic.h&gt; N Y 多线程中公共享数据的原子操作 27 &lt;stdnoreturn.h&gt; N Y 定义宏noreturn 28 &lt;threads.h&gt; N Y 多线程支持 29 &lt;uchar.h&gt; N Y 处理unicode字符 POSIX.1 标准概述POSIX是由IEEE制订的标准族。最初POSIX指的只是IEEE标准1003.1-1988（操作系统接口），后来则扩展成包括很多标记为1003的标准及标准草案，如shell和实用程序（1003.2）。其正式称呼为 IEEE 1003，而国际标准名称为 ISO/IEC 9945。 这些标准涵盖了很多方面，比如Unix系统调用的C语言接口、shell程序和工具、线程及网络编程。 这些标准的制定目的是为了提升应用程序在不同UNIX系统环境之间的可移植性。他是ISO C的超集。同样的，POSIX也只是定义接口，而不定义具体的实现。 POSIX标准族中的1003.1也被称为POSIX.1标准。 POSIX.2标准（ISO/IEC 9945-2:1993）主要是对shell和包括C编译器命令行接口在内的各种Unix工具进行了标准化。 演进 X/Open 公司是由多家国际计算机厂商所组成的联盟，他们的目的是为了制定出一套全面而又一致的开放系统标准。1993年，该公司获得Unix的商标权。 OSF: Open System Software Foundation，开放系统软件基金会。OSF是20世纪80年代末UNIX纷争期间成立的两家厂商联盟之一。OSF的主要成员包括 Digital、 IBM、 HP、 Apollo、 Bull、 Nixdorf 和 Siemens。 OSF 成立的主要目的是为了应对由 AT&amp;T（ UNIX 的发明者）和 SUN 公司（ UNIX 工作站市场的领跑者）结盟所带来的威胁。 1996年，X/Open和OSF合并成立 The Open Group。 1999年，出于修订并加强POSIX标准和SUS规范的目的，IEEE、Open Group以及 ISO/IEC联合技术委员会共同成立了austin公共标准修订工作组(Common Standards Revision Group, CSRG)，现在POSIX标准仍由austin Group维护。 POSIX.1 IEEE std 1003.1-1988: POSIX.1的第一个版本 ISO/IEC 9945-1:1990|IEEE std 1003.1-1990: 1990年 IEEE std 1003.1-1988被采纳为ISO标准 IEEE std 1003.1-1996|ISO/IEC 9945-1:1996: 包含内容见下面列表 IEEE std 1003.1-1990 IEEE std 1003.1b-1993（对基本POSIX标准的实时性扩展） IEEE std 1003.1c-1995（pthreads） IEEE std 1003.1i-1995（实时技术勘误表） IEEE std 1003.1-2001: 包含的内容很多，见下面列表 IEEE std 1003.1-1996 IEEE P1003.1a草案（系统接口修正） IEEE std 1003.1d-1999（高级实时扩展） IEEE std 1003.1j-2000（更多高级实时扩展） IEEE std 1003.1q-2000（事件跟踪方面的扩展） 部分IEEE std 1003.1g-2000（协议无关接口） ISO/IEC 9945-2:1993：即IEEE std 1003.2-1993（POSIX.2） IEEE P1003.2b草案（shell及实用程序的修正） IEEE std 1003.2d-1994（批处理扩展） SUSv2：包括系统接口定义（第五版）、命令和实用程序（第五版）、系统接口和头文件（第五版） Open Group 技术标准，网络服务，5.2发行版 ISO/IEC 9899:1999（C99） IEEE std 1003.1-2008|ISO/ICE 9945:2009：该标准基于下面几个标准 IEEE std 1003.1-2004 Open Group技术标准，2006，扩展API集，第1~4部分 ISO/IEC 9899:1999 XPG &amp; SUS X/Open公司编纂的 《X/Open Portability Guide》（XPG，X/Open 可移植性指南）是一套基于POSIX 标准的可移植性指导丛书。XPG是X/Open公司的出版物 SUS是Open Group公司的出版物。SUS 是POSIX.1标准的一个超集，POSIX.1相当于SUS中的基础规范部分。XSI: X/Open System Interface, X/Open系统接口。POSIX.1中的XSI选项描述了可选的接口，也定义了遵循XSI的实现必须支持POSIX.1的哪些可选部分。只有遵循XSI的实现才能称为UNIX系统。 XPG3: X/Open于1989年发布首个重要版本，是基于IEEE std 1003.1:1988。 XPG4：X/Open于1992年发布，基于IEEE std 1003.1:1990 和 IEEE std 1003.2:1992 XPG4v2|SUSv1|UNIX95: X/Open于1994年发布，因为它大约包含了1170个接口，因此也被称为 “Spec 1170”，主要内容包括： X/Open 通用应用环境（Common Application Environment， CAE）第四发行版（前身就是XPG4） System V接口定义（System V Interface Definition，SVID）第三版Level 1接口 OSF应用环境规范（Application Environment Specification， AES）Full Use接口 SUSv2|UNIX98: Open Group于1997年发布 SUSv3: Open Group于2001年发布，基本规范与IEEE std 1003.1-2001相同，除此之外还包括X/Open Curses第4发行版第2版。SUSv3 规范可在线获得，网址是 http://www.unix.org/version3/online.html。通过 SUSv3 认证的 UNIX 实现可被称为 UNIX 03。它的基本规范约有3700页，包含以下4个部分： 基本定义（XBD），包含了定义、术语、概念以及对头文件内容的规范。总计提供了84个头文件的规范。 系统接口（XSH），首先介绍了各种有用的背景信息。主要内容包含对各种函数（在特定的 UNIX 实现中，这些函数要么是作为系统调用，要么是作为库函数来实现的）的定义。总计包括了 1123 个系统接口。 Shell 和实用工具（XCU），明确定义了 shell 和各种 UNIX 命令的行为。总共定义了160 个实用工具的行为。 基本原理（XRAT），包括了与前三部分有关的描述性文字和原理说明 SUSv4：Open Group与2008年发布，较之于之先前版本，该标准包含了基本规范以及 XSI 扩展。 SUS(和XPG)标准顺应了相应的POSIX标准，并被组织为POSIX的超集。除了对许多额外的接口作出规范外，SUS标准还将很多被POSIX视为可选的接口和行为规范作为了必选项。 POSIX.1-2001定义了两种规范符合度： POSIX规范符合度 XSI规范符合度。对 UNIX 实现来说，要想完全符合 XSI 规范，除了必须满足 POSIX 规范的所有规定之外，还要提供若干POSIX 规范中的可选接口和行为。只有这一规范符合度达标，才能从 OPEN GROUP获得 UNIX03 称号 各种标准之间的关系 实线表示标准间的直接过渡，虚线则表示标准间有一定的瓜葛，这无非有两种情况：其一，一个标准被并入了另一标准；其二，一个标准依附于另一个标准。 查看使用的POSIX.1标准1234567891011121314151617$ getconf _POSIX_VERSION200809$ ldd --version |grep -i lddldd (Ubuntu GLIBC 2.35-0ubuntu3.1) 2.35$ gcc --version |grep -i gccgcc (Ubuntu 11.2.0-19ubuntu1) 11.2.0$ cat 002_standard.c #include &lt;stdio.h&gt;#include &lt;unistd.h&gt;void main() &#123; printf(&quot;posix standard: %ld\n&quot;, _POSIX_VERSION);&#125;$ gcc 002_standard.c $ ./a.out posix standard: 200809$ POSIX.1-2008 标准头文件 序号 头文件 必选 备注 1 &lt;aio.h&gt; 异步输入和输出 2 &lt;arpa/inet.h&gt; 互联网相关处理定义 3 &lt;cpio.h&gt; cpio archive format宏定义 4 &lt;dirent.h&gt; format of directory entries 5 &lt;dlfcn.h&gt; 动态链接处理 6 &lt;fcntl.h&gt; 文件控制 7 &lt;fmtmsg.h&gt; 消息显示格式 8 &lt;fnmatch.h&gt; 文件名匹配类型 9 &lt;ftw.h&gt; 文件树遍历 10 &lt;glob.h&gt; pathname pattern-matching types 11 &lt;grp.h&gt; group structure 12 &lt;iconv.h&gt; 代码集转换 13 &lt;langinfo.h&gt; 语言信息常量 14 &lt;libgen.h&gt; 路径模式匹配（dirname/basename) 15 &lt;monetary.h&gt; 货币类型与函数 16 &lt;mqueue.h&gt; 消息队列 17 &lt;ndbm.h&gt; 数据库操作 18 &lt;net/if.h&gt; sockets local interfaces 19 &lt;netdb.h&gt; 网络数据库操作 20 &lt;netinet/in.h&gt; internet address family 21 &lt;netinet/tcp.h&gt; tcp协议定义 22 &lt;nl_types.h&gt; 消息类型 23 &lt;poll.h&gt; poll 24 &lt;pthread.h&gt; 多线程 25 &lt;pwd.h&gt; 口令文件 26 &lt;regex.h&gt; 正则表达式 27 &lt;sched.h&gt; 执行调度 28 &lt;search.h&gt; search tables 29 &lt;semaphore.h&gt; 信号量 30 &lt;spawn.h&gt; spawn (ADVANCED REALTIME) 31 &lt;strings.h&gt; 字符串操作 32 &lt;stropts.h&gt; 33 &lt;sys/ipc.h&gt; XSI 进程间通信 34 &lt;sys/mman.h&gt; 内存管理 35 &lt;sys/msg.h&gt; XSI 消息队列 36 &lt;sys/resource.h&gt; XSI 资源操作 37 &lt;sys/select.h&gt; 38 &lt;sys/sem.h&gt; XSI 信号量 39 &lt;sys/shm.h&gt; XSI 共享内存 40 &lt;sys/socket.h&gt; 套接字接口 41 &lt;sys/stat.h&gt; 文件属性 42 &lt;sys/statvfs.h&gt; vfs文件系统信息 43 &lt;sys/time.h&gt; 44 &lt;sys/times.h&gt; 45 &lt;sys/types.h&gt; 46 &lt;sys/uio.h&gt; vector I/O操作 47 &lt;sys/un.h&gt; 48 &lt;sys/utsname.h&gt; 49 &lt;sys/wait.h&gt; 50 &lt;syslog.h&gt; 51 &lt;tar.h&gt; 52 &lt;termios.h&gt; 53 &lt;trace.h&gt; 54 &lt;ulimit.h&gt; 55 &lt;unistd.h&gt; 56 &lt;utime.h&gt; 57 &lt;utmpx.h&gt; 58 &lt;wordexp.h&gt; 字扩展类型]]></content>
      <tags>
        <tag>c</tag>
        <tag>iso-c</tag>
        <tag>posix.1</tag>
        <tag>sus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[持续交付2.0读书笔记]]></title>
    <url>%2F2020%2F07%2F25%2Freading-notes%2Fcontinuous-delivery-2-0%2F</url>
    <content type="text"><![CDATA[概述 精益思想是指导企业根据用户需求，定义企业生产价值，按照价值流来组织全部生产活动，使价值在生产活动之间流动起来，由需求拉动产品的生产，从而识别整个生产活动中不经意间产生的浪费，并消除之。 持续交付2.0 是一种产品研发管理思维框架。它以精益思想为指导，全面贯彻识别和消除一切浪费的理念，通过一系列工作原则与实践，完成高质量，底成本，无风险地快速交付客户价值。 双环模型持续交付2.0建立在持续交付1.0的“可持续地快速发布软件服务”以及精益创业的“最小化可行产品”两种理念的基础上，强调要以业务为导向，从一开始就将业务问题进行分解，并通过不断的科学探索与快速验证，减少浪费的同时，快速找到正确的业务前进方向，简称为“双环模型” 核心原则 坚持少做 需求永远是做不完的，而且很多需求都不一定是有价值的。所以，坚持少做，想办法对新创意尽早验证。 持续分解问题 即使很大的课题或很大范围的变更，也可以将其分解为一系列小变更。通过分解成一系列的小问题，将小问题快速解决，并得到反馈，从而尽早消除风险。 坚持快速反馈 通过快速反馈，尽早了解所完成工作的质量和效果。 持续改进并衡量 无论做了什么样的改进，如果无法以某种方式衡量它的结果，就无法证明真的得到了改进。在着手解决每个问题之前，我们都要找到适当的衡量方式，并将其与对应的功能需求放在同等重要的位置上，一起完成。 价值探索环 如何发现和识别用户地真实需求是一个难题。探索环通过提供一系列原则和方法，帮助大家分析和解决这一问题。 探索环地意义由于市场变化很快，当花费大量的时间完成产品所有的功能开发后，产品常会因为潜在用户对原型的理解偏差，或用户的需求发生了变化，导致之前的设计不再适应市场需求。瀑布模式的开发流程，在开发过程中存在一些风险假设。一是用户假设，即我们提供的产品服务是针对某类潜在的用户人群的需求的假设；二是问题假设，即目标用户之所以有这些需求，是因为他们的确存在某些痛点需要解决的假设；三是解决方案假设，即我们提供的解决方案能够解决这些通点，而且比其他现有的解决方案有效且高效。 上述三个假设中，任何一个假设不成立，都会导致我们事倍功半，甚至前功尽弃。探索环的目标就是通过一系列的环节，能够设别和定义业务问题（持续识别和定义上述有价值的假设），制定相应的衡量标准，并找出低成本且可快速验证的最小可行解决方案（Minimum Viable Solution）。 它本质上就是一个理解用户需求，判断优先级，再评估需求的过程。 探索环的关键环节 提问 通过有针对性的提问与讨论，澄清客户需求背后要实现的真实目标，以便寻找解决问题的方法，同时也有助于团队成员从业务问题出发，充分理解业务问题。 在提问环节要求不仅仅是找到“做什么”以及“怎么做”，更应该了解客户需求背后的原因“为什么要这样做”。 锚定 共创 精炼 敏捷十二原则 尽早地持续交付有价值的软件，以便让客户满意，这是最高优先级的事情。 即便在开发阶段后期，也欢迎需求变化。为了让客户获得业务竞争优势，利用敏捷过程来应对变化。 频繁交付可工作的软件，建议采用较短的交付周期(通常是几周或一两个月) 在整个项目过程中，业务人员和开发人员每天能够一起工作一段时间。 围绕积极的个体，建立项目团队。给他们需要的环境和支持，并相信他们能够完成工作。 无论团队内外，传递信息效果最好和效率最高的方式是面对面交谈。 可工作的软件是项目进度的首要衡量标准。 敏捷过程促进可持续发展。项目主要干系人，开发人员和用户应该能一直保持节奏。 持续关注技术卓越和良好的设计，提高敏捷性。 以简洁为本，它是极力减少不必要工作量的艺术。 最好的架构/需求和设计会从自组织团队中涌现。 团队要定期地反思“如何变得更有成效？”，然后相应地调整自身行为。]]></content>
      <tags>
        <tag>continuous delivery</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3内置函数]]></title>
    <url>%2F2020%2F07%2F18%2Fpython%2Fpython3-doc-buildin-function%2F</url>
    <content type="text"><![CDATA[sortedsorted(iterable, /, *, key=None, reverse=False) 函数返回一个新的已排序列表，不会修改原有的列表key 表示一个带有单个参数的函数，用于从 iterable 的每个元素中提取用于比较的键 (例如 key=str.lower)。 默认值为 None, 表示直接比较元素，如果元素不支持 &lt; 比较操作则抛出异常 。reverse为True，表示降序排序，默认为升序排序 1234567891011121314151617181920212223&gt;&gt;&gt; tmp_list=[3,1,7,6,5]&gt;&gt;&gt; sorted(tmp_list)[1, 3, 5, 6, 7]&gt;&gt;&gt; sorted(tmp_list, reverse=True)[7, 6, 5, 3, 1]&gt;&gt;&gt; print(tmp_list)[3, 1, 7, 6, 5]&gt;&gt;&gt; tmp_dict=[&#123;"name": "a", "age":16&#125;, &#123;"name":"b", "age":10&#125;]&gt;&gt;&gt; &gt;&gt;&gt; sorted(tmp_dict)Traceback (most recent call last): File "&lt;pyshell#117&gt;", line 1, in &lt;module&gt; sorted(tmp_dict)TypeError: '&lt;' not supported between instances of 'dict' and 'dict'&gt;&gt;&gt; &gt;&gt;&gt; def dict_sort(obj): return obj.get("age")&gt;&gt;&gt; sorted(tmp_dict, key=dict_sort)[&#123;'name': 'b', 'age': 10&#125;, &#123;'name': 'a', 'age': 16&#125;]&gt;&gt;&gt; tmp_dict[&#123;'name': 'a', 'age': 16&#125;, &#123;'name': 'b', 'age': 10&#125;]]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3内置类型序列]]></title>
    <url>%2F2020%2F07%2F04%2Fpython%2Fpython3-doc-buildin-sequence%2F</url>
    <content type="text"><![CDATA[三种基本的序列类型: 列表(list) 元组(tuple) range iterator迭代器，用于表示一连串数据流的对象。 重复调用迭代器对象的__next__()方法(或将迭代器对象传递给内置函数next())会逐个返回数据流中的元素。当没有元素可用时会抛出StopIteration异常。 迭代器对象必须包含__iter__()方法返回迭代器对象自身，因此迭代器对象默认是可迭代的，可以被用于适用于迭代器对象的大部分场合。 iterable可迭代的，是指对象具备一次返回一个成员的能力。所有的序列类型的对象都是可迭代的。任何实现了__iter__()或实现了sequence语义的__getitem__()的对象也都是可迭代的。 可迭代的对象可以被用在for循环或其他所有需要序列的地方(如zip(), map()等) 当一个可迭代的对象作为参数传递给内置函数iter()时就会返回一个迭代器。 当使用一个可迭代的对象时，通常不需要自己调用iter()生产迭代器然后再处理迭代器。for语句会自动完成这个操作，它创建一个临时的未命名变量用于在循环期间保存迭代器。 1234567891011121314151617&gt;&gt;&gt; range_obj = range(3)&gt;&gt;&gt; print(range_obj)range(0, 3)&gt;&gt;&gt; iter_obj = iter(range_obj)&gt;&gt;&gt; print(iter_obj)&lt;range_iterator object at 0x0000022DC27816F0&gt;&gt;&gt;&gt; print(next(iter_obj))0&gt;&gt;&gt; print(next(iter_obj))1&gt;&gt;&gt; print(next(iter_obj))2&gt;&gt;&gt; print(next(iter_obj))Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration&gt;&gt;&gt; 判断一个对象是不是可迭代的方式 12345678910111213141516171819202122232425262728293031&gt;&gt;&gt; tmp_list = [1,2,3]&gt;&gt;&gt; tmp_str = "abc"&gt;&gt;&gt; tmp_dict = &#123;"name": "john"&#125;&gt;&gt;&gt; tmp_range = range(10)&gt;&gt;&gt; from collections import Iterable&gt;&gt;&gt; print(isinstance(tmp_list, Iterable))True&gt;&gt;&gt; print(isinstance(tmp_str, Iterable))True&gt;&gt;&gt; print(isinstance(tmp_dict, Iterable))True&gt;&gt;&gt; print(isinstance(tmp_range, Iterable))True&gt;&gt;&gt; from collections import Iterator&gt;&gt;&gt; print(isinstance(tmp_range, Iterator))False&gt;&gt;&gt; print(isinstance(tmp_list, Iterator))False&gt;&gt;&gt; print(isinstance(tmp_dict, Iterator))False&gt;&gt;&gt; print(isinstance(tmp_str, Iterator))False&gt;&gt;&gt; print(isinstance(iter(tmp_str), Iterator))True&gt;&gt;&gt; print(isinstance(iter(tmp_list), Iterator))True&gt;&gt;&gt; print(isinstance(iter(tmp_dict), Iterator))True&gt;&gt;&gt; print(isinstance(iter(tmp_range), Iterator))True&gt;&gt;&gt; generator通常指生成器函数，一个返回generator iterator的函数。他与普通函数的不同点在于其包含了yield表达式用于产生一系列值提供给for循环使用或通过next()函数依此获取。 generator iterator生成器迭代器，generator 函数所创建的对象。生成器迭代器实质上也是迭代器。 每个 yield 会临时暂停处理，记住当前位置执行状态（包括局部变量和挂起的 try 语句）。当该 生成器迭代器 恢复时，它会从离开位置继续执行（这与每次调用都从新开始的普通函数差别很大）。 生成器迭代器使用 yield 关键字实现一次返回一个值给调用者，然后暂停执行，等待下一次调用，好处是节省内存空间。 生成器可以用next()函数，也可以用for迭代的方式获取元素值，中间还可以用close()来随时终止生成器 next()函数每次执行时，都会继续执行挂起的生成器函数，直到执行完毕。 生成器的这种特点被称为”延迟计算”或”惰性求值(Lazy evaluation)”，可以有效的节省内存。惰性求值实际上是体现了协同程序的思想。 虽然生成器的这种行为类似于迭代器，但两者有较大差别，迭代器不具备这种执行-暂停-再执行-再暂停的特性，所以迭代器不具有延迟计算，没有协同程序的思想。 1234567891011121314151617181920212223&gt;&gt;&gt; def generator_func(x):... for i in range(x):... yield i * 2...&gt;&gt;&gt; for v in generator_func(3):... print(v)...024&gt;&gt;&gt; &gt;&gt;&gt; generator_iter = generator_func(3)&gt;&gt;&gt; print(next(generator_iter))0&gt;&gt;&gt; print(next(generator_iter))2&gt;&gt;&gt; print(next(generator_iter))4&gt;&gt;&gt; print(next(generator_iter))Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt;StopIteration&gt;&gt;&gt; generator expression生成器表达式，返回一个生成器迭代器的表达式。他是一种特殊的生成器函数。 格式: (结果 for 变量 in 可迭代对象 if 条件筛选) 生成器表达式如果作为某个函数的参数，则可以省略掉() 生成器表达式和列表推导式的区别: 列表推导式比较消耗内存，一次性加载所有数据。生成器表达式几乎不占用内存，使用的时候才分配和使用内存 得到的值不一样。列表推导式得到的是一个列表。生成器表达式获取的是一个生成器。 12345678910111213141516def add(n, i): return n + idef test(): for i in range(4): yield ig = test()for n in [1, 10]: # n == 1 时，g = (add(n, i) for i in g)，此时 n 没有替换为 1。 惰性机制，不到最后不会拿值 # n == 10时，g = (add(n, i) for i in (add(n, i) for i in g)) # g = (add(n, i) for i in (10, 11, 12, 13)) # g = (10 + 10, 10 + 11, 10 + 12, 10 + 13) g = (add(n, i) for i in g) # 生成器表达式，在此之上所有的代码都没有进行计算print(list(g)) # [20, 21, 22, 23] list comprehension列表推导式，处理一个序列中的所有或部分元素并返回结果列表的一种紧凑写法。 格式: [结果 for 变量 in 可迭代对象 if 条件筛选] 如[‘{:#04x}’.format(x) for x in range(256) if x % 2 == 0] 将生成一个 0 到 255 范围内的十六进制偶数对应字符串（0x..）的列表。其中 if 子句是可选的，如果省略则 range(256) 中的所有元素都会被处理。 序列操作range类型不支持序列的s1 + s2 和 s * n操作s * n 如果 n 小于0，会按照0来处理，会产生一个空序列 如果s是可修改序列, 注意该操作不会创建序列s的副本，而是创建序列s的引用。这种行为通常不是期望的行为 1234567891011121314151617181920&gt;&gt;&gt; ori_list = []&gt;&gt;&gt; new_list = [ori_list] * 3 # 创建一个list，里面每一个元素都是ori_list的引用&gt;&gt;&gt; print(ori_list, new_list)[] [[], [], []]&gt;&gt;&gt; ori_list.append(1) # 修改ori_list后，会影响new_list中的每一个元素&gt;&gt;&gt; print(ori_list, new_list)[1] [[1], [1], [1]]&gt;&gt;&gt;&gt;&gt;&gt; ### 示例2&gt;&gt;&gt; ori_list = [1]&gt;&gt;&gt; new_list = [ori_list] * 3&gt;&gt;&gt; print(ori_list, new_list)[1] [[1], [1], [1]]&gt;&gt;&gt; ori_list = [1,2] # 对ori_list重新赋值不会影响new_list中的元素&gt;&gt;&gt; print(ori_list, new_list)[1, 2] [[1], [1], [1]]&gt;&gt;&gt; new_list[0].append(3)&gt;&gt;&gt; print(ori_list, new_list)[1, 2] [[1, 3], [1, 3], [1, 3]]&gt;&gt;&gt; s1 + s1 对不可变序列(str, bytes等)使用连接操作时，如果有大量(N个)不可变序列需要连接时效率会很慢，原因是需要进行N-1次的内存申请和搬运操作 官方推荐使用str.join()和bytes.join()方法替代，在执行join操作时，会首先统计出在list中一共有多少个对象，并统计这些对象所维护的字符串一共有多长，然后申请内存，将list中所有的对象维护的字符串都拷贝到新开辟的内存空间中。这里只进行了一次内存空间的申请，就完成了N个对象的连接操作。相比于 + 操作符，待连接的对象越多，效率的提升也会越明显。 12345678910111213141516171819202122import timecount = 10000000start_time = time.perf_counter()s = ''for n in range(0,count): s += str(n)end_time = time.perf_counter()print('Time elapse:&#123;&#125;'.format(end_time - start_time))start_time = time.perf_counter()s = []for n in range(0,count): s.append(str(n))''.join(s)end_time = time.perf_counter()print('Time elapse:&#123;&#125;'.format(end_time - start_time))start_time = time.perf_counter()s = ''.join(map(str,range(0,count)))end_time = time.perf_counter()print('Time elapse:&#123;&#125;'.format(end_time - start_time)) 方式 十万数据 百万数据 千万数据 方式一 0.05587520000000001 3.3037078 457.09966000000003 方式二 0.04598980000000001 0.45585239999999994 6.734024699999964 方式三 0.030382799999999988 0.3231406999999997 3.248821899999996 切片操作s[i:j:k] 123456789101112131415161718&gt;&gt;&gt; word = "Hello World"&gt;&gt;&gt; print(word[1:9]) # 切片的范围为[i,j)，包括i，但是不包含jello Wor&gt;&gt;&gt; print(word[9:1]) # 如果 i &gt; j，则返回空序列, k默认是1&gt;&gt;&gt; print(word[-1:3])&gt;&gt;&gt; print(word[1:9:2]) # 返回符合 i + n * k &lt; j 的所有元素el o&gt;&gt;&gt; print(word[1:100]) # 如果 i / j &gt; len(word), 则按照len(word)处理 ello World&gt;&gt;&gt; print(word[100:9])&gt;&gt;&gt;&gt;&gt;&gt; print(word[1:9:-2]) # 如果k为负值，则要求 i &gt; j&gt;&gt;&gt; print(word[9:1:-2])lo l 创建多维数组 先创建一个所需长度的列表，然后对列表中的所有元素进行填充 12345&gt;&gt;&gt; row, column = 3, 2 # 创建 3 行 2 列的二维数组&gt;&gt;&gt; A = [ [0] * column ] * row&gt;&gt;&gt; print(A)[[0, 0], [0, 0], [0, 0]]&gt;&gt;&gt; 使用numpy库 12345678910111213141516&gt;&gt;&gt; a1 = numpy.zeros([3,2], int) # 创建 3行2列的二维数组&gt;&gt;&gt; print(a1)[[0 0][0 0][0 0]]&gt;&gt;&gt;&gt;&gt;&gt; a2 = numpy.empty([3, 2]) # empty不会初始化为0&gt;&gt;&gt; print(a2)[[5.11798224e-307 3.44897992e-307][1.69118108e-306 9.34609790e-307][6.23037657e-307 8.34445138e-308]]&gt;&gt;&gt; help(numpy.zeros)Help on built-in function zeros in module numpy:zeros(...) zeros(shape, dtype=float, order='C') range类型range是一个内置的class类型，是Sequence[int]的子类，他是一个不可变的数字序列，通常用于for循环中指定循环次数。 range()返回的对象再很多方面表现的像是list，但是实际上不是。他返回的是一个可迭代的对象。 range相对于list和tuple的优点在于，不管range表示的范围是多大，他总是占用很小的相同大小的内存(仅仅保存start/stop/step三个值)。]]></content>
      <tags>
        <tag>python</tag>
        <tag>sequence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3内置类型]]></title>
    <url>%2F2020%2F07%2F04%2Fpython%2Fpython3-doc-buildin-type%2F</url>
    <content type="text"><![CDATA[Python中主要的内置类型有 数值类型(numberic) 序列(sequence) 字典(mapping) 类(class) 实例(instance) 异常(exception) 序列]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Python Stardard Libary]]></title>
    <url>%2F2020%2F07%2F04%2Fpython%2Fpython3-doc-stardard-lib%2F</url>
    <content type="text"><![CDATA[内置类型内置函数]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The Python Tutorial]]></title>
    <url>%2F2020%2F07%2F04%2Fpython%2Fpython3-doc-tutorial%2F</url>
    <content type="text"><![CDATA[执行运算符优先级参考 交互模式 _ 变量在交互模式中，最后一个printed expression会被赋值到 _ 变量中。使用该变量时，应该把它作为一个只读类型的变量。 123456789101112131415161718192021222324&gt;&gt;&gt; _ # 交互模式初始化是 _ 变量不存在Traceback (most recent call last): File "&lt;pyshell#0&gt;", line 1, in &lt;module&gt; _NameError: name '_' is not defined&gt;&gt;&gt; a=3&gt;&gt;&gt; _Traceback (most recent call last): File "&lt;pyshell#2&gt;", line 1, in &lt;module&gt; _NameError: name '_' is not defined&gt;&gt;&gt; b=4&gt;&gt;&gt; a+b7&gt;&gt;&gt; _7&gt;&gt;&gt; c=5&gt;&gt;&gt; _7&gt;&gt;&gt; c+_12&gt;&gt;&gt; _12&gt;&gt;&gt; 脚本文件的Shebang行 Unix系统中的 #! 符号称之为 Shebang 在Unix系统中，在python脚本文件的第一行指定如下内容后，python脚本就可以像shell一样直接执行 1#!/usr/bin/env python3 不使用#!/usr/bin/python3的原因是，为了提高可移植性，比如有些系统的python3没有安装在/usr/bin/目录，那么这种方式就会出错，而#!/usr/bin/env python3的方式，会在系统的PATH中搜索python3的安装路径，然后再调用对应路径下的python解释器执行。 编码文件编码默认情况下，python的代码文件采用的是UTF-8的编码方式。可以通过使用 1# -*- coding: encoding -*- 的方式修改文件的编码格式。 控制流程for循环在迭代一个collection的过程中同时修改该集合的内容时，如果想要取得正确的结果，可能需要一些技巧。通常情况下，是迭代一个副本，或者创建一个新的集合。 123456789101112131415&gt;&gt;&gt; words = ['cat', 'windows', 'linux']&gt;&gt;&gt; for w in words:... print(w)... words.remove(w) # 期望删除所有的元素...catlinux&gt;&gt;&gt; print(words) # 实际结果并不是期望的结果['windows']&gt;&gt;&gt; words = ['cat', 'windows', 'linux']&gt;&gt;&gt; for w in words[:]: # 迭代时，迭代的时works的一个副本的内容... words.remove(w)...&gt;&gt;&gt; print(words)[] 循环的else语句循环语句可以有else子句。它会在循环耗尽了迭代对象(for循环)或循环条件为假(while循环)时被执行，但是不会在循环执行break语句终止时被执行。 12345678910111213141516171819202122232425262728293031323334&gt;&gt;&gt; for i in range(0):... print(i)... else:... print("end")...end&gt;&gt;&gt;&gt;&gt;&gt; for i in range(3):... print(i)... else:... print("end")...012end&gt;&gt;&gt; while False:... print('aaa')... else:... print("else statement")...else statement&gt;&gt;&gt;&gt;&gt;&gt; for i in range(5):... print(i)... if i == 2:... break... else:... print("else statement")...012&gt;&gt;&gt; try…except语句中的else子句try … except 语句有一个可选的 else 子句，在使用时必须放在所有的 except 子句后面。 如果控制流离开 try 子句体时没有引发异常，并且没有执行 return或break/continue(try在for循环中时) 语句，可选的 else 子句将被执行。 else 语句中的异常不会由之前的 except 子句处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556&gt;&gt;&gt; def func(a, b):... ret = None... try:... ret = a / b... print("ret in try: %s" % ret)... except Exception as e:... print("catch exception: %s" % str(e))... else:... print("ret in else: %s" % ret)... finally:... print("ret in finally: %s" % ret)...&gt;&gt;&gt; func(10, 2) # 正常执行时，执行顺序 try -&gt; else -&gt; finallyret in try: 5.0ret in else: 5.0ret in finally: 5.0&gt;&gt;&gt; func(10, 0) # try中出现异常时， 执行顺序 try -&gt; except -&gt; finallycatch exception: division by zeroret in finally: None&gt;&gt;&gt; ### 如果 try 中有 return, 则 else子句不会执行&gt;&gt;&gt; def func(a, b):... ret = None... try:... ret = a / b... print("ret in try: %s" % ret)... return ret... except Exception as e:... print("catch exception: %s" % str(e))... else:... print("ret in else: %s" % ret)... finally:... print("ret in finally: %s" % ret)...&gt;&gt;&gt; func(10, 2) # try中没有异常抛出且有return语句时，执行顺序 try -&gt; finallyret in try: 5.0ret in finally: 5.05.0&gt;&gt;&gt; for i in [1, 2, 0, 5]:... print("i: %s" % i)... try:... ret = 10 / i... if i == 2:... break... except Exception as e:... print("catch exception")... else:... print("else statement")... finally:... print("finally statement")...i: 1else statementfinally statementi: 2finally statement&gt;&gt;&gt; try…except…finally 即使try/except/else中有return语句，finally子句也总是会被执行，函数的返回值是由最后的return决定的。所以如果finally中有return子句，最终生效的是finally中的return。 12345678910111213141516171819202122232425262728293031&gt;&gt;&gt; def func(a, b):... try:... ret = a / b... return ret... except:... return -1... finally:... print("finally")...&gt;&gt;&gt; func(10, 2)finally5.0&gt;&gt;&gt; func(10, 0)finally-1&gt;&gt;&gt;&gt;&gt;&gt; # 如果finally中有return，一定会是finally中的return生效&gt;&gt;&gt; def func(a, b):... try:... ret = a / b... return ret... except:... return -1... finally:... return -2...&gt;&gt;&gt; func(10, 2)-2&gt;&gt;&gt; func(10, 0)-2&gt;&gt;&gt; 数据结构数值运算 除运算时总是返回float类型的结果。表达式中整数与浮点数都存在时也是会返回float类型的结果 floor division // 运算会返回整数结果，是直接丢弃小数部分，不会四舍五入 字符串显示 通常情况下，交互模式中显示字符串时会将字符串的内容用单引号&#39;包裹起来 1234567891011121314151617181920212223&gt;&gt;&gt; str1 = '"isn\'t," they said'&gt;&gt;&gt; str1'"isn\'t," they said'&gt;&gt;&gt; print(str1)"isn't," they said&gt;&gt;&gt; str2="no, it is not"&gt;&gt;&gt; str2'no, it is not'&gt;&gt;&gt; print(str2)no, it is not&gt;&gt;&gt; str3="first line\nsecond line"&gt;&gt;&gt; str3'first line\nsecond line'# 使用print语句打印时，不会显示字符串回显时使用的包裹字符，同时会生效转义字符&gt;&gt;&gt; print(str3)first linesecond line&gt;&gt;&gt; str4="doesn\'t"# 当字符串中包含单引号同时没有包含双引号时，字符串的回显使用双引号包裹&gt;&gt;&gt; str4"doesn't"&gt;&gt;&gt; print(str4)doesn't 字符串中有反斜杠\时，会默认将后面的字符理解为转义字符，如果不想让字符转义时，可以使用\\或在字符串前添加r标记 123456789&gt;&gt;&gt; print("c:\name1\name2")c:ame1ame2&gt;&gt;&gt; print("c:\\name1\\name2")c:\name1\name2&gt;&gt;&gt; print(r"c:\name1\name2")c:\name1\name2&gt;&gt;&gt; 列表 列表中可以包含不同类型的元素，但是通常情况下都是同类型的。 列表的所有切片操作都会返回一个新的列表(shallow copy, 浅拷贝) 123456789101112131415161718192021222324&gt;&gt;&gt; list1=[1,2,3,4,5]&gt;&gt;&gt; id(list1)2012936495808&gt;&gt;&gt; list2=list1[:]&gt;&gt;&gt; id(list2)2012929059648&gt;&gt;&gt; list3=list1[2:]&gt;&gt;&gt; id(list3)2012936912256&gt;&gt;&gt;&gt;&gt;&gt; str1="abcdefg"&gt;&gt;&gt; str2=str1[:]&gt;&gt;&gt; id(str1)2012936632368&gt;&gt;&gt; id(str2)2012936632368&gt;&gt;&gt; id(str1)==id(str2)True&gt;&gt;&gt; id(list1)==id(list2)False&gt;&gt;&gt; str3=str1[2:]&gt;&gt;&gt; id(str3)2012936535024&gt;&gt;&gt; list.sort()会修改list的内容，返回值为None 123456&gt;&gt;&gt; print(tmp_list)[3, 1, 7, 6, 5]&gt;&gt;&gt; tmp_list.sort()&gt;&gt;&gt; print(tmp_list)[1, 3, 5, 6, 7]&gt;&gt;&gt; 函数函数中的默认值是在 定义过程 中在函数定义处计算的 12345678910111213141516171819&gt;&gt;&gt; i = 5&gt;&gt;&gt; def func(arg=i): print(arg) &gt;&gt;&gt; i = 6&gt;&gt;&gt; func()5&gt;&gt;&gt; func(i)6&gt;&gt;&gt; del i&gt;&gt;&gt; def func(arg=i): print(arg) Traceback (most recent call last): File "&lt;pyshell#29&gt;", line 1, in &lt;module&gt; def func(arg=i):NameError: name 'i' is not defined&gt;&gt;&gt; 函数中的默认值赋值只会执行一次如果函数的默认是可变对象(列表/字典等)时，所有采用默认值的函数调用，共享该可变对象 1234567891011121314&gt;&gt;&gt; def func(a, L=[]): L.append(a) return L&gt;&gt;&gt; func(1)[1]&gt;&gt;&gt; func(2)[1, 2]&gt;&gt;&gt; tmp_list = [1, 4, 5]&gt;&gt;&gt; func(3, tmp_list)[1, 4, 5, 3]&gt;&gt;&gt; func(4)[1, 2, 4]&gt;&gt;&gt; 函数中形参格式如果 参数中既有 *args 类型，又有**keywords类型，那么*args必须在**keywords前面 *args 类型的参数，在函数内的类型时元组类型**keywords 类型的参数，在函数内的类型时字典类型 1234567891011121314151617181920212223242526272829303132333435&gt;&gt;&gt; def func(kind, *args, **keywords): print(kind) print(type(args)) print(args) print(type(keywords)) print(keywords) &gt;&gt;&gt; func(1, "a", "b", "c", name="abc", age="12")1&lt;class 'tuple'&gt;('a', 'b', 'c')&lt;class 'dict'&gt;&#123;'name': 'abc', 'age': '12'&#125;&gt;&gt;&gt; func(1, *("a", "b", "c"), **&#123;"name":"abc", "age":"12"&#125;)1&lt;class 'tuple'&gt;('a', 'b', 'c')&lt;class 'dict'&gt;&#123;'name': 'abc', 'age': '12'&#125;&gt;&gt;&gt; args=["arg1", "arg2"]&gt;&gt;&gt; tmp_dict=&#123;"name1": "value1", "name2": "value2"&#125;&gt;&gt;&gt; func(2, args, tmp_dict)2&lt;class 'tuple'&gt;(['arg1', 'arg2'], &#123;'name1': 'value1', 'name2': 'value2'&#125;)&lt;class 'dict'&gt;&#123;&#125;&gt;&gt;&gt; ### 函数调用时，如果之前有定义好的列表/元组或字典类型的变量，需要给*args 或 **keywords格式的形参传递时，可以使用 * 或 ** 对之前定义好的变量进行解包操作&gt;&gt;&gt; func(2, *args, **tmp_dict)2&lt;class 'tuple'&gt;('arg1', 'arg2')&lt;class 'dict'&gt;&#123;'name1': 'value1', 'name2': 'value2'&#125;&gt;&gt;&gt; 如果存在 / 或 *, / 之前的所有参数都只能通过位置方式传参，* 之后的所有参数只能通过key=value方式传参，其他参数可以使用两种的任意一种方式传参 1def func(pos1, pos2, /, p_or_kwd1, p_or_kwd2, *, kwd1, kwd2) 模块模块初始化模块中可以包含可执行的语句以及函数定义。这些语句用于初始化模块。它们仅在模块第一次被import时执行一次 每个模块在每个解释器会话中只被导入一次。如果更改了模块的内容，必须重启解释器或者使用 importlib.reload(module_name) 被导入的模块名存放在调入模块的全局符号表中，可以通过dir()查看 模块导入模块的搜索方式: 当导入一个模块时，先查找是否为内置模块；如果没有找到，则在sys.path定义的列表中查找 sys.path中默认包含以下内容 当前脚本所在路径 系统环境变量PYTHONPATH python安装路径相关目录]]></content>
      <tags>
        <tag>pyhton</tag>
        <tag>tutorial</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[URI编码]]></title>
    <url>%2F2020%2F06%2F25%2Fhttp%2Furi-encoded%2F</url>
    <content type="text"><![CDATA[保留字符的URI编码 保留字符 URI编码 ！ %21 * %2A “ %22 ‘ %27 ( %28 ) %29 ; %3B : %3A @ %40 &amp; %26 = %3D + %2B $ %24 , %2C / %2F ? %3F % %25 # %23 [ %5B ] %5D]]></content>
      <tags>
        <tag>http</tag>
        <tag>URI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pip工具]]></title>
    <url>%2F2020%2F06%2F25%2Fpython%2Fpython-pip%2F</url>
    <content type="text"><![CDATA[从python3.4版本开始，pip工具默认包含在了python的安装包中 python Packagings文档pip官方文档 常用命令pip命令执行的方式有如下两种: pip &lt;args&gt; pyhton -m pip &lt;args&gt; 12345678910111213141516171819202122pip install somePackage # 安装最新版本pip install somePackage==1.0.4 # 安装指定版本，如果之前有安装其他版本，会先卸载老的版本pip install 'somePackage&gt;=1.0.4' # 安装指定最低版本pip freeze &gt; requirements.txtpip install -r requirements.txt # 根据requirements文件安装pip install --upgrade somePackage # 升级软件到最新版本pip install /path/to/SomePackage-1.0-py2.py3-none-any.whl # 安装本地指定文件pip wheel --wheel-dir=. requests # 下载requests及依赖包到wheel-dir目录，不安装pip wheel --wheel-dir=/local/wheels -r requirements.txtpip install --no-index --find-links=. requests # 在本地find-links指定的目录查找包进行安装pip install --no-index --find-links=/local/wheels -r requirements.txtpip uninstall somePackage # 卸载命令pip uninstall -r requirements.txt # 根据requirements文件卸载pip search somePackage # 搜索包pip show somePackage # 显示包的信息pip list --outdated # 显示所有可以升级的所有的包 配置文件配置文件路径pip的配置文件的存放有三种作用范围的配置方式: site-wide per-user per-virtualenv 如果存在多个配置文件，会按照上面的先后顺序去读取文件内容，如果有重复内容，后读取的文件内容会覆盖前面的内容 Linux Mac windows per-user ${HOME}/.config/pip/pip.conf${HOME}/.pip/pip.conf(老的配置方式) ${HOME}/Library/Application Support/pip/pip.conf(高优先查找)${HOME}/.config/pip/pip.conf(低优先查找)${HOME}/.pip/pip.conf(老的配置方式) %APPDATA%\pip\pip.ini%HOME%\pip\pip.ini(老的配置方式) per-virtualenv $VIRTUAL_ENV/pip.conf $VIRTUAL_ENV/pip.conf %VIRTUAL_ENV%\pip.ini site-wide /etc/pip.conf /Library/Application Support/pip/pip.conf C:\ProgramData\pip\pip.ini(win7及后续版本) 配置文件内容123456[global]index-url = https://mirrors.aliyun.com/pypi/simple/#proxy=http://[user:passwd@]proxy.server:port[install]trusted-host=mirrors.aliyun.com 配置文件中的配置项，都可以在命令行中通过 --&lt;option&gt; 的方式对某一次命令执行进行特殊指定proxy中账号和密码如果有特殊字符，必须使用 percent-encoded(又称为URI编码)]]></content>
      <tags>
        <tag>python</tag>
        <tag>pip</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx安装]]></title>
    <url>%2F2020%2F06%2F15%2Fnginx%2Fnginx-install%2F</url>
    <content type="text"><![CDATA[yum源安装源码安装 1234567891011121314151617[root@localhost nginx-1.18.0]# yum install -y zlib-devel pcre-devel[root@localhost nginx-1.18.0]# ./configure --prefix=/usr/local/nginx ...... nginx path prefix: "/usr/local/nginx" nginx binary file: "/usr/local/nginx/sbin/nginx" nginx modules path: "/usr/local/nginx/modules" nginx configuration prefix: "/usr/local/nginx/conf" nginx configuration file: "/usr/local/nginx/conf/nginx.conf" nginx pid file: "/usr/local/nginx/logs/nginx.pid" nginx error log file: "/usr/local/nginx/logs/error.log" nginx http access log file: "/usr/local/nginx/logs/access.log" nginx http client request body temporary files: "client_body_temp" nginx http proxy temporary files: "proxy_temp" nginx http fastcgi temporary files: "fastcgi_temp" nginx http uwsgi temporary files: "uwsgi_temp" nginx http scgi temporary files: "scgi_temp"[root@localhost nginx-1.18.0]# make &amp;&amp; make install 设置开机自启动 123456789101112131415[root@localhost nginx-1.18.0]# cat /usr/lib/systemd/system/nginx.service[Unit]Description=nginx serviceAfter=network.target[Service]Type=forkingExecStart=/usr/local/nginx/sbin/nginxExecReload=/usr/local/nginx/sbin/nginx -s reloadExecStop=/usr/local/nginx/sbin/nginx -s quitPrivateTmp=ture[Install]WantedBy=multi-user.target[root@localhost nginx-1.18.0]# systemctl enable nginx[root@localhost nginx-1.18.0]# systemctl start nginx[root@localhost nginx-1.18.0]# systemctl status nginx]]></content>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx使用总结]]></title>
    <url>%2F2020%2F06%2F15%2Fnginx%2Fnginx%2F</url>
    <content type="text"><![CDATA[安装nginx]]></content>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins pipeline的groovy脚本执行权限问题]]></title>
    <url>%2F2020%2F06%2F15%2Fjenkins%2Fjenkins-script-approval%2F</url>
    <content type="text"><![CDATA[在Pipeline中直接如下执行Groovy脚本时，会提示权限问题 1234List&lt;String&gt; jenkinsPlugins = new ArrayList&lt;String&gt;(Jenkins.instance.pluginManager.plugins)jenkinsPlugins.sort &#123; it.displayName &#125;.each &#123; plugin -&gt; println("$&#123;plugin.shortName&#125;:$&#123;plugin.version&#125;")&#125; 问题日志如下: 123456Started by user unknown or anonymousRunning in Durability level: MAX_SURVIVABILITY[Pipeline] Start of PipelineScripts not permitted to use method jenkins.model.Jenkins getPluginManager. Administrators can decide whether to approve or reject this signature.[Pipeline] End of Pipelineorg.jenkinsci.plugins.scriptsecurity.sandbox.RejectedAccessException: Scripts not permitted to use method jenkins.model.Jenkins getPluginManager 解决方法: jenkins &gt; Manage jenkins &gt; In-process Script Approval中增加权限，这种方式在重启Jenkins服务后需要再次增加权限 创建pipeline任务时，取消Use Groovy Sandbox的勾选 安装Permissive Script Security插件，启动jenkins服务时，指定-Dpermissive-script-security.enabled=true启动参数 安装方法3配置后，在任务的执行日志中会有相关提示信息，但是不会再因为需要approve而终止任务运行 12345678Started by user unknown or anonymousRunning in Durability level: MAX_SURVIVABILITY[Pipeline] Start of PipelineScripts not permitted to use staticMethod jenkins.model.Jenkins getInstance. Administrators can decide whether to approve or reject this signature.Scripts not permitted to use method jenkins.model.Jenkins getPluginManager. Administrators can decide whether to approve or reject this signature.Scripts not permitted to use method hudson.PluginManager getPlugins. Administrators can decide whether to approve or reject this signature.expected to call java.util.ArrayList.sort but wound up catching org.jenkinsci.plugins.workflow.cps.CpsClosure2.call; see: https://jenkins.io/redirect/pipeline-cps-method-mismatches/[Pipeline] End of Pipeline]]></content>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum私有源配置]]></title>
    <url>%2F2020%2F06%2F14%2Fcentos%2Fyum-private-repo%2F</url>
    <content type="text"><![CDATA[本地源配置 将系统的iso文件挂载到/mnt/iso目录 1mount -o loop xxx.iso /mnt/iso 在/etc/yum.repo.d/中增加local.repo文件，内容如下: 12345[local]name=localbaseurl=file:///mnt/isoenable=1gpgcheck=0 enable 表示是否启用该源，0表示关闭，1表示开启gpgcheck 表示是否检查GPG-KEy，0表示不检查，1表示检查 搭建局域网HTTP服务的私有源生成repodata 1234567891011121314151617[root@localhost /]# yum install createrepo[root@localhost /]# mkdir -p /data/repo/7/x86_64[root@localhost x86_64]# cd /data/repo/7/x86_64# 执行 createrepo 会在目录下生成 repodata目录，为了简单，当前目录下之copy了一个zlib的rpm包# 如果rpm包有变化，需要执行createrepo --update .[root@localhost x86_64]# createrepo .Spawning worker 0 with 4021 pkgsWorkers FinishedSaving Primary metadataSaving file lists metadataSaving other metadataGenerating sqlite DBsSqlite DBs complete[root@localhost x86_64]# ll |grep -v rpmtotal 3891360drwxr-xr-x. 2 root root 4096 Jun 15 13:54 repodata[root@localhost x86_64]# 搭建http服务 参考nginx安装 配置文件如下: 123456789101112131415161718192021222324252627user root;worker_processes 1;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; sendfile on; keepalive_timeout 65; server &#123; listen 8090; server_name localhost; root /data/repo; location / &#123; autoindex on; charset utf-8; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; &#125;&#125; 修改yum.repo验证 先删掉当前所有的repo配置，增加private的repo配置 12345678910111213141516171819202122232425[root@localhost yum.repos.d]# cat private.repo[private]name=privatebaseurl=http://192.168.43.129:8090/7/x86_64enable=1gpgcheck=0[root@localhost yum.repos.d]# yum clean allLoaded plugins: fastestmirrorCleaning repos: privateCleaning up list of fastest mirrorsOther repos take up 50 M of disk space (use --verbose for details)[root@localhost yum.repos.d]# yum makecacheLoaded plugins: fastestmirrorDetermining fastest mirrorsprivate | 2.9 kB 00:00:00(1/3): private/filelists_db | 927 B 00:00:00(2/3): private/other_db | 1.4 kB 00:00:00(3/3): private/primary_db | 2.0 kB 00:00:00Metadata Cache Created[root@localhost yum.repos.d]# yum list availableLoaded plugins: fastestmirrorLoading mirror speeds from cached hostfileAvailable Packageszip.x86_64 3.0-11.el7 private[root@localhost yum.repos.d]# yum install -y zip]]></content>
      <tags>
        <tag>yum</tag>
        <tag>repo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualbox增强功能]]></title>
    <url>%2F2020%2F06%2F14%2Fvirtualbox%2Fvirtualbox-addtions%2F</url>
    <content type="text"><![CDATA[virtual box版本: 6.0.22linux虚拟机版本: centos 7.6-1810 最小化安装 安装增强功能 在启动虚拟机之前，先在 [设置] -&gt; [存储] -&gt; [存储介质] -&gt; [控制器IDE]中增加一个虚拟光驱 选择增强功能的虚拟光驱文件C:\Program Files\Oracle\VirtualBox\VBoxGuestAdditions.iso 启动虚拟机后，光驱文件为/dev/cdrom，需要手动挂载到/mnt/cdrom 安装增强功能时，需要增加内核模块，需要安装依赖 yum install -y bzip2 kernel-devel gcc make perl 执行命令 cd /mnt/cdrom; ./VBoxLinuxAdditions.run 配置共享文件夹在 [设置] -&gt; [共享文件夹] 中添加共享文件夹即可 共享文件夹路径为 宿主机 中要共享到虚拟机的文件夹路径挂载点为 虚拟机 中的共享文件夹路径选中 自动挂载 和 固定分配使用共享文件夹目录功能需要先安装增强功能]]></content>
      <tags>
        <tag>vitrualbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[virtualbox使用总结]]></title>
    <url>%2F2020%2F06%2F14%2Fvirtualbox%2Fvirtualbox%2F</url>
    <content type="text"><![CDATA[安装增强功能网络配置]]></content>
      <tags>
        <tag>virtualbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum命令使用]]></title>
    <url>%2F2020%2F06%2F03%2Fcentos%2Fyum-cmd%2F</url>
    <content type="text"><![CDATA[搜索命令属于哪些包 yum search xxx yum provides xxx yum list 命令 描述 yum list [all] 所有已安装和可以安装的包 yum list available 所有可以安装的包 yum list installed 所有已经安装的包 yum list updates 所有可以升级的包 yum list extra 所有已经安装但不在repository的包 查看软件包详情 yum info wget查看软件包依赖 yum deplist wget删除yum安装的软件 yum remove xxx 或 yum erase xxx更新软件 yum update [package_name]如果没有指定package_name, 则会更新所有已安装的软件]]></content>
      <tags>
        <tag>centos</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下docker安装]]></title>
    <url>%2F2020%2F05%2F31%2Fwindows%2Fwindows-docker%2F</url>
    <content type="text"><![CDATA[官方文档]]></content>
      <tags>
        <tag>docker</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WSL使用]]></title>
    <url>%2F2020%2F05%2F31%2Fwindows%2Fwsl%2F</url>
    <content type="text"><![CDATA[WSL官方文档 WSL常用命令 命令 说明 wslconfig /l [/running, /all] 查看已经安装的linux子系统 wslconfig /u 注销安装的子系统 wslconfit /s 将名称为name的子系统设置为默认 安装的linux子系统保存在%LocalAppData%\Packages目录下面 使用 wslconfig /u 命令注销掉，并未真正删除，store里面还是显示已安装，使用管理员身份运行下面两个powershell命令进行删除get-appxpackage -allusers |select name, packagefullnameget-appxpackage CanonicalGroupLimited.Ubuntu20.04onWindows |remove-appxpackage WSL下安装centosCentWSL已失效Rolisoft的WSL下Linux的转换方法12345678910111213141516PS D:\workspace\github\WSL-Distribution-Switcher&gt; git clone https://github.com/RoliSoft/WSL-Distribution-Switcher.gitCloning into 'WSL-Distribution-Switcher'...remote: Enumerating objects: 323, done.remote: Total 323 (delta 0), reused 0 (delta 0), pack-reused 323Receiving objects: 100% (323/323), 114.58 KiB | 235.00 KiB/s, done.Resolving deltas: 100% (204/204), done.PS D:\workspace\github\WSL-Distribution-Switcher&gt;PS D:\workspace\github\WSL-Distribution-Switcher&gt; python .\get-prebuilt.py centos:8.1.1911[*] Requesting authorization token...[*] Fetching manifest info for centos:8.1.1911...[*] Downloading layer sha256:a3ed95caeb02ffe68cdd9fd84406680ae93d633cb16422d00e8a7c22955b46d4...[*] Downloading layer sha256:8a29a15cefaeccf6545f7ecf11298f9672d2f0cdaf9e357a95133ac3ad3e1f07... rootfs_centos_8.1.19... [===============&gt; ] 30.04%[*] Rootfs archive for centos:8.1.1911 saved to rootfs_centos_8.1.1911.tar.gz.PS D:\workspace\github\WSL-Distribution-Switcher&gt; python .\install.py centos:8.1.1911[*] Probing the Linux subsystem...[!] The Linux subsystem is not installed. Please go through the standard installation procedure first. 安装失败，因为它依赖Debian子系统。即使使用Microsoft store安装了Debian子系统后，仍然执行失败，提示找不到lxrun.exe。lxrun.exe已经是废弃的应用程序。所以放弃了该种方法]]></content>
      <tags>
        <tag>centos</tag>
        <tag>WSL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows使用总结]]></title>
    <url>%2F2020%2F05%2F31%2Fwindows%2Fwindows-usage%2F</url>
    <content type="text"><![CDATA[windows hosts文件 文件位置: C:\Windows\System32\drivers\etc\hosts raw.githubusercontent.com无法连接时，可以在hosts文件中添加主机IP映射 1151.101.76.133 raw.githubusercontent.com # ip地址信息可以通过各种[站长工具网站](https://tool.chinaz.com/)查询 登录虚拟机时提示host key验证失败123456789101112131415161718PS C:\Users\xxx&gt; ssh root@192.168.43.129@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!Someone could be eavesdropping on you right now (man-in-the-middle attack)!It is also possible that a host key has just been changed.The fingerprint for the ECDSA key sent by the remote host isSHA256:DX2C/kvltG3k9LJpC6Mlz2WPAkcpf5pQaRYyZLkH/3A.Please contact your system administrator.Add correct host key in C:\\Users\\xxx/.ssh/known_hosts to get rid of this message.Offending ECDSA key in C:\\Users\\xxx/.ssh/known_hosts:7ECDSA host key for 192.168.43.129 has changed and you have requested strict checking.Host key verification failed.PS C:\Users\xxx&gt; ssh-keygen.exe -R 192.168.43.129# Host 192.168.43.129 found: line 7C:\Users\xxx/.ssh/known_hosts updated.Original contents retained as C:\Users\xxx/.ssh/known_hosts.old windows下docker安装WSL]]></content>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux下的diff和patch使用]]></title>
    <url>%2F2020%2F05%2F22%2Flinux%2Flinux-diff-patch%2F</url>
    <content type="text"><![CDATA[diff命令diff命令时unix中用来比较文件差异的工具，也通常用于代码管理中。 diff命令显示结果有三种格式: 正常格式(normal diff) diff f1 f2 上下文格式(context diff) diff -c f1 f2 合并格式(unified diff) diff -u f1 f2 side-by-side格式 diff -y f1 f2 比较文件的内容: 1234567891011121314151617181920[root@localhost b]# cat -n f1 1 0 2 3 3 1 4 a 5 b 6 c 7 d 8 e 9 f[root@localhost b]# cat -n f2 1 3 2 a 3 b 4 aaa 5 f 6 bbb 7 ccc 8 ddd[root@localhost b]# 正常格式12345678910111213141516[root@localhost b]# diff f1 f21d0 # 变动位置说明, f1文件的第一行被删除(d,delete)&lt; 0 # `&lt;`行 表示f1文件变动行的内容3d1&lt; 16,8c4 # f1文件的第6行到第8行内容被修改(c, change)成f2文件的第四行内容&lt; c&lt; d&lt; e---&gt; aaa # `&gt;`行 表示f2文件变动行的内容9a6,8 # f1文件第9行后面被增加(a, add)了f2文件的第6行到第8行的内容&gt; bbb&gt; ccc&gt; ddd[root@localhost b]# 上下文格式 上个世纪80年代初，加州大学伯克利分校推出BSD版本的Unix时，觉得diff的显示结果太简单，最好加入上下文，便于了解发生的变动。因此，推出了上下文格式的diff可以通过 diff -C Num 或 diff --context[=Num]的方式指定显示上下文的行数，默认为3行(前三行加后三行) 123456789101112131415161718192021222324[root@localhost b]# diff f1 f2 -c*** f1 2020-05-22 00:21:43.668716845 +0800 # *** 表示变动前文件--- f2 2020-05-22 00:32:51.747625563 +0800 # --- 表示变动后文件*************** # 15个星号，表示内容分割*** 1,9 **** # 显示变动前的文件(***)的第一行到第九行- 0 # - 表示改行被删除 3- 1 a b! c # ! 表示内容被修改! d! e f--- 1,8 ---- # 显示变动后的文件(---)的第一行到第八行 3 a b! aaa # 对应变动前的修改部分 f+ bbb # + 表示新增内容+ ccc+ ddd[root@localhost b]# 合并格式 如果两个文件相似度很高，那么上下文格式的diff，将显示大量重复的内容，很浪费空间。1990年，GNU diff率先推出了”合并格式”的diff，将f1和f2的上下文合并在一起显示可以通过 diff -U Num 或 diff --unified[=Num]的方式指定显示上下文的行数，默认为3行(前三行加后三行) git的diff格式就是采用的合并格式的变体 12345678910111213141516171819[root@localhost b]# diff f1 f2 -u--- f1 2020-05-22 00:21:43.668716845 +0800 # --- 表示变动前的文件+++ f2 2020-05-22 00:32:51.747625563 +0800 # +++ 表示变动后的文件@@ -1,9 +1,8 @@ # 变动的位置用两个@作为起首和结束 # f1文件从第一行开始连续9行的内容变成了f2文件的第一行开始连续8行内容-0 # - 表示 f1 删除的行 3-1 a b-c-d-e+aaa # + 表示 f2 新增的行 f+bbb+ccc+ddd[root@localhost b]# side-by-side格式 这种格式下，会将两个文件的内容分成两列对比展示出来 1234567891011121314[root@localhost b]# diff -y -W 20 f1 f20 &lt; # &lt; 表示只在f1文件中存在3 3 # 表示两个文件内容相同1 &lt;a ab bc | aaa # 两个文件中的内容有差异d &lt;e &lt;f f &gt; bbb # &gt; 表示只在f2文件中存在 &gt; ccc &gt; ddd[root@localhost b]# 命令格式说明diff [选项] [文件1或目录1] [文件2或目录2]（四种组合方式） 比较两个文件时，如果其中一个文件为 - 符号，表示从标准输入读取，以 ctrl+d 结束输入如果输入的参数一个时文件，一个是目录时，会在该目录下查找同名文件进行比较，如果文件不存，则提示失败如果输入的参数是两个目录时，也是只比较目录下的同名文件，默认是只比较目录下的文件，不会递归比较子目录diff命令返回0 表示无差异，返回1 表示有差异， 返回2 表示命令出错(如文件不存在等) 常用的选项 选项 说明 --normal 正常格式进行展示，如果不指定显示格式，默认为正常格式 -c或-C NUM或--context=NUM 按照上下文格式进行展示 -u或-U NUM或--unified=NUM 按照合并格式进行展示 -y或--side-by-side 按照side-by-side格式进行展示 -W NUM或--width=NUm 指定-y模式下显示的总列数，默认为130 --suppress-common-lines 指定-y模式下，不显示相同内容的行 -r或--recursive 递归比较子目录 -x或--exclude=PAT 排除与PAT（pattern样式）匹配的文件 -X或--exculde-from=FILE 排除与FILE中样式匹配的文件 -i或--ignore-case 忽略大小写的区别 -b或--ignore-space-change 忽略空格的差异 -w或--ignore-all-space 忽略所有的空白差异 -B或--ignore-blank-line 忽略空白行差异 -I RE或--ignore-matching-lines=RE 忽略所有匹配RE（regexp正则表达式）的行的更改 -Z或--ignore-trailing-space 忽略行尾空格 -E或--ignore-tab-expansion 忽略tab扩展差异 --ignore-file-name-case 比较时忽略文件大小写 --no-ignore-file-name-case 比较时不忽略文件大小写 --ignore-file-name-case 比较时忽略文件大小写 -N或--new-file 比较目录时，如果f3只在a目录中存在，默认会输出Only in a: f3，如果配置了该参数后，diff命令会将f3文件与一个空白文件进行对比 -p或--show-c-function 如果比较的文件时c语言源文件，显示差异所在的函数名 -P或--unidirectional-new-file 与 -N类似，只有当第二个目录包含了第一个目录没有的文件时，才会将这个文件与空白文件做对比 patch命令 执行patch命令时，patch文件中定义的修改后的目录不能存在 patch命令说明patch命令的使用有两种格式 如果针对单文件打补丁: patch [option] [originalfile [patchfile]] 同时常用更多的方式为: patch -pnum &lt; patchfile 常用的命令选项| 名称 | 说明 || ———————- | ———————————————————————————————————————————————— || --dry-run | 只是打印应用补丁后的结果，并不会实际修改文件 || -R 或 --reverse | 该命令执行时会假设补丁文件是通过交换ori和mod参数，实际上可以对打过补丁后的文件做回滚操作 || -b或--backup | 对每一个修改的文件做备份，会生成xxx.orig备份文件 || -pNum或--strip=NUM | 设置执行命令时会去除patchfile中的几层路径名。0表示不删除，使用patchfile中的全路径，如果未指定该参数或NUM设置有问题，会提示找不到需要打补丁的文件 | diff + patch的补丁应用 如果是对目录制作补丁文件，目录应该使用相对路径，不要使用绝对路径两个目录的结构要一样 根据修改后目录的内容不同，生成补丁的方式也会不一样 如果mod的目录中只包含了对ori目录中某些文件的修改或新增了某些文件 diff -urP src_ori_dir src_mod_dir &gt; src.patch 12345678910111213141516171819202122232425262728293031323334353637383940[root@localhost test_diff_patch]# tree ./src_ori./src_ori # ori目录中有两个文件 123 和 abc，文件中的内容与文件名相同├── 123└── abc0 directories, 2 files[root@localhost test_diff_patch]# cat ./src_ori/*123abc#### patch中修改了abc文件的内容为bbb，并新增了文件ccc###[root@localhost test_diff_patch]# cat src.patchOnly in src_ori: 123diff -ruP src_ori/abc src_mod/abc--- src_ori/abc 2020-05-23 14:25:13.895198462 +0800+++ src_mod/abc 2020-05-23 14:04:06.095735637 +0800@@ -1 +1 @@-abc+bbbdiff -ruP src_ori/ccc src_mod/ccc--- src_ori/ccc 1970-01-01 08:00:00.000000000 +0800+++ src_mod/ccc 2020-05-23 14:25:41.160887860 +0800@@ -0,0 +1 @@+ccc[root@localhost test_diff_patch]# patch -p0 &lt; src.patchpatching file src_ori/abcpatching file src_ori/ccc[root@localhost test_diff_patch]# tree ./src_ori./src_ori # 执行了patch命令后，ori中多了ccc文件，abc的内容也变成了bbb├── 123├── abc└── ccc0 directories, 3 files[root@localhost test_diff_patch]# cat ./src_ori/*123bbbccc[root@localhost test_diff_patch]# 只要mod的目录中有对ori目录文件做删除，那么mod目录中必须包含未删除ori中的其他所有文件 diff -urN src_ori_dir src_mod_dir &gt; src.patch 12345678910111213141516171819202122232425262728293031323334353637383940414243444546# ori中文件内容与文件名相同baoze@DESKTOP-EV6CLJE:/mnt/d/workspace/patch_test$ ll ./*/*-rwxrwxrwx 1 baoze baoze 7 Jun 2 18:55 ./mod/aaa*-rwxrwxrwx 1 baoze baoze 4 Jun 2 18:54 ./ori/aaa*-rwxrwxrwx 1 baoze baoze 4 Jun 2 18:54 ./ori/bbb*./ori/inner:total 0drwxrwxrwx 1 baoze baoze 512 Jun 2 18:54 ./drwxrwxrwx 1 baoze baoze 512 Jun 2 18:54 ../-rwxrwxrwx 1 baoze baoze 4 Jun 2 18:54 ccc*baoze@DESKTOP-EV6CLJE:/mnt/d/workspace/patch_test$## mod中内容修改了aaa文件，删除了bbb和ccc文件baoze@DESKTOP-EV6CLJE:/mnt/d/workspace/patch_test$ diff -ruN ori mod &gt; mod.patchbaoze@DESKTOP-EV6CLJE:/mnt/d/workspace/patch_test$ cat mod.patchdiff -ruN ori/aaa mod/aaa--- ori/aaa 2020-06-02 18:54:37.447786500 +0800+++ mod/aaa 2020-06-02 18:55:36.400920500 +0800@@ -1 +1 @@-aaa+newaaadiff -ruN ori/bbb mod/bbb--- ori/bbb 2020-06-02 18:54:42.786351600 +0800+++ mod/bbb 1970-01-01 08:00:00.000000000 +0800@@ -1 +0,0 @@-bbbdiff -ruN ori/inner/ccc mod/inner/ccc--- ori/inner/ccc 2020-06-02 18:54:29.759650700 +0800+++ mod/inner/ccc 1970-01-01 08:00:00.000000000 +0800@@ -1 +0,0 @@-cccbaoze@DESKTOP-EV6CLJE:/mnt/d/workspace/patch_test$# 对ori进行打补丁baoze@DESKTOP-EV6CLJE:/mnt/d/workspace/patch_test$ patch -p0 &lt; mod.patchpatching file ori/aaapatching file ori/bbbpatching file ori/inner/ccc# 打补丁后ori目录下只有aaa文件，内容也有修改baoze@DESKTOP-EV6CLJE:/mnt/d/workspace/patch_test$ ll ori/total 0drwxrwxrwx 1 baoze baoze 512 Jun 2 19:08 ./drwxrwxrwx 1 baoze baoze 512 Jun 2 19:06 ../-rwxrwxrwx 1 baoze baoze 7 Jun 2 19:08 aaa*baoze@DESKTOP-EV6CLJE:/mnt/d/workspace/patch_test$ cat ori/aaanewaaabaoze@DESKTOP-EV6CLJE:/mnt/d/workspace/patch_test$]]></content>
      <tags>
        <tag>diff</tag>
        <tag>patch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python3官方文档学习笔记]]></title>
    <url>%2F2020%2F05%2F20%2Fpython%2Fpython3-doc-notes%2F</url>
    <content type="text"><![CDATA[Python3.8.0 Python Tutorial Python Standard Libary]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python使用总结]]></title>
    <url>%2F2020%2F05%2F20%2Fpython%2Fpyhton-usage%2F</url>
    <content type="text"><![CDATA[基于Python3 基础知识python3官方文档学习笔记 pip工具 PEP8官网文档PEP8中文]]></content>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[coverage-test]]></title>
    <url>%2F2020%2F02%2F10%2Ftest%2Fcoverage-test%2F</url>
    <content type="text"><![CDATA[参考1参考2]]></content>
      <tags>
        <tag>lcov</tag>
        <tag>gcov</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ps命令详解]]></title>
    <url>%2F2019%2F12%2F04%2Flinux%2Flinux-cmd-ps%2F</url>
    <content type="text"><![CDATA[概述ps命令支持三种不同类型的选项 UNIX选项，以 - 符号开头 BSD选项，不能包含 - GUN选项，以 -- 符号开头 不同类型的选项可以自由混合，但是有可能会产生冲突。 示例Unix模式显示系统中的所有process进程1234ps -eps -efps -eFps -ely BSD模式显示系统中的所有process进程12ps axps aux 树状显示系统中所有process进程123ps -ejHps axjfps -ef f 树状显示系统中的所有threads线程12ps -eLfps axms To get security info123ps -eo euser,ruser,suser,fuser,f,comm,labelps axZps -eM To see every process running as root (real &amp; effective ID) in user format1ps -U root -u root u To see every process with a user-defined format123ps -eo pid,tid,class,rtprio,ni,pri,psr,pcpu,stat,wchan:14,commps axo stat,euid,ruid,tty,tpgid,sess,pgrp,ppid,pid,pcpu,commps -Ao pid,tt,user,fname,tmout,f,wchan Print only the process IDs of syslogd1ps -C syslogd -o pid= Print only the name of PID 421ps -q 42 -o comm= 常用选项 选项 说明 -A -e 显示所有进程信息 -123 123 --pid pidlist -p pidlistp pidlist 显示pidlist中指定的所有pid的进程信息接受空白分隔或逗号分隔的列表形式的单个参数，如-p &quot;123,124&quot;或-p &quot;123 124&quot; -U userlist--User userlist 显示userlist中指定的RUID(real user id)或name的进程信息RUID表示create该进程的用户 U userlist-u userlist--user userlist 显示userlist中指定的EUID(effective user id)或name的进程信息EUID用于系统决定用户对文件资源的访问权限，一般情况下等同于RUID -f-F 显示所有的列，通常与其它unix格式选项联合使用使用该参数时会显示进程的命令参数信息与-L参数同时使用时，还会显示NLWP(number of threads)和LWP(thread id)信息 e 在命令列中最后显示进程的环境变量信息，如 ps -ef e f ASCII字符显示树状结构, 表示程序间的层次关系 -mm 显示进程中的线程信息 -L Show threads, possibly with LWP and NLWP columns o format-o format--format format 用户自定义格式。format可以是一个空白或逗号分割的列表，用于指定输出的列，支持的列表内容见输出列内容列的表头内容可以重命名 ps -o pid,ruser=RealUser列的表头可以忽略 ps -o pid=,comm= 上述中xxxlist的内容，表示接受空白分割或逗号分割的列表形式的单个参数 输出列内容]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux历史记录history配置]]></title>
    <url>%2F2019%2F11%2F27%2Flinux%2Flinux-history-config%2F</url>
    <content type="text"><![CDATA[history命令说明查看最近10条记录1history 10 重新执行某条历史命令1234!1000 # 执行第1000条历史命令!-2 # 执行倒数第二条历史命令!! # 执行上一条命令!string # 执行最近一条以string开头的命令 history配置可以通过设置某些环境变量，实现history的功能配置 环境变量 备注 HISTSIZE history保留历史命令的条数，如果配置为0，则不保留history HISTFILE 保存历史命令的文件，默认为 .bash_history HISTFILESIZE .bash_history中保留历史命令条数 HISTTIMEFORMAT history中显示时间格式，不配置则不显示 HISCONTROL 历史命令记录控制。\n ignoredups: 忽略连续重复的命令\n ignorespace: 忽略以空白字符开头的命令\n ignoreboth: 同时忽略以上两种\n erasedups: 忽略所有历史记录中重复的命令 HISTIGNORE 配置忽略指定命令， 如 HISTIGNORE=”pwd:ls:ls -ltr” 常用history配置12345678910111213141516171819# 修改 /etc/profile中历史记录最大条数sed -i 's/^HISTSIZE=1000/HISTSIZE=9999/g' /etc/profile# 在 .bashrc中增加以下配置# 获取操作者的ip信息USER_IP=`who -u am i 2&gt;/dev/null | awk '&#123;print $NF&#125;' | sed -e 's/[()]//g'`if [ "$USER_IP" = "" ]thenUSER_IP=`hostname`fi# 设置history命令时间格式(包含年月日，时分秒，操作者ip，操作者使用用户 信息)export HISTTIMEFORMAT="`whoami` %F %T $USER_IP "# 使能(-s) histappend配置，可以通过执行shopt命令查看当前各种配置的使能情况# 如果使能 histappend，表示在shell退出时将本shell中所有的历史记录追加到 HISTFILE 指定的文件中# 如果未使能 histappend，表示在shell退出时将历史记录覆盖指定文件# 通常该配置在 /etc/bashrc中存在，在 /root/.bashrc中会调用执行 /etc/bashrcshopt -s histappend# PROMPT_COMMAND中的内容为 在打印每个主提示符之前执行的命令PROMPT_COMMAND="history -a;history -c;history -r;$PROMPT_COMMAND" 清除history记录当打开一个session时，在该session中执行的命令会放在缓存中，当终端退出或关闭时，会将缓存中的内容写入HISTFILE指定的文件中。 当session被kill掉时，该session中缓存的命令，无法记录到HISTFILE指定文件。 清除当前session的命令1history -c 清除所有的历史记录1echo "" &gt; /root/.bash_history]]></content>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux-systemd]]></title>
    <url>%2F2019%2F11%2F24%2Flinux%2Flinux-systemd%2F</url>
    <content type="text"><![CDATA[systemd githubsystemd官网systemd man手册 参考1参考2参考3]]></content>
      <tags>
        <tag>systemd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git中ssl证书设置]]></title>
    <url>%2F2019%2F11%2F23%2Fgit%2Fgit-ssl-no-verify%2F</url>
    <content type="text"><![CDATA[忽略ssl证书1git config --global http.sslVerify false 某些场景(如在docker的构建环境中，不希望通过修改docker来忽略ssl校验)下，不方便使用上述命令设置忽略ssl校验时，可以通过设置环境变量 GIT_SSL_NO_VERIFY为 true 的方式进行忽略 指定ssl证书1git config --global http.sslCAPath /git/certificates 可以通过设置环境变量 GIT_SSL_CAPATH=/git/certificates 来指定证书路径]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[终止长时间运行的构建记录]]></title>
    <url>%2F2019%2F11%2F23%2Fjenkins%2Fjenkins-stop-longtime-builds%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819def timeThreshold = 200 // secondsdef jobs = Jenkins.instance.getAllItems(hudson.model.Job.class)jobs.each &#123; job -&gt; def builds = job.getBuilds() if(builds) &#123; builds.each &#123; if(it.isBuilding()) &#123; def duration = System.currentTimeMillis() - it.getStartTimeInMillis() if (duration &gt; timeThreshold * 1000) &#123; println("abort job:$&#123;job.name&#125; buildNum:$&#123;it.number&#125; duration:$&#123;duration&#125;ms") it.getExecutor().interrupt(hudson.model.Result.ABORTED) &#125; &#125; &#125; &#125; else &#123; println("$&#123;job.name&#125; don't have builder, skip...") &#125;&#125;]]></content>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins通过ssh方式连接执行机]]></title>
    <url>%2F2019%2F11%2F23%2Fjenkins%2Fjenkins-ssh-slave%2F</url>
    <content type="text"><![CDATA[连接过程 master通过ssh协议访问slave的sshd服务，先建立ssh连接 检查slave中的java程序及版本 拷贝最新的remoting.jar到slave中，如果slave中已经存在remoting.jar，则校验master与slave中jar的md5值是否一致，如果不一致则更新。 启动命令建立master与slave通信的专用通道，后续master向slave下发命令都是通过该通道进行。 slave中的连接日志保存在 ${slave_workspace}/remoting/logs 目录下，每次master与slave的连接都会生成一个 remoting.log.x 的日志文件master中的连接日志保存在 ${master_jenkins_home}/logs/slaves/${slave_name}/slave.log.x master上的连接日志如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475SSHLauncher&#123;host=&apos;192.168.43.150&apos;, port=22, credentialsId=&apos;test&apos;, jvmOptions=&apos;&apos;, javaPath=&apos;&apos;, prefixStartSlaveCmd=&apos;&apos;, suffixStartSlaveCmd=&apos;&apos;, launchTimeoutSeconds=210, maxNumRetries=10, retryWaitTime=15, sshHostKeyVerificationStrategy=hudson.plugins.sshslaves.verifiers.NonVerifyingKeyVerificationStrategy, tcpNoDelay=true, trackCredentials=true&#125;[11/23/19 17:28:18] [SSH] Opening SSH connection to 192.168.43.150:22.[11/23/19 17:28:18] [SSH] WARNING: SSH Host Keys are not being verified. Man-in-the-middle attacks may be possible against this connection.[11/23/19 17:28:24] [SSH] 认证成功。[11/23/19 17:28:24] [SSH] The remote user&apos;s environment is:BASH=/usr/bin/bashBASHOPTS=cmdhist:extquote:force_fignore:hostcomplete:interactive_comments:progcomp:promptvars:sourcepathBASH_ALIASES=()BASH_ARGC=()BASH_ARGV=()BASH_CMDS=()BASH_EXECUTION_STRING=setBASH_LINENO=()BASH_SOURCE=()BASH_VERSINFO=([0]=&quot;4&quot; [1]=&quot;2&quot; [2]=&quot;46&quot; [3]=&quot;2&quot; [4]=&quot;release&quot; [5]=&quot;x86_64-redhat-linux-gnu&quot;)BASH_VERSION=&apos;4.2.46(2)-release&apos;DIRSTACK=()EUID=0GROUPS=()HOME=/rootHOSTNAME=localhost.localdomainHOSTTYPE=x86_64IFS=$&apos; \t\n&apos;LANG=zh_CN.UTF-8LESSOPEN=&apos;||/usr/bin/lesspipe.sh %s&apos;LOGNAME=rootMACHTYPE=x86_64-redhat-linux-gnuMAIL=/var/mail/rootOPTERR=1OPTIND=1OSTYPE=linux-gnuPATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/binPIPESTATUS=([0]=&quot;0&quot;)PPID=18696PS4=&apos;+ &apos;PWD=/rootSELINUX_LEVEL_REQUESTED=SELINUX_ROLE_REQUESTED=SELINUX_USE_CURRENT_RANGE=SHELL=/bin/bashSHELLOPTS=braceexpand:hashall:interactive-commentsSHLVL=1SSH_CLIENT=&apos;192.168.43.150 53796 22&apos;SSH_CONNECTION=&apos;192.168.43.150 53796 192.168.43.150 22&apos;TERM=dumbUID=0USER=rootXDG_RUNTIME_DIR=/run/user/0XDG_SESSION_ID=21_=/etc/bashrc[11/23/19 17:28:24] [SSH] Checking java version of /data/workspace/jdk/bin/javaCouldn&apos;t figure out the Java version of /data/workspace/jdk/bin/javabash: /data/workspace/jdk/bin/java: 没有那个文件或目录[11/23/19 17:28:24] [SSH] Checking java version of java[11/23/19 17:28:24] [SSH] java -version returned 11.0.3.[11/23/19 17:28:24] [SSH] Starting sftp client.[11/23/19 17:28:24] [SSH] 正在拷贝最新版本的 remoting.jar...[11/23/19 17:28:24] [SSH] Copied 875,406 bytes.Expanded the channel window size to 4MB[11/23/19 17:28:24] [SSH] Starting agent process: cd &quot;/data/workspace&quot; &amp;&amp; java -jar remoting.jar -workDir /data/workspace -jar-cache /data/workspace/remoting/jarCache11月 23, 2019 5:28:26 下午 org.jenkinsci.remoting.engine.WorkDirManager initializeWorkDir信息: Using /data/workspace/remoting as a remoting work directory11月 23, 2019 5:28:26 下午 org.jenkinsci.remoting.engine.WorkDirManager setupLogging信息: Both error and output logs will be printed to /data/workspace/remoting&lt;===[JENKINS REMOTING CAPACITY]===&gt;channel startedRemoting version: 3.35This is a Unix agentWARNING: An illegal reflective access operation has occurredWARNING: Illegal reflective access by jenkins.slaves.StandardOutputSwapper$ChannelSwapper to constructor java.io.FileDescriptor(int)WARNING: Please consider reporting this to the maintainers of jenkins.slaves.StandardOutputSwapper$ChannelSwapperWARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operationsWARNING: All illegal access operations will be denied in a future releaseEvacuated stdoutAgent successfully connected and online 重连方法修改了slave的某些配置(如修改了tmpdir)后需要重新建立slave与master的连接，通过master上的Mark this node temporarily offline按钮时实现不了重连功能的。 通过 Disconnect 按钮进行断链，然后重新 Launch agent 重启执行机，执行机重启后，master会自动重连 执行Delete Agent删掉该执行机后重新添加该执行机 到执行机上杀掉对应进程，然后再master中再Launch agent 1234567[root@localhost ~]# ps -ef |grep remoting.jarroot 8015 7860 0 17:16 ? 00:00:00 bash -c cd "/data/workspace" &amp;&amp; java -jar remoting.jar -workDir /data/workspace -jar-cache /data/workspace/remoting/jarCacheroot 8020 8015 5 17:16 ? 00:00:08 java -jar remoting.jar -workDir /data/workspace -jar-cache /data/workspace/remoting/jarCacheroot 10188 5056 0 17:19 pts/0 00:00:00 grep --color=auto remoting.jar[root@localhost ~]# kill -9 8015[root@localhost ~]# ps -ef |grep remoting.jarroot 10552 5056 0 17:19 pts/0 00:00:00 grep --color=auto remoting.jar]]></content>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins执行机磁盘空间监控配置]]></title>
    <url>%2F2019%2F11%2F23%2Fjenkins%2Fjenkins-slave-space-config%2F</url>
    <content type="text"><![CDATA[概述Jenkins的master会监控执行机中的空间状态，当执行机中的空间不满足某个条件时会自动offline掉该执行机，该项配置的地方即为: http://192.168.43.150:8080/computer/configure Free Disk Space 指的是Jenkins_home所在磁盘的空间，默认阈值为1G。 Free Temp Space 检查的是 java.io.tmpdir 系统属性所指定的分区目录，任务运行过程中经常会在tmp目录中创建一些临时文件 通常情况下linux执行机中tmp目录指向的是/tmp目录，windows执行机中tmp目录指向的时C:\Users\${user_name}\AppData\Local\Temp\ 可以通过在执行机的script console中执行脚本 System.getProperty(“java.io.tmpdir”)查询当前执行机的tmpdir 当执行机中的空间不足又无法进行数据清理时，可以通过执行java的启动参数将tmp目录指定为数据盘所在目录，然后重新建立master与slave之间的连接即可。 SSH方式连接执行机tmp目录配置 1java -Djava.io.tmpdir=/data/tmp -jar remoting.jar -workDir /data/workspace -jar-cache /data/workspace/remoting/jarCache JNLP方式连接执行机tmp目录配置1java -Djava.io.tmpdir=d:/jenkins_workspace/tmp -jar agent.jar -jnlpUrl http://192.168.43.150:8080/computer/192.168.43.100/slave-agent.jnlp -secret 18ba424329d85b70fcf59f4e6aabf41614381867e5752b72a1f19bf6e6ce361c -workDir "d:/jenkins_workspace"]]></content>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker attach命令]]></title>
    <url>%2F2019%2F11%2F19%2Fdocker%2Fdocker-attach-cmd%2F</url>
    <content type="text"><![CDATA[docker attach命令可以将当前终端的标准输入、标准输出和标准错误连接到指定的容器中，这允许操作者查看其正在进行的输出或交互式地控制它，就像命令直接在终端中运行一样。 该命令显示的是容器 ENTRYPOINT/CMD 进程的输出, 执行该命令时有可能看起来像是hang住了，但是实际上进程可能没有与终端进行交互(输入内容到终端)。 可以在docker的宿主机不同session中同时执行多次attach命令。 退出attach方式CRTL+p CTRL+q 方式ctrl+p ctrl+q是默认的detach键序列(key sequence)，也可以通过--detach-keys string来覆盖默认的键序列。自定义的string可以是[a-Z]的字母或ctrl-与以下内容的任意组合: a-z (小写字母) @ [ \ _ ^ 这种方式要求容器运行(docker run)时必须同时指定 -i -t 参数。采用这种方式只是从容器中detach出来，不会停止容器的运行。 123456789101112131415161718########## session 1 ##########[root@localhost ~]# docker run -it centos:8 /bin/bash --login[root@a58c215443bd /]# ps -efUID PID PPID C STIME TTY TIME CMDroot 1 0 2 11:21 pts/0 00:00:00 /bin/bash --loginroot 18 1 0 11:21 pts/0 00:00:00 ps -ef[root@a58c215443bd /]########### session 2 ##########[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa58c215443bd centos:8 "/bin/bash --login" 13 seconds ago Up 10 seconds epic_haslett[root@localhost ~]# docker attach a58c[root@a58c215443bd /]# [ctrl+p ctrl+q] read escape sequence[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESa58c215443bd centos:8 "/bin/bash --login" 56 seconds ago Up 52 seconds epic_haslett[root@localhost ~]# 如果容器运行时未同时指定 -i -t 参数，CTRL+p CTRL+q 无效。 CTRL+c方式12--sig-proxy=true|false # 默认值 true Proxy all received signals to the process (non-TTY mode only). SIGCHLD, SIGKILL, and SIGSTOP are not proxied. 该选项仅在non-TTY模式下起作用，即docker run时不指定-t选项。此时，默认–sig-proxy为true，SIGINT信号被发送至docker中PID为1的进程。 CTRL+c 发送 SIGKILL 信号到容器。If –sig-proxy is true (the default),CTRL-c sends a SIGINT to the container 在容器中以PID 1运行的进程会被Linux特别处理:它会忽略任何带有默认操作的信号。因此，除非进行了相应的编码，否则进程不会在SIGINT或SIGTERM上终止。 –sig-proxy=true &amp;&amp; docker run -it交互式启动bash CTRL+C作用在attach的bash，对容器退出无效，在attach中输入exit时容器退出 12345678910111213141516########## 交互式启动bash时 session 1[root@localhost ~]# docker run -it centos:8 /bin/bash --loginWARNING: IPv4 forwarding is disabled. Networking will not work.[root@b9c822d1b3eb /]########### session 2[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESb9c822d1b3eb centos:8 "/bin/bash --login" 46 seconds ago Up 44 seconds sleepy_kepler[root@localhost ~]# docker attach b9c[root@b9c822d1b3eb /]# ^C[root@b9c822d1b3eb /]# exitlogout[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@localhost ~]# 交互式启动非bash时 CTRL+C对容器退出有效 123456789101112131415161718192021222324252627282930313233343536########## session 1[root@localhost ~]# docker run -it centos:8 top -btop - 12:46:53 up 4:28, 0 users, load average: 1.76, 1.75, 1.84Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombie%Cpu(s): 60.0 us, 40.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stMiB Mem : 991.2 total, 145.6 free, 466.6 used, 379.1 buff/cacheMiB Swap: 1024.0 total, 841.5 free, 182.5 used. 383.2 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 48264 1980 1464 R 20.0 0.2 0:00.05 top########## session 2[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES0fb225d37701 centos:8 "top -b" 23 seconds ago Up 20 seconds confident_turing[root@localhost ~]# docker attach 0fbtop - 12:47:25 up 4:28, 0 users, load average: 2.22, 1.86, 1.88Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombie%Cpu(s): 39.5 us, 42.0 sy, 0.0 ni, 16.6 id, 0.0 wa, 0.0 hi, 1.9 si, 0.0 stMiB Mem : 991.2 total, 146.1 free, 465.8 used, 379.3 buff/cacheMiB Swap: 1024.0 total, 841.5 free, 182.5 used. 384.0 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 48264 1980 1464 R 0.0 0.2 0:00.06 toptop - 12:47:25 up 4:28, 0 users, load average: 2.22, 1.86, 1.88Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombie%Cpu(s): 66.7 us, 33.3 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stMiB Mem : 991.2 total, 146.1 free, 465.8 used, 379.3 buff/cacheMiB Swap: 1024.0 total, 841.5 free, 182.5 used. 384.0 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 48264 1980 1464 R 0.0 0.2 0:00.06 top^C[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@localhost ~]# –sig-proxy=true &amp;&amp; docker run -d交互式启动非bash时 CTRL+C对容器退出有效 123456789101112131415161718[root@localhost ~]# docker run -d centos:8 top -b645242bbe8be193008f3794b4d9eb5dd88274da8b6b882743ec1c3c232d96a59[root@localhost ~]#[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES645242bbe8be centos:8 "top -b" 6 seconds ago Up 4 seconds happy_moser[root@localhost ~]# docker attach 645top - 12:52:15 up 4:33, 0 users, load average: 2.04, 1.93, 1.89Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombie%Cpu(s): 22.7 us, 29.5 sy, 0.0 ni, 46.0 id, 0.0 wa, 0.0 hi, 1.8 si, 0.0 stMiB Mem : 991.2 total, 143.9 free, 465.4 used, 381.9 buff/cacheMiB Swap: 1024.0 total, 841.5 free, 182.5 used. 384.3 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 48264 1976 1464 R 0.3 0.2 0:00.07 top^C[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@localhost ~]# –sig-proxy=false &amp;&amp; docker run -it交互式启动bash时 CTRL+C对容器退出无效，在attach中输入exit时容器退出 12345678910111213141516########## session 1[root@localhost ~]# docker run -it centos:8 /bin/bash --loginWARNING: IPv4 forwarding is disabled. Networking will not work.[root@308cd9572fe2 /]########### session 2[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES308cd9572fe2 centos:8 "/bin/bash --login" 7 seconds ago Up 6 seconds elated_tharp[root@localhost ~]# docker attach --sig-proxy=false 308[root@308cd9572fe2 /]# ^C[root@308cd9572fe2 /]# exitlogout[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES[root@localhost ~]# –sig-proxy=false &amp;&amp; docker run -d交互式启动非bash时 CTRL+C对容器退出无效 12345678910111213141516[root@localhost ~]# docker run -d centos:8 top -b5cb4252610b412f1301b6d1561d3958edd79da20a22dbb65b8697ec5361ee25a[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES5cb4252610b4 centos:8 "top -b" 7 seconds ago Up 6 seconds focused_perlman[root@localhost ~]# docker attach --sig-proxy=false 5cbtop - 12:26:40 up 4:07, 0 users, load average: 2.61, 2.24, 2.05Tasks: 1 total, 1 running, 0 sleeping, 0 stopped, 0 zombie%Cpu(s): 23.2 us, 30.5 sy, 0.0 ni, 44.2 id, 0.0 wa, 0.0 hi, 2.1 si, 0.0 stMiB Mem : 991.2 total, 140.7 free, 465.7 used, 384.7 buff/cacheMiB Swap: 1024.0 total, 843.2 free, 180.8 used. 384.2 avail Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 1 root 20 0 48264 1980 1464 R 0.3 0.2 0:00.07 top^C[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7下docker配置user-namespace后启动容器失败]]></title>
    <url>%2F2019%2F11%2F17%2Fdocker%2Fcentos7-user-namespace-runtime-error%2F</url>
    <content type="text"><![CDATA[运行环境:os: CentOS Linux release 7.6.1810 (Core)docker: 19.03.4 错误提示123[root@localhost ~]# docker run -it --rm centos:8 /bin/bash --logindocker: Error response from daemon: OCI runtime create failed: container_linux.go:346: starting container process caused "process_linux.go:319: getting the final child's pid from pipe caused \"EOF\"": unknown.[root@localhost ~]# 原因redhat7.4版本的release notes中说明7.4版本已经支持了user namespace特性，但是 user.max_user_namespace 的默认值是0。如果要使用user namespace功能需要修改该默认值。 同时7.4版本中将非特权用户的user namespace功能设置为了技术预览。可以通过配置内核启动参数 namespace.unpriv_enable=1 来打开该功能。设置了该功能后，非特权用户通过传递CLONE_NEWNS选项来调用 clone() 时不再返回错误而是允许该操作。 However, to enable the unprivileged access to name spaces, the CAP_SYS_ADMIN flag has to be set in some user name space to create a mount name space 解决方法设置max_user_namespace123456789#方法一echo 15000 &gt; /proc/sys/user/max_user_namespace#方法二sysctl -w 15000 user.max_user_namespace#方法三echo "user.max_user_namespaces=15000" &gt;&gt; /etc/sysctl.confreboot 方法一和方法二重启后配置会丢失 设置namespace.unpriv_enable123# 打开namespace.unpriv_enablesudo grubby --args="namespace.unpriv_enable=1 user_namespace.enable=1" --update-kernel="$(grubby --default-kernel)"reboot 执行该命令前 /boot/grub2/grub.cfg 部分内容如下 123456789101112131415menuentry &apos;CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core)&apos; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option &apos;gnulinux-3.10.0-957.el7.x86_64-advanced-76bc0bdb-c41f-47f8-aae1-72561c04faa5&apos; &#123; load_video set gfxpayload=keep insmod gzio insmod part_msdos insmod xfs set root=&apos;hd0,msdos1&apos; if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1 --hint=&apos;hd0,msdos1&apos; 6904b786-8e67-448b-9eac-2c768f1f9aa6 else search --no-floppy --fs-uuid --set=root 6904b786-8e67-448b-9eac-2c768f1f9aa6 fi linux16 /vmlinuz-3.10.0-957.el7.x86_64 root=/dev/mapper/centos-root ro crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet LANG=zh_CN.UTF-8 initrd16 /initramfs-3.10.0-957.el7.x86_64.img&#125; 执行该命令后 123456789101112131415menuentry &apos;CentOS Linux (3.10.0-957.el7.x86_64) 7 (Core)&apos; --class centos --class gnu-linux --class gnu --class os --unrestricted $menuentry_id_option &apos;gnulinux-3.10.0-957.el7.x86_64-advanced-76bc0bdb-c41f-47f8-aae1-72561c04faa5&apos; &#123; load_video set gfxpayload=keep insmod gzio insmod part_msdos insmod xfs set root=&apos;hd0,msdos1&apos; if [ x$feature_platform_search_hint = xy ]; then search --no-floppy --fs-uuid --set=root --hint-bios=hd0,msdos1 --hint-efi=hd0,msdos1 --hint-baremetal=ahci0,msdos1 --hint=&apos;hd0,msdos1&apos; 6904b786-8e67-448b-9eac-2c768f1f9aa6 else search --no-floppy --fs-uuid --set=root 6904b786-8e67-448b-9eac-2c768f1f9aa6 fi linux16 /vmlinuz-3.10.0-957.el7.x86_64 root=/dev/mapper/centos-root ro crashkernel=auto rd.lvm.lv=centos/root rd.lvm.lv=centos/swap rhgb quiet LANG=zh_CN.UTF-8 namespace.unpriv_enable=1 user_namespace.enable=1 initrd16 /initramfs-3.10.0-957.el7.x86_64.img&#125; 123# 关闭namespace.unpriv_enablesudo grubby --remove-args="namespace.unpriv_enable=1 user_namespace.enable=1" --update-kernel="$(grubby --default-kernel)"reboot]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker配置使用User Namespace]]></title>
    <url>%2F2019%2F11%2F17%2Fdocker%2Fdocker-user-namespace%2F</url>
    <content type="text"><![CDATA[官方文档 概述docker容器运行时，默认情况下容器内进程的运行用户就是docker host上的root用户，这样运行时如果将host中的某些目录挂载到容器中时，容器内的进程拥有这些目录的所有权限，这样时不安全的。 解决方法有两种，一种是使用非root用户运行容器，另一种就是使用下面讲的user namespace方式。 Linux的user namespace可以对运行的进程做用户隔离，在这些进程不感知的情况下，限制它们对系统资源的访问。可以通过Linux的user namespace功能，将容器内的root用户映射为docker host中的低权限用户。 docker启用user namespace docker在1.10(2016-02-04)版本中才实现了使用user namespace的功能，称之为 userns-remap 首先在docker host中创建用户和组 1234[root@localhost ~]# groupadd -g 5000 dockertest[root@localhost ~]# useradd -u 5000 -g dockertest dockertest[root@localhost ~]# id dockertestuid=5000(dockertest) gid=5000(dockertest) groups=5000(dockertest) 修改docker host中的 /etc/subuid 和 /etc/subgid 配置 123456[root@localhost ~]# cat /etc/subuiddockertest:5000:1 # 容器中root用户(uid=0)映射为docker host中的uid为5000的用户dockertest:100000:65535 # 容器中的用户 1 ~ 65536 映射为 host中的 uid 为 100000 ~ 100000+65535[root@localhost ~]# cat /etc/subgiddockertest:5000:1 # 同subuiddockertest:100000:65535 # 同subuid 也可以直接配置dockertest:100000:65536，这样的话，容器的root映射为host的uid=100000的用户 修改/etc/docker/daemon.json文件，增加 &quot;userns-remap&quot;:&quot;dockertest&quot; 配置，然后重启docker服务 启动容器进行检查 1234567891011121314[root@localhost ~]# docker run -d --rm centos:8 sleep 300152a7eed420e3d84eefebf1fadc1f1f9d8cfa2fd607d59c03a806d822f5e57d3[root@localhost ~]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES152a7eed420e centos:8 "sleep 300" 6 seconds ago Up 3 seconds jovial_sutherland[root@localhost ~]# ps -ef |grep -i sleepdockert+ 12387 12371 0 20:20 ? 00:00:00 /usr/bin/coreutils --coreutils-prog-shebang=sleep /usr/bin/sleep 300[root@localhost ~]# cat /proc/12387/uid_map 0 5000 1 # 将host 上的 5000 用户映射为容器内的 0(root)用户 1 100000 65535 # 将host 上的 100000 用户映射为容器内的 1 用户[root@localhost ~]# cat /proc/12387/gid_map 0 5000 1 1 100000 65535[root@localhost ~]# docker使用userns-remap时，在docker_home目录下会自动创建一个5000.5000(根据实际情况会有变化)的目录 在修改daemon.json文件时，可以将userns-remap的值设置为已经存在的用户。也可以指定为默认值(default)，如果指定为 default，那么会自动创建用户和组 dockremap。如果使用default配置，RHEL/centos不会自动将 dockremap 添加到 /etc/subuid 和 /etc/subgid 中，需要手动添加。 容器中禁用namespace映射当docker daemon启用了user namespace后，所有启动的容器默认都会使用user namespace功能。 此时如果想要禁用容器的user namespace(如想要启动一个具有特权的容器)，可以在docker create/docker run/docker exec命令中增加 --userns=host 选项实现。 使用 --userns=host 选项时，不会为该容器进行用户映射，但是由于容器之间共享read-only(image) layers，容器的文件系统所有者仍然会映射为daemon中配置userns-remap用户。这样可能会导致容器内某些程序运行时出现一些意外，For instance sudo (which checks that its binaries belong to user 0) or binaries with a setuid flag。 docker使用user namespace的限制当docker启用user namespace时，会与docker的下面的一些特性无法兼容: sharing PID or NET namespaces with the host(–pid=host or –network=host) external (volume or storage) drivers which are unaware or incapable of using daemon user mappings Using the –privileged mode flag on docker run without also specifying –userns=host。(docker run中使用了–privileged但是没有使用–userns=host) 常见问题检查Linux内核是否开启了user namespace功能 首先确认内核版本，linux是在内核3.8开始才引入了user namespace功能 查看内核编译选项 12[root@localhost ~]# cat /boot/config-$(uname -r) |grep -i config_user_nsCONFIG_USER_NS=y CentOS7配置userns-remap后启动容器失败]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker中的用户说明]]></title>
    <url>%2F2019%2F11%2F17%2Fdocker%2Fdocker-uid-gid%2F</url>
    <content type="text"><![CDATA[以下内容适用于docker未使用的user namespace的情况 linux系统中的uid和gid是由内核负责管理的，而且内核管理是使用的是id不是name。同一台宿主机中运行的不同的docker和宿主机共享同一个内核，所以所有的docker中的uid和gid的管理和宿主机也都是一致的。即docker中的uid为1000的用户和宿主机中uid为1000的用户实质上是同一个用户。默认情况下docker启动时，都是采用的root账号，相当于容器中的应用对宿主机有完全的控制权限，这种做法时不安全的，所以需要对容器运行时指定一个具有合适权限的用户。 不同docker之间以及docker和宿主机中同一个uid可能对应不同的的用户名称，这是因为uid到用户名的解析(用户态程序)不同而已。 指定docker运行使用的用户Dockerfile中使用USER命令指定下面是jenkins的dockerfile中关于USER使用的节选 123456789101112131415161718192021# ......ARG user=jenkinsARG group=jenkinsARG uid=1000ARG gid=1000# Jenkins is run with user `jenkins`, uid = 1000# If you bind mount a volume from the host or a data container,# ensure you use the same uidRUN mkdir -p $JENKINS_HOME \ &amp;&amp; chown $&#123;uid&#125;:$&#123;gid&#125; $JENKINS_HOME \ &amp;&amp; groupadd -g $&#123;gid&#125; $&#123;group&#125; \ &amp;&amp; useradd -d "$JENKINS_HOME" -u $&#123;uid&#125; -g $&#123;gid&#125; -m -s /bin/bash $&#123;user&#125;# ......RUN chown -R $&#123;user&#125; "$JENKINS_HOME" "$REF"# .....USER $&#123;user&#125;# ...... docker run 命令行参数中指定用户1docker run -d --user 1000 ubuntu sleep infinity]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git中的换行符配置]]></title>
    <url>%2F2019%2F11%2F17%2Fgit%2Fgit-crlf%2F</url>
    <content type="text"><![CDATA[Dos/Windows系统中的换行符使用的是0x0D0A(CRLF)，而unix/linux/mac系统中使用的换行符为0x0A(LF)。 autocrlfgit提供了一个autocrlf的配置项，用于提交和检出时自动替换换行符，它的可选项有: true: 提交时转换为linux格式 LF，检出时转换为windows格式 CRLF (windows版本git工具安装时默认采用本选项) false: 提交检出均不转换 input： 提交时转换为linux格式 LF，检出时不转换 12345678# 提交时转换为LF，检出时转换为CRLFgit config --global core.autocrlf true# 提交时转换为LF，检出时不转换git config --global core.autocrlf input# 提交检出均不转换git config --global core.autocrlf false safecrlf如果把 autocrlf 选项配置成了 false，建议将 safecrlf 选项配置为 true。 safecrlf 选项用于检查提交的文件中包含混合换行符，可选项有: true: 拒绝提交包含混合换行符的文件 false: 允许提交包含混合换行符的文件 warn: 提交包含混合换行符的文件时进行告警 12345678# 拒绝提交包含混合换行符的文件git config --global core.safecrlf true# 允许提交包含混合换行符的文件git config --global core.safecrlf false# 提交包含混合换行符的文件时给出警告git config --global core.safecrlf warn windows的git命令行中提供了 dos2unix 工具可进行换行符转换。 多平台开发时的建议12git config --global core.autocrlf inputgit config --global core.safecrlf true]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins的日志配置]]></title>
    <url>%2F2019%2F11%2F15%2Fjenkins%2Fjenkins-log-config%2F</url>
    <content type="text"><![CDATA[use a post initialization scriptjenkins支持在启动后立即运行指定脚本(${JENKINS_HOME/init.groovy} 或 ${JENKINS_HOME}/init.groovy.d/*.groovy)，脚本可以访问Jenins中的类和所有插件。可以利用这个特性来实现日志配置 12345import java.util.logging.Levelimport java.util.logging.LoggerLogger.getLogger("hudson.plugins.git.GitStatus").setLevel(Level.SEVERE)Logger.getLogger("hudson.security.csrf.CrumbFilter").setLevel(Level.SEVERE) use java.util.logging创建一个logging.properties文件，里面包含日志记录的配置，然后通过增加JVM选项-Djava.util.logging.config.file=&lt;pathTo&gt;/logging.properties 来生效配置 这种方式只支持使用了 java.util.logging 来记录日志的classes，如果某些classes使用了其他日志功能（如 org.apache.commons.logging）则不会生效 1234567891011handlers=java.util.logging.ConsoleHandler,java.util.logging.FileHandlerjava.util.logging.FileHandler.level=INFOjava.util.logging.FileHandler.formatter=java.util.logging.SimpleFormatterjava.util.logging.FileHandler.pattern=/var/log/jenkins/jenkins.logjava.util.logging.FileHandler.append=truejava.util.logging.FileHandler.limit=10000000java.util.logging.FileHandler.count=5java.util.logging.ConsoleHandler.level=INFOjava.util.logging.ConsoleHandler.formatter=java.util.logging.SimpleFormatter 使用linux的logrotatelogrotate是个十分有用的工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。 Logrotate是基于CRON来运行的，其脚本是/etc/cron.daily/logrotate。 logrotate的配置文件是/etc/logrotate.conf，通常不需要对它进行修改。日志文件的轮循设置在独立的配置文件中，它们放在/etc/logrotate.d/目录下。 /etc/logrotate.d/jenkins文件配置如下: 1234567891011121314/var/jenkins_home/logs/jenkins.log &#123; daily //日志文件轮循周期。可用值为‘daily’，‘weekly’或者‘yearly’ rotate 5 //最多将存储5个归档日志。对于第六个归档，时间最久的归档将被删除 dataext //旧日志文件以创建日期命名 compress //在轮循任务完成后，已轮循的归档将使用gzip进行压缩 delaycompress //总是与compress选项一起用，delaycompress选项指示logrotate不要将最近的归档压缩，压缩将在下一次轮循周期进行。这在你或任何软件仍然需要读取最新归档时很有用。 missingok //在日志轮循期间，任何错误将被忽略，例如“文件无法找到”之类的错误 notifempty //如果日志文件为空，轮循不会进行 size 100k //当日志文件到达指定的大小时才转储，log-size能指定bytes(缺省)及KB (sizek)或MB(sizem) create 644 root root //mode owner group 转储文件，使用指定的文件模式创建新的日志文件 postrotate //在logrotate转储之后需要执行的指令，例如重新启动 (kill -HUP) 某个服务 必须独立成行 /usr/bin/killall -HUP rsyslogd endscript&#125; 值得注意的一个配置是：copytruncate copytruncate 如果没有这个选项的话，操作方式：是将原log日志文件，移动成类似log.1的旧文件， 然后创建一个新的文件。 如果设置了，操作方式：拷贝原日志文件，并且将其变成大小为0的文件。 区别是如果进程,比如nginx 使用了一个文件写日志，没有copytruncate的话，切割日志时， 把旧日志log-&gt;log.1 ，然后创建新日志log。这时候nginx 打开的文件描述符依然时log.1，由没有信号通知nginx 要换日志描述符，所以它会继续向log.1写日志，这样就不符合我们的要求了。 因为我们想切割日志后，nginx 自动会向新的log 文件写日志，而不是旧的log.1文件 解决方法有两个： 1.向上面的nginx 切割日志配置，再postrotate里面写个脚本 postrotate [ -s /run/nginx.pid ] &amp;&amp; kill -USR1 cat /run/nginx.pidendscript 这样就是发信号给nginx ,让nginx 关闭旧日志文件描述符，重新打开新的日志文件描述，并写入日志 2.使用copytruncate参数，向上面说的，配置了它以后，操作方式是把log 复制一份 成为log.1，然后清空log的内容，使大小为0，那此时log依然时原来的旧log，对进程（nginx）来说，依然打开的是原来的文件描述符，可以继续往里面写日志，而不用发送信号给nginx copytruncate这种方式操作的时候， 拷贝和清空之间有一个时间差，可能会丢失部分日志数据。 nocopytruncate 备份日志文件不过不截断。]]></content>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改Jenkins Home]]></title>
    <url>%2F2019%2F11%2F14%2Fjenkins%2Fjenkins-change-home%2F</url>
    <content type="text"><![CDATA[修改 JENKINS_HOME 前必须先停止jenkins服务，修改后将原来 jenkins home目录中的数据copy到新目录，然后重启服务。 使用war启动jenkins直接通过 java -DJENKINS_HOME=/var/jenkins_home -jar jenkins.war 指定 -DJENKINS_HOME 选项即可 centos使用rpm安装或yum安装通过修改 /etc/sysconfig/jenkins 配置文件中的 JENKINS_HOME 配置 docker容器化安装通过在 docker run 中增加 -e JENKINS_HOME=xxxx 环境变量来修改]]></content>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker重启策略]]></title>
    <url>%2F2019%2F11%2F14%2Fdocker%2Fdocker-restart-policies%2F</url>
    <content type="text"><![CDATA[使用在 docker run 命令中通过指定 --restart=xxx 选项来指定容器在退出时的重启策略。 Docker容器的重启动作都是由Docker守护进程完成的。 重启策略 策略 说明 no 默认值，当容器退出时不会重启 on-failure[:max-retries] 在容器为非正常退出(退出状态为非0)时才会重启，可以指定最大重启次数 always 不管容器退出状态为什么，总是重启容器，当指定该值时，守护进程总是会在进程启动后启动容器 unless-stopped 无论退出状态如何，总是重启容器，除非容器在Docker守护进程停止之前进入了停止状态。 每次重启时，docker都会按照 100ms 200ms 400ms 800ms 1600ms … 的规律增加等待延时，直到达到on-failure的最大次数或者docker停止或通过docker rm -f 删除容器。 如果容器重新启动成功(容器启动并运行至少10秒)，则延迟将重置为其默认值100 ms。 可以通过docker inspect获得容器(尝试)重新启动的次数。例如，获取容器“my-container”的重启次数 1docker inspect -f "&#123;&#123; .RestartCount &#125;&#125;" my-container docker run 命令中 --restart=xxx 和 --rm 选项时互斥的，不能同时指定 容器只有在成功启动后restart policy才能生效。这里的”成功启动”是指容器处于up至少10秒且已经处于docker监管。这是避免没有成功启动的容器陷入restart的死循环。 如果手动stop一个容器，容器设置的restart policy将会被忽略，除非docker守护进程重启或者容器手动重启；这是避免了如果重启策略设置了always，如果不忽略policy那么容器无法手动停止。 更新重启策略1docker update --restart=no my-container 当需要彻底删除一个指定always策略的容器时，必须先更新重启策略为no，然后在停止和删除容器。]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker配置代理]]></title>
    <url>%2F2019%2F11%2F11%2Fdocker%2Fdocker-set-proxy%2F</url>
    <content type="text"><![CDATA[systemd中，创建 /etc/systemd/system/docker.service.d/http-proxy.conf 文件，增加如下配置 12[Service]Environment=&quot;HTTP_PROXY=http://proxy.example.com:80/&quot; &quot;HTTPS_PROXY=https://proxy.example.com:443/&quot; &quot;NO_PROXY=localhost,127.0.0.1,docker-registry.example.com,&quot;]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker配置文件常用配置]]></title>
    <url>%2F2019%2F11%2F11%2Fdocker%2Fdocker-config-file%2F</url>
    <content type="text"><![CDATA[默认配置文件为: /etc/docker/daemon.json, 如果该文件不存在，需要自己创建 官方配置文件说明 常用配置如下 12345678910&#123; "graph": "/data/docker_home", // 配置docker默认root目录，该配置19.03.0版本已废弃，计划19.09.0版本删除 "data-root": "/data/docker_home", // 配置docker默认root目录 "registry-mirrors": [ //配置docker镜像源 "https://registry.docker-cn.com", // Docker 官方镜像中国区 "http://hub-mirror.c.163.com", // 网易镜像源 "https://docker.mirrors.ustc.edu.cn"], // 中科大镜像源 "insecure-registries": [], // 配置非安全的镜像仓库(私有仓库)，通常公司内部镜像源配置在此处 "debug": true, //启动debug模式，默认为 false&#125; insecure-registries中定义的私有仓库如果端口号不为 80 , 则必须指定端口号使用 docker pull 拉取镜像时必须和 insecure-registers 中定义的完全一致(包括端口号)]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改docker默认root目录]]></title>
    <url>%2F2019%2F11%2F11%2Fdocker%2Fchange-docker-dir%2F</url>
    <content type="text"><![CDATA[方法一 停止服务 systemctl stop docker 修改docker服务配置文件/usr/lib/systemd/system/docker.service 12# 启动命令配置中，增加 --data-root 配置ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --data-root=/data/docker_home 同步原来的数据到新目录 rsync -aqxP /var/lib/docker/ /data/docker_home/ 删除原来目录 rm -rf /var/lib/docker/ 重新加载配置 systemctl daemon-reload 启动服务 systemctl start docker 方法二 停止服务 systemctl stop docker 修改配置文件 /etc/docker/daemon.json 12345678// 增加 graph 或 data-root 配置&#123; "graph": "/data/docker_home" // 不推荐使用, 该配置19.03.0版本已废弃，计划19.09.0版本删除&#125;&#123; "data-root": "/data/docker_home"&#125; 同步原来的数据到新目录 rsync -aqxP /var/lib/docker/ /data/docker_home/ 删除原来目录 rm -rf /var/lib/docker/ 重新加载配置 systemctl daemon-reload 启动服务 systemctl start docker]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker使用总结]]></title>
    <url>%2F2019%2F11%2F11%2Fdocker%2Fdocker-usage%2F</url>
    <content type="text"><![CDATA[官方文档CentOS下安装dockerdocker常见配置说明 docker可执行文件: /usr/bin/dockerd docker服务配置文件: /usr/lib/systemd/system/docker.service docker配置文件: /etc/docker/daemon.json docker存储默认目录: /var/lib/docker 修改docker存储的默认路径docker配置文件常用设置docker代理配置dockerd命令详解docker重启策略docker中的用户说明docker中使用user namespace常用命令删除所有容器1docker ps -a |awk '&#123;print $1&#125;'|tail -n +2 |xargs -t -n 1 docker rm -f docker attach命令]]></content>
      <tags>
        <tag>总结</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos下docker安装]]></title>
    <url>%2F2019%2F11%2F11%2Fcentos%2Fcentos-docker-install%2F</url>
    <content type="text"><![CDATA[CentOS7.6 卸载老版本 12345678yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-engine 安装所需依赖 123yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 配置repo 123yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo 安装docker 1yum install docker-ce docker-ce-cli containerd.io]]></content>
      <tags>
        <tag>centos</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清理Jenkins中所有任务的历史记录]]></title>
    <url>%2F2019%2F11%2F08%2Fjenkins%2Fjenkins-clear-jobs-history%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233def jobRetain = 3 // job 保留的历史记录数量// Jenkins.instance.getClass(): hudson.model.Hudson// 获取所有freestyle的jobjobs = Jenkins.instance.getAllItems(AbstactProject.class)println(jobs)// 获取所有pipeline的jobjobs = Jenkins.instance.getAllItems(org.jenkinsci.plugins.workflow.job.WorkflowJob.class)println(jobs)// 获取所有的jobjobs = Jenkins.instance.getAllItems(hudson.model.Job.class)println(jobs)jobs.each &#123; job -&gt; def builds = job.getBuilds() println(builds) if(builds) &#123; def latestBuildNumber = job.getLastBuild().getNumber() def retainMaxNumber = latestBuildNumber - jobRetain println("$&#123;job.name&#125;'s last build number: $&#123;latestBuildNumber&#125;") if (retainMaxNumber &lt;= 0) &#123; println("$&#123;job.name&#125;'s last build is less than $&#123;jobRetain&#125;, skip...") return &#125; println(builds.getClass()) job.getBuilds().findAll&#123;it.number &lt;= retainMaxNumber&#125;.each &#123; // it.getClass(): org.jenkinsci.plugins.workflow.job.WorkflowRun println("delete $&#123;job.name&#125;'s $&#123;it.number&#125;") it.delete() &#125; &#125; else &#123; println("$&#123;job.name&#125; don't have builder, skip...") &#125;&#125; 执行日志如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677Started by user unknown or anonymousRunning in Durability level: MAX_SURVIVABILITY[Pipeline] Start of Pipeline[Pipeline] echo[hudson.model.FreeStyleProject@5aab9184[jenkins_shell_test], com.tikal.jenkins.plugins.multijob.MultiJobProject@ce9939f[multijob_test], hudson.model.FreeStyleProject@12b9358a[no_build_job]][Pipeline] echo[org.jenkinsci.plugins.workflow.job.WorkflowJob@10dabbd8[clear_history], org.jenkinsci.plugins.workflow.job.WorkflowJob@4e79153f[pipeline_shell_test]][Pipeline] echo[org.jenkinsci.plugins.workflow.job.WorkflowJob@10dabbd8[clear_history], hudson.model.FreeStyleProject@5aab9184[jenkins_shell_test], com.tikal.jenkins.plugins.multijob.MultiJobProject@ce9939f[multijob_test], hudson.model.FreeStyleProject@12b9358a[no_build_job], org.jenkinsci.plugins.workflow.job.WorkflowJob@4e79153f[pipeline_shell_test]][Pipeline] echo[clear_history #24, clear_history #23, clear_history #22, clear_history #21, clear_history #20, clear_history #19, clear_history #18, clear_history #17, clear_history #16, clear_history #15, clear_history #14][Pipeline] echoclear_history&apos;s last build number: 24[Pipeline] echoclass hudson.util.RunList[Pipeline] echodelete clear_history&apos;s 21[Pipeline] echodelete clear_history&apos;s 20[Pipeline] echodelete clear_history&apos;s 19[Pipeline] echodelete clear_history&apos;s 18[Pipeline] echodelete clear_history&apos;s 17[Pipeline] echodelete clear_history&apos;s 16[Pipeline] echodelete clear_history&apos;s 15[Pipeline] echodelete clear_history&apos;s 14[Pipeline] echo[jenkins_shell_test #7, jenkins_shell_test #6, jenkins_shell_test #5, jenkins_shell_test #4, jenkins_shell_test #3, jenkins_shell_test #2, jenkins_shell_test #1][Pipeline] echojenkins_shell_test&apos;s last build number: 7[Pipeline] echoclass hudson.util.RunList[Pipeline] echodelete jenkins_shell_test&apos;s 4[Pipeline] echodelete jenkins_shell_test&apos;s 3[Pipeline] echodelete jenkins_shell_test&apos;s 2[Pipeline] echodelete jenkins_shell_test&apos;s 1[Pipeline] echo[multijob_test #3, multijob_test #2, multijob_test #1][Pipeline] echomultijob_test&apos;s last build number: 3[Pipeline] echomultijob_test&apos;s last build is less than 3, skip...[Pipeline] echo[][Pipeline] echono_build_job don&apos;t have builder, skip...[Pipeline] echo[pipeline_shell_test #91, pipeline_shell_test #90, pipeline_shell_test #89, pipeline_shell_test #88, pipeline_shell_test #87, pipeline_shell_test #86, pipeline_shell_test #85, pipeline_shell_test #84, pipeline_shell_test #83, pipeline_shell_test #82][Pipeline] echopipeline_shell_test&apos;s last build number: 91[Pipeline] echoclass hudson.util.RunList[Pipeline] echodelete pipeline_shell_test&apos;s 88[Pipeline] echodelete pipeline_shell_test&apos;s 87[Pipeline] echodelete pipeline_shell_test&apos;s 86[Pipeline] echodelete pipeline_shell_test&apos;s 85[Pipeline] echodelete pipeline_shell_test&apos;s 84[Pipeline] echodelete pipeline_shell_test&apos;s 83[Pipeline] echodelete pipeline_shell_test&apos;s 82[Pipeline] End of PipelineFinished: SUCCESS]]></content>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态替换map中的变量]]></title>
    <url>%2F2019%2F11%2F02%2Fgroovy%2Fgroovy-repalce-param-in-yaml%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728def replaceVariableInMap(def oriValue, def key, def value) &#123; if (oriValue instanceof String) &#123; return oriValue.replace("\$&#123;$&#123;key&#125;&#125;", value.toString()) &#125; else if (oriValue instanceof List) &#123; def tmpList = [] oriValue.each &#123; cf -&gt; tmpList.add(replaceVariableInMap(cf, key, value)) &#125; return tmpList &#125; else if (oriValue instanceof Map) &#123; def tmpMap = [:] oriValue.each &#123; k, v-&gt; tmpMap.put(k, replaceVariableInMap(v, key, value)) &#125; return tmpMap &#125; else &#123; return oriValue &#125;&#125;def testMap = [general: [branch: "\$&#123;branch&#125;"], stages: [tasks: [repos: [url: "\$&#123;url&#125;", branch: "\$&#123;branch&#125;", id: "domain"]]]]def params = [branch: "test_branch", url: "https://git.test.com"]params.each &#123;k, v -&gt; testMap = replaceVariableInMap(testMap, k, v)&#125;println testMap]]></content>
      <tags>
        <tag>groovy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[脚本式pipeline中failFast使用]]></title>
    <url>%2F2019%2F11%2F02%2Fjenkins%2Fjenkins-script-pipeline-failfast%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122def generateJobStage(String jobName) &#123; return &#123; node('master') &#123; echo "$&#123;jobName&#125; start" sleep 5 sh "exit 1" echo "job end" &#125; &#125;&#125;script &#123; def jobs = ['jobA', 'jobB', 'jobC'] def parallelStagesMap = jobs.collectEntries &#123; def jobName -&gt; ["$&#123;jobName&#125;", generateJobStage(jobName)] &#125; parallelStagesMap.failFast = true println parallelStagesMap stage("test") &#123; parallel parallelStagesMap &#125;&#125;]]></content>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pipeline中任务分段日志获取]]></title>
    <url>%2F2019%2F10%2F22%2Fjenkins%2Fjenkins-pipeline-stage-log%2F</url>
    <content type="text"><![CDATA[脚本式pipeline12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import hudson.model.Actionimport org.jenkinsci.plugins.workflow.cps.nodes.StepStartNodeimport org.jenkinsci.plugins.workflow.graph.FlowNodeimport org.jenkinsci.plugins.workflow.actions.LabelActiondef hasLabelAction(FlowNode flowNode) &#123; def actions = flowNode.getActions() for (Action action : actions) &#123; if (action instanceof LabelAction) &#123; return true &#125; &#125; return false&#125;def getStepStartNode(List&lt;FlowNode&gt; flowNodes, String stepNodeName, def depth) &#123; if (depth &lt; 0) &#123; return null &#125; for(FlowNode flowNode : flowNodes) &#123; def labelActionFlag = false if (flowNode instanceof StepStartNode) &#123; labelActionFlag = hasLabelAction(flowNode) &#125; if (labelActionFlag &amp;&amp; flowNode.getDisplayName().equals(stepNodeName)) &#123; return flowNode &#125; // 递归查询 def node = getStepStartNode(flowNode.getParents(), stepNodeName, depth) if(node) &#123; return node &#125; &#125; return null&#125;def getBlueOceanLogUrlByName(String stepNodeName) &#123; // currentBuild: class org.jenkinsci.plugins.workflow.support.steps.build.RunWrapper // build: class org.jenkinsci.plugins.workflow.job.WorkflowRun def build = currentBuild.getRawBuild() // execution: class org.jenkinsci.plugins.workflow.cps.CpsFlowExecution def execution = build.getExecution() // executionHeads: class java.util.ArrayList def executionHeads = execution.getCurrentHeads() def flowNode = getStepStartNode(executionHeads, stepNodeName, 10) if (flowNode) &#123; return Jenkins.instance.getRootUrl() + "blue/rest/organizations/jenkins/pipelines/$&#123;JOB_NAME&#125;/runs/$&#123;BUILD_NUMBER&#125;/nodes/" + flowNode.getId() + "/log" &#125; return ""&#125;def generateTask(def taskName) &#123; def taskBody = &#123; println getBlueOceanLogUrlByName("Branch: $&#123;taskName&#125;") node &#123; println("====&gt; $&#123;taskName&#125; start") sleep 3 println("====&gt; $&#123;taskName&#125; end") &#125; &#125; taskBody&#125;def createParallelTasks(def jobs) &#123; def pipelineConfig = [:] jobs.each &#123; def job -&gt; def taskBody = generateTask(job) pipelineConfig.put(job, taskBody) &#125; pipelineConfig&#125;script &#123; def jobs = ["job_a", "job_b", "job_c"] def pipelineConfig = createParallelTasks(jobs) stage('test') &#123; println getBlueOceanLogUrlByName("test") parallel pipelineConfig &#125;&#125;]]></content>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[free命令详解]]></title>
    <url>%2F2019%2F09%2F03%2Flinux%2Flinux-cmd-free%2F</url>
    <content type="text"><![CDATA[free命令显示了系统中已使用和空闲的物理内存和交换内存，以及内核使用的buffer和cache的大小。命令中的数据是通过解析/proc/meminfo文件获得的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@localhost ~]# free -w total used free shared buffers cache availableMem: 1014972 604816 65888 6880 164 344104 220752Swap: 1048572 264 1048308[root@localhost ~]# free -k total used free shared buff/cache availableMem: 1014972 605732 64932 6880 344308 219800Swap: 1048572 264 1048308[root@localhost ~]# cat /proc/meminfoMemTotal: 1014972 kBMemFree: 64916 kBMemAvailable: 219784 kBBuffers: 164 kBCached: 264984 kBSwapCached: 8 kBActive: 645456 kBInactive: 155036 kBActive(anon): 509284 kBInactive(anon): 32940 kBActive(file): 136172 kBInactive(file): 122096 kBUnevictable: 0 kBMlocked: 0 kBSwapTotal: 1048572 kBSwapFree: 1048308 kBDirty: 16 kBWriteback: 0 kBAnonPages: 535368 kBMapped: 44520 kBShmem: 6880 kBSlab: 79160 kBSReclaimable: 48748 kBSUnreclaim: 30412 kBKernelStack: 2704 kBPageTables: 6608 kBNFS_Unstable: 0 kBBounce: 0 kBWritebackTmp: 0 kBCommitLimit: 1556056 kBCommitted_AS: 778052 kBVmallocTotal: 34359738367 kBVmallocUsed: 27092 kBVmallocChunk: 34359707152 kBHardwareCorrupted: 0 kBAnonHugePages: 356352 kBCmaTotal: 0 kBCmaFree: 0 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBDirectMap4k: 63424 kBDirectMap2M: 985088 kB[root@localhost ~]# 列内容说明: total: 系统中的内存总量，对应/proc/meminfo中的MemTotal和SwapTotal的内容 used: 已占用内存大小，通过total - free - buffers - cache计算得出 free: 空闲内存大小，对应/proc/meminfo中的MemFree和SwapFree的内容 shared: 共享内存占用大小，通过情况都是tmpfs占用，对应/proc/meminfo中的Shmem的内容，在2.6.32内核中开始提供该内容显示，在不支持的系统中显示为0 buffers: 内核buffers占用大小，对应/proc/meminfo中的Buffers内容 cache: page cache和slabs占用的大小，对应/proc/meminfo中的Cached和Slab内容之和 buff/cache: buffers和cache之和 available: 在不考虑交换内存的情况下，估算有多少内存可以用来启动新应用。不同于cache和free字段提供的数据，该字段考虑了page cache，同时并非所有的可回收的slabs内存由于在使用中并不一定能被回收，对应/proc/meminfo中的MemAvailable内容(在内核3.14上可用，在内核2.6.27+上模拟，否则与free内容相同) buffers与cachelinux缓存机制在系统运行过程中，内核会利用空闲的物理内存，划出一部分区域作为buffers/cache，将一些程序使用过的硬盘数据读入缓存区域的内存，利用高速的内存读写特性提升数据的访问效率。 针对应用程序来说，通常情况下buffers/cache占用的内存是可用的，当应用程序需要用到内存的时候，会回收buffers/cache内存。 buffers与cache的区别cache 指 page cache，它是针对文件系统的，是文件的缓存。当缓存中的文件被修改(写操作)后，linux不会立即执行写磁盘操作，而是把page cache中的页面标记为脏页，定期同步到存储设备中。 buffers 指 buffer cache，是磁盘块的缓存，是针对块设备的。直接对块设备的进行操作的数据会缓存到buffers中，例如，文件系统的元数据信息。 手动释放buffers和cache/proc/sys/vm文档 123456#释放page cacheecho 1 &gt; /proc/sys/vm/drop_caches#释放可回收的slab对象(包括dentries和iinodes)echo 2 &gt; /proc/sys/vm/drop_caches#释放page cache 和 slab 对象echo 3 &gt; /proc/sys/vm/drop_caches 通过写drop_caches文件是一个非破坏性(non-destructive)的操作，不会释放脏数据。在执行该命令前执行sync命令可以强制将一些脏数据刷盘，然后尽可能多的释放内存。 这个文件的内容并不能控制内核是否使用缓存机制。 是否需要手动清除缓存通常情况下，应用程序在系统上稳定运行之后，free的值也会保持在一个稳定的值，虽然看上去比较小，Linux内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对buffer／cache的释放。尤其是被使用更多的cache空间。既然它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放cache，作为free空间分给相关进程使用。所以一般情况下，我们认为buffer/cache空间可以被释放，这个理解是正确的。 通常情况下，当发生内存不足，应用程序获取不到内存，OOM等错误时，需要排查应用程序是否存在内存泄露的情况。针对内存泄露/内存溢出等导致内存不足的情况，可以通过swap的使用情况来快速判断(free中swap的使用情况，vmstate中si/so的值等)。 但是并非所有的buffer/cache都能释放 如何控制linux清理cache机制–内存整理影响系统性能案例 linux内存分配与回收 Linux中Buffer/Cache清理Linux服务器Cache占用过多内存导致系统内存不足问题的排查解决Linux服务器Cache占用过多内存导致系统内存不足问题的排查解决-2 禁用buffer/cache功能可以在/etc/sysctl.conf中添加下面内容禁用buffer/cache功能 12345678910vm.dirty_ratio = 1vm.dirty_background_ratio=1 vm.dirty_writeback_centisecs=2 vm.dirty_expire_centisecs=3 vm.drop_caches=3 vm.swappiness =100 vm.vfs_cache_pressure=163 vm.overcommit_memory=2 vm.lowmem_reserve_ratio=32 32 8 kern.maxvnodes=3 /proc/sys/vm/dirty_ratio 这个参数表示文件系统的写缓冲区占用系统内存的百分比，即当写缓冲使用到系统内存多少的时候，开始向磁盘写数据。增大之会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时，应该降低其数值。 /proc/sys/vm/dirty_background_ratio 这个参数控制文件系统的pdflush进程，在何时刷新磁盘。单位是百分比，表示系统内存的百分比，意思是当写缓冲使用到系统内存多少的时候，pdflush开始向磁盘写数据。增大之会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时， 应该降低其数值 /proc/sys/vm/dirty_writeback_centisecs 这个参数控制内核的脏数据刷新进程pdflush的运行间隔。单位是 1/100 秒。缺省数值是500，也就是 5 秒。如果你的系统是持续地写入动作，那么实际上还是降低这个数值比较好，这样可以把尖峰的写操作削平成多次写操 /proc/sys/vm/dirty_expire_centisecs 这个参数声明Linux内核写缓冲区里面的数据多“旧”了之后，pdflush进程就开始考虑写到磁盘中去。单位是 1/100秒。缺省是 30000，也就是 30 秒的数据就算旧了，将会刷新磁盘。对于特别重载的写操作来说，这个值适当缩小也是好的，但也不能缩小太多，因为缩小太多也会导致IO提高太快。建议设置为 1500，也就是15秒算旧。 /proc/sys/vm/drop_caches 释放已经使用的cache /proc/sys/vm/page-cluster 该文件表示在写一次到swap区的时候写入的页面数量，0表示1页，1表示2页，2表示4页。 /proc/sys/vm/swapiness 该文件表示系统进行交换行为的程度，数值（0-100）越高，越可能发生磁盘交换。 /proc/sys/vm/vfs_cache_pressure 该文件表示内核回收用于directory和inode cache内存的倾向]]></content>
      <tags>
        <tag>linux</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins运行shell脚本时读取系统环境变量]]></title>
    <url>%2F2019%2F09%2F01%2Fjenkins%2Fjenkins-sh-read-env%2F</url>
    <content type="text"><![CDATA[FreeStyle的JenkinsJob在freestyle的job中配置执行shell命令后，job在运行时默认的执行方式为 /bin/bash -xe /tmp/jenkinsxxxx.sh 1234567Building in workspace /var/lib/jenkins/workspace/jenkins_shell_test[jenkins_shell_test] $ /bin/sh -xe /tmp/jenkins6138408577395354213.sh+ set -x+ exportexport BUILD_CAUSE=&quot;MANUALTRIGGER&quot;export BUILD_CAUSE_MANUALTRIGGER=&quot;true&quot;... 在执行机上查看对应的进程 1234[root@localhost ~]# ps -ef |grep -i jenkinsjenkins 12371 1 20 16:30 ? 00:03:55 /etc/alternatives/java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /usr/lib/jenkins/jenkins.war --logfile=/var/log/jenkins/jenkins.log --webroot=/var/cache/jenkins/war --daemon --httpPort=8080 --debug=5 --handlerCountMax=100 --handlerCountMaxIdle=20jenkins 27359 12371 0 16:48 ? 00:00:00 /bin/sh -xe /tmp/jenkins6138408577395354213.shjenkins 27360 27359 0 16:48 ? 00:00:00 sleep 30 /bin/sh -xe xxx.sh方式运行的shell为非交互式非登录的模式，这种模式下的shell在启动时不会读取/etc/profile中的内容，所以/etc/profile中定义的环境变量不能访问 解决方法: 在shell中添加 #!/bin/bash -ilex，将shell模式修改为交互登录模式即可。 12345[root@localhost ~]# ps -ef |grep -i jenkinsjenkins 12371 1 10 16:30 ? 00:04:43 /etc/alternatives/java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /usr/lib/jenkins/jenkins.war --logfile=/var/log/jenkins/jenkins.log --webroot=/var/cache/jenkins/war --daemon --httpPort=8080 --debug=5 --handlerCountMax=100 --handlerCountMaxIdle=20jenkins 15197 12371 0 17:13 ? 00:00:00 /bin/bash -liex /tmp/jenkins15271049705299428998.shjenkins 15211 15197 0 17:13 ? 00:00:00 sleep 30[root@localhost ~]# 注意, #!/bin/bash -ilex 一定要在首行 pipeline模式的JenkinsJobpipeline模式下的原因与解决方案与FreeStyle类似，只是pipeline模式下脚本运行的进程不是jenkins主进程直接fork出来的。 1234567[root@localhost ~]# ps -ef |grep -i jenkinsjenkins 12371 1 11 16:30 ? 00:05:13 /etc/alternatives/java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /usr/lib/jenkins/jenkins.war --logfile=/var/log/jenkins/jenkins.log --webroot=/var/cache/jenkins/war --daemon --httpPort=8080 --debug=5 --handlerCountMax=100 --handlerCountMaxIdle=20jenkins 17509 1 0 17:16 ? 00:00:00 sh -c (pid=$$; &#123; while [ \( -d /proc/$pid -o \! -d /proc/$$ \) -a -d '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf' -a \! -f '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt' ]; do touch '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-log.txt'; sleep 3; done &#125; &amp; jsc=durable-7a8937f3d4c335791e06262c93820f88; JENKINS_SERVER_COOKIE=$jsc 'sh' -xe '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/script.sh' &gt; '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-log.txt' 2&gt;&amp;1; echo $? &gt; '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt.tmp'; mv '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt.tmp' '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt'; wait) &gt;&amp;- 2&gt;&amp;- &amp;jenkins 17511 17509 0 17:16 ? 00:00:00 sh -c (pid=$$; &#123; while [ \( -d /proc/$pid -o \! -d /proc/$$ \) -a -d '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf' -a \! -f '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt' ]; do touch '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-log.txt'; sleep 3; done &#125; &amp; jsc=durable-7a8937f3d4c335791e06262c93820f88; JENKINS_SERVER_COOKIE=$jsc 'sh' -xe '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/script.sh' &gt; '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-log.txt' 2&gt;&amp;1; echo $? &gt; '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt.tmp'; mv '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt.tmp' '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt'; wait) &gt;&amp;- 2&gt;&amp;- &amp;jenkins 17512 17509 0 17:16 ? 00:00:00 sh -xe /var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/script.shjenkins 17514 17512 0 17:16 ? 00:00:00 sleep 30jenkins 17786 17511 0 17:16 ? 00:00:00 sleep 3 pipeline中配置bash的登录模式 1234// #!/bin/bash -ilex 一定要在首行，与第一个 """ 同行sh """#!/bin/bash -ilexexport"""]]></content>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash参数说明]]></title>
    <url>%2F2019%2F09%2F01%2Fbash%2Fshell-parameter%2F</url>
    <content type="text"><![CDATA[特殊参数$$当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。 12345678910111213#显示当前shell的PID[root@localhost ~]# echo $$7338[root@localhost ~]# cat test.shecho $$ # 此处打印 test.sh 脚本运行的 PIDsleep 10# 运行shell脚本程序test.sh时，系统将创建一个子shell，它的父shell为 7338[root@localhost ~]# /bin/bash test.sh &amp;[1] 16371[root@localhost ~]# 16371[root@localhost ~]# ps -ef |grep -i test.shroot 16371 7338 0 05:13 pts/0 00:00:00 /bin/bash test.sh]]></content>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash启动介绍]]></title>
    <url>%2F2019%2F08%2F30%2Fbash%2Fshell%2F</url>
    <content type="text"><![CDATA[概述0号/1号和2号进程 123UID PID PPID C STIME TTY TIME CMDroot 1 0 0 Aug08 ? 00:00:02 /usr/lib/systemd/systemd --switched-root --system --deserialize 22root 2 0 0 Aug08 ? 00:00:00 [kthreadd] 系统启动后，当用户登录到系统时，系统将启动一个用户态的shell进程。在shell进程中运行shell脚本程序时，系统将创建一个子shell，此时系统中将有两个shell，一个是登录时系统启动的shell，另一个是系统为运行脚本程序创建的shell。脚本执行运行完后，子shell将终止，并返回到执行脚本之前的shell。 tty终端的shell进程如下： 通过ssh连接到系统的shell进程如下: 12345678910[root@localhost ~]# echo $$7338[root@localhost ~]# ps -ef |grep -i 7338root 7338 7331 0 03:48 pts/0 00:00:00 -bash[root@localhost ~]# ps -ef |grep -i 7331root 7331 3329 0 03:48 ? 00:00:12 sshd: root@pts/0,pts/1root 7338 7331 0 03:48 pts/0 00:00:00 -bashroot 7344 7331 0 03:48 pts/1 00:00:00 -bash[root@localhost ~]# ps -ef |grep -i 3329root 3329 1 0 Aug08 ? 00:00:00 /usr/sbin/sshd -D shell分类交互式shell与非交互式shell区分方法 可以通过打印“$-”变量的值（代表着当前shell的选项标志），查看其中的“i”选项（表示interactive shell）来区分交互式与非交互式shell。 12345678910111213141516171819[root@localhost ~]# echo $$31991[root@localhost ~]# cat test.shecho $-case "$-" in*i*) echo This shell is interactive;;*) echo This shell is not interactive;;esac[root@localhost ~]# bash test.shhBThis shell is not interactive[root@localhost ~]# echo $$31991[root@localhost ~]# bash -i test.sh himBThis shell is interactive[root@localhost ~]# echo $$31991 通过检查$PS1的内容是否为空判断，在非交互式shell中不会设置该变量 123456789101112131415161718192021[root@localhost ~]# echo $$31991[root@localhost ~]# cat test.shecho $-if [[ -z "$PS1" ]];then echo This shell is not interactiveelse echo This shell is interactivefi[root@localhost ~]# bash test.shhBThis shell is not interactive[root@localhost ~]# echo $$31991[root@localhost ~]# bash -i test.shhimBThis shell is interactive[root@localhost ~]# echo $$31991[root@localhost ~]# echo $-himBH himBH解释 交互式shell顾名思义，shell等待用户输入，输入后系统立即执行并返回结果，并等待一下此输入。当退出后，shell也终止了。 启动交互式shell的方法 启动shell时不带任何选项参数 启动shell时指定-i选项参数 启动shell时指定了-s且没有指定-c参数 非交互式shell通常情况下，执行shell脚本文件时的子shell都是属于非交互式的。在这种场景下，shell读取存放在脚本文件中的内容然后执行，直到读到文件的结尾EOF，shell终止。 登录shell与非登录shell登录式shell需要用户名和密码登录后才能进入的shell，或者通过–login选项打开的shell。 非登录式shell不需要输入用户名和密码即可打开的Shell，例如：直接命令“bash”就是打开一个新的非登录shell，在Gnome或KDE中打开一个“终端”（terminal）窗口程序也是一个非登录shell。 执行exit命令，退出一个shell（登录或非登录shell）；执行logout命令，退出登录shell（不能退出非登录shell） 123456789101112[root@localhost ~]# echo $$2532[root@localhost ~]# bash[root@localhost ~]# echo $$2709[root@localhost ~]# logoutbash: logout: not login shell: use 'exit'[root@localhost ~]# exitexit[root@localhost ~]# exitlogout连接断开 bash是 login shell 时，其进程名为&quot;-bash&quot; 而不是&quot;bash&quot; 12345678910111213141516[root@localhost ~]# echo $$2995[root@localhost ~]# ps -ef |grep -i bashroot 2995 2985 0 08:55 pts/0 00:00:00 -bashroot 3001 2985 0 08:55 pts/1 00:00:00 -bash[root@localhost ~]# bash[root@localhost ~]# echo $$3689[root@localhost ~]# ps -ef |grep -i bashroot 2995 2985 0 08:55 pts/0 00:00:00 -bashroot 3001 2985 0 08:55 pts/1 00:00:00 -bashroot 3689 2995 0 08:56 pts/0 00:00:00 bash[root@localhost ~]# exitexit[root@localhost ~]# echo $$2995 shell分类组合情况 登录式 非登录式 交互式 1.登录系统时获得的顶层shell，无论是通过本地终端登录，还是通过网络ssh登录2.使用bash –login命令启动的shell3.使用su [-/-l/–login] [user]切换到其他用户时 1.使用bash命令启动的shell2.使用su [user]切换到其他用户时 非交互式 在脚本中使用–login选项调用bash（比如在脚本第一行做如下指定：#!/bin/bash –login） 通常情况下执行bash脚本时运行脚本的子shell bash启动时执行的启动文件 登录式 非登录式 交互式 如果/etc/profile存在，则首先执行该文件依次查找存在并可读的~/.bash_profile, ~/.bash_login, ~/.profile中的第一个执行如果启动时指定了--noprofile选项，则不执行上述两个步骤退出时，如果~/.bash_logout存在则执行 如果~/.bashrc存在则执行如果指定了--norc参数则不执行上述步骤可以通过指定--rcfile file指定其他文件替代~/.bashrc 非交互式 同上 查找环境变量BASH_ENV，读取并执行BASH_ENV指向的文件中的内容 shell启动选项参数-i 选项强制子shell使用交互式方式运行 -c cmd_string 选项表示子shell从字符串中读入命令，如果字符串后还有变量就被设定为从$0开始的位置参数 1234[root@localhost ~]# /bin/bash -c 'echo hello world'hello world[root@localhost ~]# /bin/bash -c 'echo $0 $1' hello kittyhello kitty ssh执行远程命令和bash -c string的用法 -s 选项如果指定-s参数，那么表示子shell从标准输入中读入命令，直到输入exit。 该参数允许指定位置参数并将其传入子shell中。 12345678910111213141516171819202122232425262728[root@localhost ~]# echo $$9051# 进入子shell中，未指定-c参数时，子shell为交互式shell[root@localhost ~]# bash -s hello new world[root@localhost ~]# echo $$11211[root@localhost ~]# echo $-himBHs[root@localhost ~]# echo $1hello[root@localhost ~]# echo $2new[root@localhost ~]# echo $3world[root@localhost ~]# exitexit# 退回父shell[root@localhost ~]# echo $$9051# 如果指定-c参数，子shell为非交互式shell[root@localhost ~]# bash -s -c 'echo $0' hellohello[root@localhost ~]# echo $$9051[root@localhost ~]# bash -s -c 'echo $-'hBcs[root@localhost ~]# echo $$9051]]></content>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash中字典使用]]></title>
    <url>%2F2019%2F08%2F08%2Fbash%2Fbash-dict%2F</url>
    <content type="text"><![CDATA[bash版本号 12bash --versionGNU bash, version 4.2.46(2)-release bash中字典使用举例 字典声明赋值 与数组不同，字典使用前必须先声明 12345# Declare dict person 必须先声明declare -A person# 使用 () 赋值person=([name]="john" [age]="18") 字典读取及遍历12345678910111213141516171819202122declare -A person# 根据key读取字典内容person=([name]="lucy" [age]="22")echo $&#123;person["name"]&#125; # lucy# 读取不存在的key时，返回为空if [[ $&#123;person["phone"]&#125; =~ "" ]]; then echo "empty"; else echo "not empty"; fi # empty# 打印字典中的所有value, 返回值为数组echo $&#123;person[@]&#125; #lucy 22echo $&#123;person[@]:0:1&#125; #lucy# 打印字典中的所有key，返回值为数组echo $&#123;!person[@]&#125; #name age# 读取字典中键值对的数量echo $&#123;#person[@]&#125; # 2# for循环遍历字典for key in $&#123;!person[@]&#125;;do echo "key: $&#123;key&#125;, value: $&#123;person[$key]&#125;"; done#key: name, value: lucy#key: age, value: 22 字典中增加删除元素123456789101112131415161718192021222324#增加字典元素两种方式declare -A personperson=([name]="hanmeimei" [age]="23")person+=([phoneNumber]="13920380998")echo $&#123;person[@]&#125; # hanmeimei 23 13920380998echo $&#123;!person[@]&#125; # name age phoneNumberperson[addr]="shanghai"echo $&#123;person[@]&#125; #hanmeimei 23 shanghai 13920380998echo $&#123;!person[@]&#125; #name age addr phoneNumber#删除字典元素unset person[phoneNumber]echo $&#123;person[@]&#125; #hanmeimei 23 shanghaiecho $&#123;!person[@]&#125; #name age addr#删除不存在的字典元素时无影响unset person[phoneNumber]echo $&#123;person[@]&#125; #hanmeimei 23 shanghaiecho $&#123;!person[@]&#125; #name age addr#删除整个字典unset personif [[ $&#123;person&#125; =~ "" ]]; then echo "empty"; else echo "not empty"; fi #empty 字典元素值替换12345declare -A personperson=([name]="lilei" [age]="12")echo $&#123;person[name]&#125; #lileiperson[name]="lucy"echo $&#123;person[name]&#125; #lucy]]></content>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过shell实现yaml目标变量替换]]></title>
    <url>%2F2019%2F08%2F08%2Fbash%2Fshell-replace-yaml-template%2F</url>
    <content type="text"><![CDATA[yaml的模板build_template.yaml如下 123repos: - url: "$&#123;REPO_URL&#125;" branch: "$&#123;BRANCH&#125;" REPO_URL和BRANCH定义在环境变量中或写入config.ini文件 123# cat config.iniREPO_URL="https://github.com/etcd-io/etcd.git"BRANCH="master' 替换脚本如下 123configContent=$(cat config.ini)yamlTemplate=$(cat build_template.yaml)printf "$configContent\ncat &lt;&lt; EOF\n$&#123;yamlTemplate&#125;\nEOF" |bash &gt; ./build.yaml 生成的build.yaml文件内容如下: 123repos: - url: "https://github.com/etcd-io/etcd.git" branch: "master"]]></content>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
        <tag>yaml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash数组]]></title>
    <url>%2F2019%2F07%2F23%2Fbash%2Fbash-array%2F</url>
    <content type="text"><![CDATA[bash版本号 12bash --versionGNU bash, version 4.2.46(2)-release bash数组使用举例 数组声明赋值1234567891011# Declare array namesdeclare -a names # 也可以不用声明，直接采用数组的赋值方式赋值，bash能自动识别为数组# 使用 [] 赋值names[0]="john"names[1]="lucy"# 使用 () 赋值names=("john" "lucy")names=([0]="john" [1]="lucy")names=([1]="jessica" [3]="hanmeimei") # 可以指定下标不连续 数组读取及遍历1234567891011121314151617181920# 根据下标读取数组内容names=([0]="lily" [1]="lucy" [3]="hanmeimei")echo $&#123;names[1]&#125; # lucyif [[ $&#123;names[2]&#125; =~ "" ]]; then echo "empty"; else echo "not empty"; fi # empty# 打印数组中所有元素， 此时打印出来的内容的是字符串列表echo $&#123;names[@]&#125; #lily lucy hanmeimei# 打印数组中元素的索引列表echo $&#123;!names[@]&#125; # 0 1 3# 读取数组长度# 上面定义的数组下标虽然不连续，但是数组长度仍为 3echo $&#123;#names[@]&#125; # 3# 遍历数组for name in $&#123;names[@]&#125;;do echo $name; done# lily# lucy# hanmeimei 数组截取及组合123456789101112131415161718names=('lilei' 'jack' 'hanmeimei' 'lily' 'lucy')# 截取从索引 1 开始（包含索引 1）的后面 3 个元素echo $&#123;names[@]:1:3&#125; # jack hanmeimei lily# 如果未指定元素个数，则表示后面所有元素echo $&#123;names[@]:2&#125; # hanmeimei lily lucy# 两个数组组合names1=('name1_1' 'name1_2')names2=('name2_1' 'name2_2' 'name2_3')names=($&#123;names1[@]&#125; $&#123;names2[@]&#125;)echo $&#123;names[@]&#125; # name1_1 name1_2 name2_1 name2_2 name2_3# 数组中增加元素names=('lily' 'lucy')names=("$&#123;names[@]&#125;" "hanmeimei")echo $&#123;names[@]&#125; # lily lucy hanmeimei 删除数据中元素1234567891011121314151617181920names=('lily' 'lucy' 'hanmeimei' 'lilei' 'jack')# 删除数组中索引为 1 的元素unset names[1]echo $&#123;names[@]&#125; # lily hanmeimei lilei jackecho $&#123;!names[@]&#125; # 0 2 3 4# 删除整个数组unset names# 使用数组截取然后重新组合方式删除元素names=('lily' 'lucy' 'hanmeimei' 'lilei' 'jack')names=($&#123;names[@]:0:1&#125; $&#123;names[@]:2&#125;)echo $&#123;names[@]&#125; # lily hanmeimei lilei jackecho $&#123;!names[@]&#125; # 0 1 2 3# 使用模式操作符删除数组中的元素names=('lily' 'lucy' 'hanmeimei' 'lilei' 'jack')names=(@&#123;names[@]/lucy/&#125;)echo $&#123;names[@]&#125; # lily hanmeimei lilei jackecho $&#123;!names[@]&#125; # 0 1 2 3 数组元素值替换123456789# 使用数组下标赋值names=('lilei' 'hanmeimei' 'lucy' 'lily')names[1]='jessica'echo $&#123;names[@]&#125; # lilei jessica lucy lily#使用模式操作符进行内容替换names=('lilei' 'hanmeimei' 'lucy' 'lily')names=($&#123;names[@]/hanmeimei/jessica&#125;)echo $&#123;names[@]&#125; # lilei jessica lucy lily]]></content>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash使用总结]]></title>
    <url>%2F2019%2F07%2F23%2Fbash%2Fbash-usage%2F</url>
    <content type="text"><![CDATA[bash启动简介bash参数 Bash官网 Bash数组Bash字典 通过shell实现yaml模板变量替换 Unix系统中的Shebang符号]]></content>
      <tags>
        <tag>总结</tag>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pipeline序列化问题]]></title>
    <url>%2F2019%2F07%2F22%2Fjenkins%2Fjenkins-serialization%2F</url>
    <content type="text"><![CDATA[Jenkins支持所有运行的job都可以在服务重启时中断、暂停在服务重启后恢复运行。为了实现这一点，Jenkins pipeline中定义的所有变量都必须是可序列化的。类似的，Jenkins也必须能序列化构建中节点和子job之间的全局变量的状态。 遇到java.io.NotSerializableException问题的一般方法 将不可序列化的代码封装在一个用@NonCPS注释的函数中。这告诉Jenkins函数包含不可序列化的部分，必须在不可中断的情况下执行。使用NonCPS的函数中不能调用任何jenkins steps或其他CPS-transformed的代码。 尝试取消不可序列化变量的定义 更多详细信息参见链接 json解析 12345678910111213import groovy.json.JsonSlurperClassic @NonCPSdef jsonParse(def json) &#123; new groovy.json.JsonSlurperClassic().parseText(json)&#125;node('master') &#123; def config = jsonParse(readFile("config.json")) def db = config["database"]["address"] ...&#125; 参考1参考2参考3]]></content>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-log命令]]></title>
    <url>%2F2019%2F07%2F22%2Fgit%2Fgit-cmd-log%2F</url>
    <content type="text"><![CDATA[命令格式1git log [&lt;options&gt;] [&lt;revision range&gt;] [[--] &lt;path&gt;…​] 命令参数选项 选项 说明 -p 以补丁格式显示每次提交之间的差异 –stat 显示每次提交的文件修改统计信息 –shortstat 只显示 –stat 中最后的行数修改添加移除统计 –name-only 仅在提交信息后显示已修改的文件清单 –name-status 显示新增、修改、删除的文件清单 –abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符 –relative-date 使用较短的相对时间显示（比如”2 weeks ago”） –graph 显示 ASCII 图形表示的分支合并历史 –pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式，格式见下表） –oneline –pretty=oneline –abbrev-commit 的简化用法 -(n) 仅显示最近的 n 条提交 –since, –after 仅显示指定时间之后的提交, 可以使用各种时间格式，比如说具体的某一天（”2008-01-15”），或者是多久以前（”2 years 1 day 3 minutes ago”） –until, –before 仅显示指定时间之前的提交 –author 仅显示指定作者相关的提交 –committer 仅显示指定提交者相关的提交 format常用的格式占位符写法及其代表的意义。 选项 说明 %H 提交对象（commit）的完整哈希字串 %h 提交对象的简短哈希字串 %T 树对象（tree）的完整哈希字串 %t 树对象的简短哈希字串 %P 父对象（parent）的完整哈希字串 %p 父对象的简短哈希字串 %an 作者（author）的名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 -date= 选项定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者(committer)的名字 ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期，按多久以前的方式显示 %s 提交说明]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下jenkins的安装]]></title>
    <url>%2F2019%2F07%2F16%2Fcentos%2Fcentos-jenkins-install%2F</url>
    <content type="text"><![CDATA[非docker安装通过设置jenkins官方repo仓库下载1234sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keyyum install jenkinscat /etc/rc.d/init.d/jenkins 安装后，jenkins.war默认地址为JENKINS_WAR=”/usr/lib/jenkins/jenkins.war” jenkins的config地址为JENKINS_CONFIG=/etc/sysconfig/jenkins jenkins服务的启动/停止/重启脚本为/etc/init.d/jenkins 下载rpm安装12wget https://pkg.jenkins.io/redhat-stable/jenkins-2.176.1-1.1.noarch.rpmrpm -ivh jenkins-2.176.1-1.1.noarch.rpm 下载war包123wget https://mirrors.huaweicloud.com/jenkins/war-stable/latest/jenkins.war#wget http://mirrors.jenkins.io/war-stable/latest/jenkins.warjava -jar jenkins.war 常用的启动参数为: 123456789101112131415161718java -Duser.timezone=GMT+08 \ -Djava.util.logging.config.file=/var/jenkins_home/jenkins.logging.properties \ -Dgroovy.grape.report.downloads=true -Divy.message.logger.level=4 \ -Dhudson.model.ParametersAction.keepUndefinedParameters=true \ -Dhudson.security.ArtifactsPermission=true -Djava.awt.headless=true \ -Dorg.apache.commons.jelly.tags.fmt.timeZone=Asia/Shanghai \ -Dfile.encoding=UTF-8 -Dsun.jnu.encoding=UTF-8 \ -Dhudson.slaves.NodeProvisioner.MARGIN=50 \ -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 \ -Dhudson.slaves.NodeProvisioner.initialDelay=0 \ -Dhudson.slaves.NodeProvisioner.recurrencePeriod=2 \ -Dhudson.model.LoadStatistics.clock=2 \ -Dhudson.model.LoadStatistics.decay=0.1 \ -Dpermissive-script-security.enabled=true \ -server -Xms10g -Xmx32g -XX:MaxPermSize=4g -XX:+HeapDumpOnOutOfMemoryError \ -Xloggc:/var/jenkins_home/jenkins_gc.log \ -DJENKINS_HOME=/var/jenkins_home \ -jar jenkins.war --logfile=/var/jenkins_home/jenkins.log jenkins.logging.properties 的内容参见说明permissive-script-security.enabled=true表示默认允许执行unsecured脚本，不再提示需要审核 虚拟机中启动jenkins后不能访问 关闭防火墙 123systemctl status firewalldsystemctl stop firewalldsystemctl disable firewalld 配置防火墙开放jinkins使用的端口 123456789101112# 检查当前防火墙开放的端口[root@localhost ~]# firewall-cmd --list-ports# 配置防火墙开放端口[root@localhost ~]# firewall-cmd --permanent --zone=public --add-port=8080/tcpsuccess[root@localhost ~]# firewall-cmd --list-ports# 重启防火墙[root@localhost ~]# systemctl reload firewalld[root@localhost ~]# firewall-cmd --list-ports8080/tcp docker安装docker hub中有两种jenkins的镜像，jenkins官方推荐使用 jenkinsci/blueocean 镜像，该镜像中包含了blueocean插件，该镜像会在blueocean发布新版本时同步发布。还有一个镜像 jenkins/jenkins, 为jenkins的纯净版本。 jenkins/jenkins的github地址 容器化安装时，支持配置下面三个环境变量，来定义jenkins的配置 JAVA_OPTS JENKINS_HOME JENKINS_OPTS JENKINS_SLAVE_AGENT_PORT 123456789101112docker run \ --restart=always \ -d \ -p 80:8080 \ -p 31281:31281 \ -e JENKINS_SLAVE_AGENT_PORT=31281 \ -e JENKINS_HOME="/var/jenkins_home" \ -e JAVA_OPTS="-Duser.timezone=GMT+08 -Dgroovy.grape.report.downloads=true -Divy.message.logger.level=4 -Djava.util.logging.config.file=/var/jenkins_home/jenkins.logging.properties -Dhudson.model.ParametersAction.keepUndefinedParameters=true -Dhudson.security.ArtifactsPermission=true -Djava.awt.headless=true -Dorg.apache.commons.jelly.tags.fmt.timeZone=Asia/Shanghai -Dfile.encoding=UTF-8 -Dsun.jnu.encoding=UTF-8 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.recurrencePeriod=2 -Dhudson.model.LoadStatistics.clock=2 -Dhudson.model.LoadStatistics.decay=0.1 -server -Xms10g -Xmx32g -XX:MaxPermSize=4g -XX:+HeapDumpOnOutOfMemoryError -Xloggc:/var/jenkins_home/jenkins_gc.log" \ -e JENKINS_OPTS="--logfile=/var/jenkins_home/logs/jenkins.log" \ -v /data/jenkins_home:/var/jenkins_home \ -v /var/run/docker.sock:/var/run/docker.sock \ jenkins/jenkins jenkins.logging.properties 的内容参见说明 docker运行jenkins时提示权限错误12touch: cannot touch ‘/var/jenkins_home/copy_reference_file.log’: Permission deniedCan not write to /var/jenkins_home/copy_reference_file.log. Wrong volume permissions? 因为容器启动时默认采用jenkins用户，uid和gid分别时 1000 和 1000，需要将挂载到容器里面的JENKINS_HOME对应的宿主机上的目录的所有者修改下 1chown -R 1000:1000 /data/jenkins_home]]></content>
      <tags>
        <tag>centos</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins通过Grab下载依赖失败]]></title>
    <url>%2F2019%2F07%2F16%2Fgroovy%2Fjenkins-groovy-grape%2F</url>
    <content type="text"><![CDATA[官方文档极客学院翻译 问题描述在使用Jenkins的 pipeline as code 特性时，遇到使用第三方jar的情况，使用了@Grab(group=&#39;org.restlet&#39;, module=&#39;org.restlet&#39;, version=&#39;1.1.6&#39;)注解，但是在Jenkins job运行时下载依赖失败。 解决方法grape默认时采用maven的 mvnrepository.com 来搜索依赖包，出问题的Jenkins master上是不能访问该仓库的，所以下载依赖失败。 在${user.home}/.groovy/目录下新增文件grapeConfig.xml，指定仓库地址为内网仓库或可访问的maven镜像仓库。 12345678&lt;ivysettings&gt; &lt;settings defaultResolver="downloadGrapes"/&gt; &lt;resolvers&gt; &lt;chain name="downloadGrapes"&gt; &lt;ibiblio name="public" root="https://mirrors.huaweicloud.com/repository/maven/" m2compatible="true"/&gt; &lt;/chain&gt; &lt;/resolvers&gt;&lt;/ivysettings&gt; grapeConfig.xml的默认配置为 123456789101112131415&lt;ivysettings&gt; &lt;settings defaultResolver="downloadGrapes"/&gt; &lt;resolvers&gt; &lt;chain name="downloadGrapes" returnFirst="true"&gt; &lt;filesystem name="cachedGrapes"&gt; &lt;ivy pattern="$&#123;user.home&#125;/.groovy/grapes/[organisation]/[module]/ivy-[revision].xml"/&gt; &lt;artifact pattern="$&#123;user.home&#125;/.groovy/grapes/[organisation]/[module]/[type]s/[artifact]-[revision](-[classifier]).[ext]"/&gt; &lt;/filesystem&gt; &lt;ibiblio name="localm2" root="file:$&#123;user.home&#125;/.m2/repository/" checkmodified="true" changingPattern=".*" changingMatcher="regexp" m2compatible="true"/&gt; &lt;!-- todo add 'endorsed groovy extensions' resolver here --&gt; &lt;ibiblio name="jcenter" root="https://jcenter.bintray.com/" m2compatible="true"/&gt; &lt;ibiblio name="ibiblio" m2compatible="true"/&gt; &lt;/chain&gt; &lt;/resolvers&gt;&lt;/ivysettings&gt; Jenkins中grape下载的第三方jar默认是缓存在${user.home}/.groovy/grapes/目录下。可以通过添加Jenkins的启动参数-Dgroovy.grape.report.downloads=true 和 -Divy.message.logger.level=4，在jenkins的日志中观察第三方依赖的下载过程。 如果jenkins master采用docker方式安装时，使用jenkins用户登录，同时设置jenkins的user.home为JENKINS_HOME即可。]]></content>
      <tags>
        <tag>jenkins</tag>
        <tag>groovy</tag>
        <tag>grape</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-commit命令]]></title>
    <url>%2F2019%2F07%2F16%2Fgit%2Fgit-cmd-commit%2F</url>
    <content type="text"><![CDATA[git commit –amend建议 git commit –amend 命令使用在未push到远端的场景。 提交还未push到远端在某次修改时，修改了README.md文件，同时新增了amendTest文件。但是在commit的时候，只提交了README.md，忘记了amendTest文件。 1234567891011121314151617181920212223242526272829303132333435363738[root@localhost gitTest]# git statusOn branch masterYour branch is up to date with 'origin/master'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: README.mdUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) amendTestno changes added to commit (use "git add" and/or "git commit -a")[root@localhost gitTest]# git commit -am 'add amendTest file'[master ce1e058] add amendTest file 1 file changed, 1 insertion(+)[root@localhost gitTest]# git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) amendTestnothing added to commit but untracked files present (use "git add" to track)[root@localhost gitTest]# git log -n 3 --onelinea889479 (HEAD -&gt; master) add amendTest file11843d7 (origin/master, origin/HEAD) updatebf2a12f update[root@localhost gitTest]# git diff --stat HEAD~1 HEAD README.md | 1 + 1 file changed, 1 insertion(+)[root@localhost gitTest]# 此时，如果想将amendTest文件提交，同时不产生新的commit记录(即新提交内容合并到上一次提交中)，可以使用git commit --amend命令 123456789101112131415161718192021222324252627[root@localhost gitTest]# git add .[root@localhost gitTest]# git commit --amendadd amendTest file# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.## Date: Sun Jun 30 15:00:20 2019 +0800## On branch master# Your branch is ahead of 'origin/master' by 1 commit.# (use "git push" to publish your local commits)## Changes to be committed:# modified: README.md# new file: amendTest Date: Sun Jun 30 15:00:20 2019 +0800 2 files changed, 2 insertions(+) create mode 100644 amendTest[root@localhost gitTest]# git log -n 3 --onelined2a42e9 (HEAD -&gt; master) add amendTest file11843d7 (origin/master, origin/HEAD) updatebf2a12f update[root@localhost gitTest]# git diff --stat HEAD~1 HEAD README.md | 1 + amendTest | 1 + 2 files changed, 2 insertions(+) 使用该git commit --amend命令后，会生成一个新的commitid，合并本次提交与上一次提交内容。 提交已经push到远端如果上一次commit已经push到远端，使用git commit --amend提交后，在push到远端时会被拒绝，通过git status提示发现当前分支与origin/master已经分叉 通过git pull将origin/master代码merge过来后，重新push可以推送成功 但是通过git log可以发现远端仍是有两次提交记录。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485[root@localhost gitTest]# git log -n 3 --onelinee30f084 (HEAD -&gt; master) add amendTest file11843d7 (origin/master, origin/HEAD) updatebf2a12f update[root@localhost gitTest]# git push origin masterEnumerating objects: 5, done.Counting objects: 100% (5/5), done.Compressing objects: 100% (3/3), done.Writing objects: 100% (3/3), 404 bytes | 202.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)To github.com:daybreakgx/gitTest.git 11843d7..e30f084 master -&gt; master[root@localhost gitTest]# git log -n 3 --onelinee30f084 (HEAD -&gt; master, origin/master, origin/HEAD) add amendTest file11843d7 updatebf2a12f update[root@localhost gitTest]# git add .[root@localhost gitTest]# git commit --amend[master 7e0656c] add amendTest file add 2 Date: Sun Jun 30 15:25:00 2019 +0800 2 files changed, 2 insertions(+) create mode 100644 amendTest[root@localhost gitTest]# git statusOn branch masterYour branch and 'origin/master' have diverged,and have 1 and 1 different commits each, respectively. (use "git pull" to merge the remote branch into yours)nothing to commit, working tree clean[root@localhost gitTest]# git log -n 3 --oneline7e0656c (HEAD -&gt; master) add amendTest file add 211843d7 updatebf2a12f update[root@localhost gitTest]# git push origin masterTo github.com:daybreakgx/gitTest.git ! [rejected] master -&gt; master (non-fast-forward)error: failed to push some refs to 'git@github.com:daybreakgx/gitTest.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details.[root@localhost gitTest]# git pullMerge made by the 'recursive' strategy.[root@localhost gitTest]# git statusOn branch masterYour branch is ahead of 'origin/master' by 2 commits. (use "git push" to publish your local commits)nothing to commit, working tree clean[root@localhost gitTest]# git push origin masterEnumerating objects: 6, done.Counting objects: 100% (6/6), done.Compressing objects: 100% (3/3), done.Writing objects: 100% (4/4), 437 bytes | 218.00 KiB/s, done.Total 4 (delta 2), reused 0 (delta 0)remote: Resolving deltas: 100% (2/2), completed with 1 local object.To github.com:daybreakgx/gitTest.git e30f084..bef9cc4 master -&gt; master[root@localhost gitTest]# git log --graph* commit bef9cc49c27913ca9924378dd50c0ef50f6d8d48 (HEAD -&gt; master, origin/master, origin/HEAD)|\ Merge: 7e0656c e30f084| | Author: daybreakgx &lt;daybreak.gx@gmail.com&gt;| | Date: Sun Jun 30 15:27:59 2019 +0800| | | | Merge branch 'master' of github.com:daybreakgx/gitTest| | | * commit e30f08487acfe730bfa241e0042a55503d41b791| | Author: daybreakgx &lt;daybreak.gx@gmail.com&gt;| | Date: Sun Jun 30 15:25:00 2019 +0800| | | | add amendTest file| | * | commit 7e0656c521428142bd248153050918a7a5f5d0ab|/ Author: daybreakgx &lt;daybreak.gx@gmail.com&gt;| Date: Sun Jun 30 15:25:00 2019 +0800| | add amendTest file add 2| * commit 11843d78157ea67dc2d4768366c1f6c446d93071| Author: daybreakgx &lt;daybreak.gx@gmail.com&gt;| Date: Sun Jun 30 14:58:02 2019 +0800| | update 撤销git commit –amend]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-ls-files命令]]></title>
    <url>%2F2019%2F07%2F08%2Fgit%2Fgit-cmd-ls-files%2F</url>
    <content type="text"><![CDATA[该命令用于显示暂存区(index)或工作区(working tree)的文件信息 命令格式git ls-files [-z] [-t] [-v] [-f] (–[cached|deleted|others|ignored|stage|unmerged|killed|modified]) (-[c|d|o|i|s|u|k|m]) [–eol] [-x &lt;pattern>|–exclude=&lt;pattern>] [-X &lt;file>|–exclude-from=&lt;file>] [–exclude-per-directory=&lt;file>] [–exclude-standard] [–error-unmatch] [–with-tree=&lt;tree-ish>] [–full-name] [–recurse-submodules] [–abbrev] [–] [&lt;file>…​] 命令参数选项 -c, –cached: 显示暂存区中的文件 -d, –deleted: 显示删除了的文件 -m, –modified: 显示修改了的文件 -i, –ignored: 显示忽略了的文件(满足忽略模式的) -o, –others: 显示其他类型的文件(如未追踪的) -s, –stage: 按照如下格式显示文件内容[&lt;tag\&gt;] &lt;mode\&gt; &lt;object\&gt; &lt;stage\&gt; &lt;file\&gt;]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-update-index命令]]></title>
    <url>%2F2019%2F07%2F07%2Fgit%2Fgit-cmd-update-index%2F</url>
    <content type="text"><![CDATA[通常该命令用于将工作区(working tree)中的内容注册到暂存区(index) 命令格式git update-index [–add] [–remove | –force-remove] [–replace] [–refresh] [-q] [–unmerged] [–ignore-missing] [(–cacheinfo &lt;mode>,&lt;object>,&lt;file>)…​] [–chmod=(+|-)x] [–[no-]assume-unchanged] [–[no-]skip-worktree] [–[no-]fsmonitor-valid] [–ignore-submodules] [–[no-]split-index] [–[no-|test-|force-]untracked-cache] [–[no-]fsmonitor] [–really-refresh] [–unresolve] [–again | -g] [–info-only] [–index-info] [-z] [–stdin] [–index-version &lt;n>] [–verbose] [–] [&lt;file>…​] 命令参数选项 –add: 如果指定的文件不在暂存区(index)中，则将其加入暂存区。 例子增加工作区新文件到暂存区123456789101112131415161718192021222324252627282930[root@localhost git_update_index]# git initInitialized empty Git repository in /root/git_update_index/.git/[root@localhost git_update_index]# find .git/objects/ -type f[root@localhost git_update_index]# echo 'version 1' &gt; text.txt[root@localhost git_update_index]# git statusOn branch masterNo commits yetUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) text.txtnothing added to commit but untracked files present (use "git add" to track)[root@localhost git_update_index]# git update-index --add text.txt[root@localhost git_update_index]# git statusOn branch masterNo commits yetChanges to be committed: (use "git rm --cached &lt;file&gt;..." to unstage) new file: text.txt[root@localhost git_update_index]# find .git/objects/ -type f.git/objects/83/baae61804e65cc73a7201a7252750c76066a30[root@localhost git_update_index]# git cat-file -p 83baae6version 1]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-cat-file 命令]]></title>
    <url>%2F2019%2F07%2F07%2Fgit%2Fgit-cmd-cat-file%2F</url>
    <content type="text"><![CDATA[该命令用于显示指定对象的信息 命令格式12git cat-file (-t [--allow-unknown-type]| -s [--allow-unknown-type]| -e | -p | &lt;type&gt; | --textconv | --filters ) [--path=&lt;path&gt;] &lt;object&gt;git cat-file (--batch | --batch-check) [ --textconv | --filters ] [--follow-symlinks] 命令参数选项 -t: 显示对象类型 -s: 显示对象大小(bytes) -e: 如果对象存在且是有效的，则命令正常返回0；如果对象无效，则命令返回非零值，并在标准错误输入打印错误信息 -p: 显示对象内容 –batch: 从标准输入读取对象id，显示对象信息(类型、大小)和对象内容 –batch-check: 从标准输入读取对象id，显示对象信息(类型、大小) 例子12345678910111213141516171819202122232425262728293031323334[root@localhost gitNewTest]# find .git/objects/ -type f.git/objects/3b/18e512dba79e4c8300dd08aeb37f8e728b8dad[root@localhost gitNewTest]# git cat-file -p 3b18e512hello world[root@localhost gitNewTest]# git cat-file -s 3b18e51212[root@localhost gitNewTest]# git cat-file -t 3b18e512blob[root@localhost gitNewTest]# git cat-file -e 3b18e512[root@localhost gitNewTest]# echo $?0[root@localhost gitNewTest]# git cat-file -e 3b18e513fatal: Not a valid object name 3b18e513[root@localhost gitNewTest]# echo $?128[root@localhost gitNewTest]# git cat-file -t 3b18e513fatal: Not a valid object name 3b18e513[root@localhost gitNewTest]# echo $?128[root@localhost gitNewTest]# git cat-file --batch3b18e5123b18e512dba79e4c8300dd08aeb37f8e728b8dad blob 12hello world3333333333 missing^C[root@localhost gitNewTest]# git cat-file --batch-check3b18e5123b18e512dba79e4c8300dd08aeb37f8e728b8dad blob 12adcesadces missing^C[root@localhost gitNewTest]#]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-hash-object 命令]]></title>
    <url>%2F2019%2F07%2F07%2Fgit%2Fgit-cmd-hash-object%2F</url>
    <content type="text"><![CDATA[该命令可以计算指定对象的object ID，并且通过指定参数(-w)将指定对象写入数据库中。该ID是个SHA-1哈希值，通过将待存储的数据内容(指定对象内容)加一个头部信息(header)一起做SHA-1校验运算得到的校验和。 命令格式12git hash-object [-t &lt;type&gt;] [-w] [--path=&lt;file&gt;|--no-filters] [--stdin [--literally]] [--] &lt;file&gt;…​git hash-object [-t &lt;type&gt;] [-w] --stdin-paths [--no-filters] 命令参数选项 -t &lt;type>: 对象类型， 默认为数据对象blob object -w: 设置该参数表示要将对象内容写入数据库 –stdin: 表示从标准输入读取对象内容 –stdin-paths: 表示从标准输入读取保存对象内容的文件名，每行表示一个文件 –: 标记后续参数类型，即 – 后面的参数会被解析为file 例子123456789101112131415161718192021[root@localhost gitNewTest]# find .git/objects -type f# 从标准输入读取内容写入数据库[root@localhost gitNewTest]# echo "hello world" |git hash-object -w --stdin3b18e512dba79e4c8300dd08aeb37f8e728b8dad[root@localhost gitNewTest]# find .git/objects -type f.git/objects/3b/18e512dba79e4c8300dd08aeb37f8e728b8dad[root@localhost gitNewTest]# tree .git/objects/.git/objects/├── 3b # SHA-1哈希值前两个字符做目录│ └── 18e512dba79e4c8300dd08aeb37f8e728b8dad # SHA-1哈希值剩余38个字符做文件名├── info└── pack3 directories, 1 file# 从文件中读取内容写入数据库[root@localhost gitNewTest]# echo 'version 1' &gt; text.txt[root@localhost gitNewTest]# cat text.txtversion 1[root@localhost gitNewTest]# git hash-object -w text.txt83baae61804e65cc73a7201a7252750c76066a30]]></content>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[epel配置与使用]]></title>
    <url>%2F2019%2F06%2F30%2Fcentos%2Fepel%2F</url>
    <content type="text"><![CDATA[为了保证稳定性，RHEL及其衍生版本Centos等的官方rpm repository中提供的软件版本都相对比较滞后。为了能使用相对较新的软件版本，可以使用EPEL扩展源。 EPEL(Extra Packages for Enterprise Linux)，是由Fedora社区维护的，为RHEL系列操作系统提供高质量软件包的项目。 yum命令安装1yum -y install epel-release rpm包安装根据系统CPU架构及操作系统版本，到 https://dl.fedoraproject.org/pub/epel/ 下载对应的rpm进行安装。 12wget wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpmrpm -ivh epel-release-latest-7.noarch.rpm 或 1yum -y install http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm 验证12345678910111213$ yum clean all; yum makecache$ yum repolistLoading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: mirrors.tuna.tsinghua.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.aliyun.comrepo id repo name statusbase/7/x86_64 CentOS-7 - Base - mirrors.aliyun.com 10,019epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 13,242extras/7/x86_64 CentOS-7 - Extras - mirrors.aliyun.com 419updates/7/x86_64 CentOS-7 - Updates - mirrors.aliyun.com 2,137repolist: 25,817]]></content>
      <tags>
        <tag>epel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git内部原理]]></title>
    <url>%2F2019%2F06%2F30%2Fgit%2Fgit-internals%2F</url>
    <content type="text"><![CDATA[概述Git从根本上说是一个基于内容寻址(content-addressable)的文件系统，并在此之上提供一个VCS的用户界面。 最初git只是为VCS提供的一套工具集，而不是一个完成的VCS，所以git存在一系列命令能完成一些底层操作，这些命令被设计为能以Unix-style连接(chained)在一起，或者可以被脚本调用。这些命令被称为底层(plumbing)命令。相对应的那些更友好(user-friendly)的命令被称为高层(porcelain)命令。 通常情况下，不会在命令行中直接使用这些底层命令，它们更多被用于构建新的命令或用于自定义的脚本。 .git目录在执行完git init命令后，会生成一个.git目录。该目录里面包含了几乎所有的git存储和操作的对象。如果你想备份或克隆一个你的repo，只需要将copy该目录即可。 一个已经有提交记录的.git目录内容如下: 123456789101112131415161718192021222324252627282930313233[root@localhost .git]# tree -F ..├── branches/├── config # 包含所有特有(project-specific)的配置项├── description # 该文件仅用于GitWeb程序，无需关注├── HEAD # imp├── hooks/ # 保存服务端和客户端的git钩子脚本├── index # imp├── info/ # 该目录下的exclude文件用于保存不希望配置在.gitignore文件中的忽略模式│ └── exclude├── logs/│ ├── HEAD│ └── refs/│ ├── heads/│ │ └── master│ └── remotes/│ └── origin/│ └── HEAD├── objects/ # imp, 存储所有的数据内容，包括所有文件的历史版本和commit信息│ ├── info/│ └── pack/│ ├── pack-de504965c4952729b475b8075c814b171ef83bf8.idx│ └── pack-de504965c4952729b475b8075c814b171ef83bf8.pack├── packed-refs└── refs/ # imp ├── heads/ │ └── master ├── remotes/ │ └── origin/ │ └── HEAD └── tags/16 directories, 24 files 文件HEAD、index和目录objects、refs是git系统的核心组成部分。 git初始化时的.git目录如下： 123456789101112131415[root@localhost .git]# tree -F ..├── branches/├── config├── description├── HEAD├── hooks/├── info/│ └── exclude├── objects/│ ├── info/│ └── pack/└── refs/ ├── heads/ └── tags/ git对象数据对象(blob object)通过 git hash-object 将文件内容写入数据库，生成的就是数据对象，可以通过 git cat-file -t 查看对象类型 123456789101112131415161718192021222324252627# 创建一个新文件，将文件内容写入数据库[root@localhost gitNewTest]# echo 'version 1' &gt; text.txt[root@localhost gitNewTest]# cat text.txtversion 1# 将文件内容写入数据库，生成一个数据对象[root@localhost gitNewTest]# git hash-object -w text.txt83baae61804e65cc73a7201a7252750c76066a30[root@localhost gitNewTest]# find .git/objects -type f.git/objects/83/baae61804e65cc73a7201a7252750c76066a30# 修改文件内容，将修改后的文件再次写入数据库，又会生成一个数据对象[root@localhost gitNewTest]# echo 'version 2' &gt; text.txt[root@localhost gitNewTest]# git hash-object -w text.txt1f7a7a472abf3dd9643fd615f6da379c4acb3e3a[root@localhost gitNewTest]# find .git/objects -type f.git/objects/83/baae61804e65cc73a7201a7252750c76066a30.git/objects/1f/7a7a472abf3dd9643fd615f6da379c4acb3e3a[root@localhost gitNewTest]# cat text.txtversion 2# 将第一个版本的内容从数据库中读出再次写回文件[root@localhost gitNewTest]# git cat-file -p 83baae6 &gt; text.txt[root@localhost gitNewTest]# cat text.txtversion 1# 查看对象内容均为数据对象[root@localhost gitNewTest]# git cat-file -t 83baae6blob[root@localhost gitNewTest]# git cat-file -t 1f7a7a4blob 使用上述方式，只能保存文件内容，不能保存文件名称。可以使用下面的树对象实现文件名保存。 树对象(tree object)git以一种类似Unix文件系统的方式存储内容。所有内容均以树对象和数据对象的形式存储，树对象对应了Unix中的目录项，数据对象大致对应了inodes或文件内容。 一个树对象包含了一条或多条树对象记录(tree entry)，每条记录对应一个指向数据对象或子树对象的SHA-1指针，以及对应的模式、类型、文件名信息。 提交对象(commit object)标签对象(tag object)参考资料 ProGit]]></content>
      <tags>
        <tag>git</tag>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-diff命令]]></title>
    <url>%2F2019%2F06%2F29%2Fgit%2Fgit-cmd-diff%2F</url>
    <content type="text"><![CDATA[命令格式12345678git diff [&lt;options&gt;] [--] [&lt;path&gt;..] # 默认表示比较工作区与暂存区git diff [&lt;options&gt;] HEAD [--] [&lt;path&gt;..] # 表示比较工作区与本地版本库最新版本git diff [&lt;options&gt;] commitid [--] [&lt;path&gt;..] # 表示比较工作区与指定commit id版本git diff [&lt;options&gt;] --cached [--] [&lt;path&gt;..] # 表示比较暂存区与本地库最新版本git diff [&lt;options&gt;] --cached commitid [--] [&lt;path&gt;..] # 表示比较暂存区与指定commit id版本git diff [&lt;options&gt;] commitid commitid [--] [&lt;path&gt;..] # 表示比较两次commitid之间的差异 命令参数选项 –raw: 显示原始的差异格式，如下: 123[root@localhost gitTest]# git diff --cached --raw:000000 100644 0000000 31d115c A addfile:100644 100644 389cecf 1f09c93 M newfile2 –stat: 显示差异统计结果，如下： 1234[root@localhost gitTest]# git diff --cached --stataddfile | 5 +++++newfile2 | 3 +--2 files changed, 6 insertions(+), 2 deletions(-) –shortstat: 只显示--stat的最后一行内容 12[root@localhost gitTest]# git diff --cached --shortstat2 files changed, 6 insertions(+), 2 deletions(-) –numstat: 只显示增加和删除的行数统计 123[root@localhost gitTest]# git diff --cached --numstat5 0 addfile1 2 newfile2 –name-only: 只显示哪些文件有差异 123[root@localhost gitTest]# git diff --cached --name-onlyaddfilenewfile2 使用git diff打补丁将工作区与本地仓库的差异做成补丁git diff &gt; patch_name 检验补丁是否能使用，如果没有任何输出表示可以顺利接受该补丁git apply –check patch_name 在另外一个地方应用补丁git apply patch_name 命令回显说明git diff命令的回显采用的时GNU diff命令合并格式的变体 linux下通过diff -u file_a file_b来显示diff的合并格式 内容增删12345678910111213141516171819202122232425262728293031&gt; git diff HEAD~1 HEADdiff --git a/README.md b/README.md # 表示显示内容为git格式的diffindex ae50fdb..54e2aab 100644 # ae50fab..54e2aab表示两个版本对象的哈希值 # 100644表示对象的模式(普通文件， 644权限)--- a/README.md # --- 表示变动前的版本+++ b/README.md # +++ 表示变动后的版本@@ -5,6 +5,7 @@ # 该行表示变动的位置，由两个@表示开头和结尾 # - 表示 文件a/README.md， + 表示文件b/README.md # 5,6 表示下方显示内容为a/README.md的第5行开始，连续6行 # 5,7 表示下方显示内容为b/README.md的第5行开始，连续7行 b c d+new line e f gdiff --git a/newfile b/newfileindex fd54aa0..2d3a259 100644--- a/newfile+++ b/newfile@@ -1,5 +1,7 @@ add new file 1-2-3++ds+honda+toyta 新增文件1234567891011diff --git a/newfile3 b/newfile3new file mode 100644index 0000000..d4afdcc--- /dev/null+++ b/newfile3@@ -0,0 +1,5 @@+add new file3++new file++new file end 删除文件12345678910111213diff --git a/newfile b/newfiledeleted file mode 100644index 2d3a259..0000000--- a/newfile+++ /dev/null@@ -1,7 +0,0 @@-add new file-1--ds-honda-toyta- 重命名文件12345678910111213141516diff --git a/deletefile b/newfile2similarity index 89%rename from deletefilerename to newfile2index 08cb754..389cecf 100644--- a/deletefile+++ b/newfile2@@ -1,8 +1,6 @@ file tobe rename 1 2-3-4 5 6 7]]></content>
      <tags>
        <tag>git</tag>
        <tag>diff</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用总结]]></title>
    <url>%2F2019%2F06%2F29%2Fgit%2Fgit-usage%2F</url>
    <content type="text"><![CDATA[githubProGit 常用术语 VCS: Version Control System 版本控制系统 DVCS: Distributed Version Control System 分布式版本控制系统 CVCS: Centralized Version Control System 中心式版本控制系统 源码安装安装依赖 123yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc xmlto docbook2xatp-get install libcurl4-gnutls-dev libexpat1-dev gettext libz-dev libssl-dev asciidoc xmlto docbook2x 编码编译安装 1234567wget https://github.com/git/git/archive/v2.22.0.tar.gztar xvf v2.22.0.tar.gzcd git-2.22.0make configure./configure --prefix=/usrmake all doc infomake install install-doc install-html install-info 常见问题多平台的换行问题git调试方法在执行git命令前可以通过设置环境变量GIT_TRACE=1和GIT_CURL_VERBOSE=1来增加命令执行的调试信息 Git内部原理Git命令高层命令git diffgit commitgit log底层命令git最核心部分是一个key-value的数据库。 hash-object命令cat-object命令update-index命令ls-files命令]]></content>
      <tags>
        <tag>总结</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[groovy闭包]]></title>
    <url>%2F2019%2F06%2F13%2Fgroovy%2Fgroovy-closure%2F</url>
    <content type="text"><![CDATA[闭包定义在计算机科学中，闭包（英语：Closure），又称词法闭包（Lexical Closure）或函数闭包（function closures），是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。 彼得·兰丁在1964年将术语“闭包”定义为一种包含环境成分和控制成分的实体。用来指代某些其开放绑定（自由变量）已经由其语法环境完成闭合（或者绑定）的lambda表达式，从而形成了闭合的表达式，或称闭包。 闭包只是在形式和表现上像函数，但实际上不是函数。函数是一些可执行的代码，这些代码在函数被定义后就确定了，不会在执行时发生变化，所以一个函数只有一个实例。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。所谓引用环境是指在程序执行中的某个点所有处于活跃状态的约束所组成的集合。其中的约束是指一个变量的名字和其所代表的对象之间的联系。 在函数定义时捕获当时的引用环境，并与函数代码组合成一个整体。当把这个整体当作函数调用时，先把其中的引用环境覆盖到当前的引用环境上，然后执行具体代码，并在调用结束后恢复原来的引用环境。这样就保证了函数定义和执行时的引用环境是相同的。这种由引用环境与函数代码组成的实体就是闭包。 自由变量是指除局部变量以外的变量。 Groovy闭包定义Groovy中的闭包是一个开放的、匿名代码块，它可以接收参数，定义返回值，也可以将闭包复制给变量，闭包还可以引用定义在其周围范围(in its surrounding scope)中的变量。与闭包的正式定义相反，Groovy语言中的闭包还可以包含定义在其周围范围之外(outside of its surrounding scope)的自由变量。 Groovy闭包语法1234567891011121314151617181920212223242526272829303132333435363738&#123; [closureParameters -&gt;] statements&#125;// examples&#123; item++ &#125; // 引用变量item// 默认参数it// 如果闭包执行时未指定参数，则it为null，类型class org.codehaus.groovy.runtime.NullObject&#123; println it&#125;//显示指定参数&#123;name -&gt; println name&#125;//指定多个具有类型的参数def body = &#123;String name, int age -&gt; println "name: $&#123;name&#125;, age:$&#123;age&#125;"&#125;//闭包是groovy.lang.Closure类型的实例assert body instanceof Closure//参数可以指定默认值def sum = &#123; int a, int b=2 -&gt; a+b &#125;//可以指定闭包的返回值类型Closure&lt;Boolean&gt; isTextFile = &#123; File it -&gt; it.name.endsWith('.txt')&#125;//如果要明确指定闭包不包含参数，需要显示的指定空参数列表def magicNumber = &#123; -&gt; 42 &#125;// this call will fail because the closure doesn't accept any argumentmagicNumber(11)//闭包的可以指定最后一个参数的长度是可变的或定义为数组def concat1 = &#123;String... args -&gt; args.join('')&#125;assert concat1('abc', 'def') == 'abcdef'def concat2 = &#123;String[] args -&gt; args.join('')&#125;assert concat2('aaa', 'bbb') == 'aaabbb'//闭包的执行也可以使用call()def multiConcat = &#123;int n, String... args -&gt; args.join('')*n&#125;assert multiConcat.call(3, 'ab', 'cd') == 'abcdabcdabcd' closureParameters是可选的逗号分隔的参数列表，参数可以指定类型(typed)也可不指定类型(untyped)。如果指定了参数，参数后面必须有 -&gt;，用于分割参数和闭包内语句。 闭包执行时，总是会有返回值。 Groovy闭包委托策略(Delegation strategy)委托(Delegation)是Groovy闭包中的一个关键特性(key concept)，闭包委托策略的可修改使得在Groovy中设计漂亮的领域特定语言(dsl, domain specific language)成为可能。 this、owner、delegate闭包内有三个内置对象: this 对应于定义闭包的封闭类(the enclosing class where the closure is defined),可以在闭包内通过getThisObject()获取 owner 对应于定义闭包的封闭对象(the enclosing object where the closure is defined)，可以是类也可以是闭包，可以在闭包内通过getOwner()获取 delegate 对应于一个第三方对象(where methods calls or properties are resolved whenever the receiver of the message is not defined)，可以在闭包内通过(getDelegate())获取 通过这三个内置对象，闭包可以调用对应对象的属性和方法。 this对应于定义闭包的封闭类12345678910111213141516171819202122// 在TestThis类中定义闭包body，并返回闭包的this对象class TestThis&#123; void run() &#123; def body = &#123;getThisObject()&#125; // 调用闭包会返回TestThis类的实例 assert body() == this // 在闭包中直接使用this对象与调用getThisObject等价 def body2 = &#123; this &#125; assert body2 == this &#125;&#125;class ClosureTest &#123; static void main(String... args) &#123; def body = &#123; this &#125; println body() == this // true println this // class ClosureTest println(this.getClass().toString()) // class java.lang.Class println(body.getClass().toString()) // class ClosureTest$_main_closure1 println body instanceof Closure // true &#125;&#125; 如果闭包在内部类中定义，那么闭包中的 this 对象返回的是内部类的实例对象1234567891011121314151617class ClosureTest &#123; class InnerClass &#123; def body = &#123; this &#125; &#125; void run()&#123; InnerClass inner = new InnerClass() println inner == inner.body() // true println this == inner.body() // false println this.getClass().toString() // class ClosureTest println inner.getClass().toString() // class ClosureTest$InnerClass println inner.body.getClass().toString() // class ClosureTest$InnerClass$_closure1 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 如果闭包A嵌入在类的某个闭包B中时，闭包A中的 this 表示的仍然是类的实例对象12345678910111213141516class ClosureTest &#123; void run()&#123; def body_b = &#123; def body_a = &#123; this &#125; body_a() &#125; println body_b() // ClosureTest@25748410 println this // ClosureTest@25748410 println body_b() == this // true println this.getClass().toString() // class ClosureTest &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; owner返回闭包定义所在的封闭对象，可以是类也可以是闭包。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 普通类class ClosureTest &#123; void run()&#123; def body_b = &#123; owner &#125; println body_b() // ClosureTest@55b5f5d2 println body_b // ClosureTest$_run_closure1@5bfa8cc5 println this // ClosureTest@55b5f5d2 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125;// 内部类class ClosureTest &#123; class InnerClass &#123; def body = &#123; owner &#125; &#125; void run() &#123; def inner = new InnerClass() println inner // ClosureTest$InnerClass@553f1d75 println inner.body() // ClosureTest$InnerClass@553f1d75 println this // ClosureTest@47404bea &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125;// 嵌套闭包class ClosureTest &#123; void run()&#123; def body_b = &#123; def body_a = &#123; owner &#125; println body_a // ClosureTest$_run_closure1$_closure2@5bfa8cc5 println body_a() // ClosureTest$_run_closure1@16ecee1 body_a() &#125; println body_b() // ClosureTest$_run_closure1@16ecee1 println body_b // ClosureTest$_run_closure1@16ecee1 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; delegate委托是Groovy语言能够构建DSL的关键特性(It is a powerful concept for building domain specific languages in groovy)。delegate是一个用户自定义的对象。 默认情况下， delegate 等同于 owner123456789101112131415161718192021222324252627class ClosureTest &#123; class InnerClass &#123; def body = &#123; delegate &#125; &#125; void run() &#123; def inner = new InnerClass() println inner // ClosureTest$InnerClass@4f071df8 println inner.body() // ClosureTest$InnerClass@4f071df8 println this // ClosureTest@29e6eb25 def body_b = &#123; def body_a = &#123; delegate &#125; body_a() &#125; println body_b() // ClosureTest$_run$_closure1@38be305c println body_b // ClosureTest$_run$_closure1@38be305c def body_c = &#123; delegate &#125; println body_c() // ClosureTest@29e6eb25 println body_c // ClosureTest$_run$_closure2@5ed731d0 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 闭包中的delegate属性可以被修改为任何对象123456789101112131415161718192021222324252627282930class ClosureTest &#123; class Person &#123; String name &#125; class Animal &#123; String name &#125; void run() &#123; def p = new Person(name: 'john') def a = new Animal(name: 'panda') def nameToUpper = &#123; delegate.name.toUpperCase() &#125; nameToUpper.delegate = p println nameToUpper() // JOHN nameToUpper.delegate = a println nameToUpper() // PANDA println p.name // john println a.name // panda // nameToUpper_use_var引用外部的局部变量p，能够达成和前面使用delegate一样的效果 // 但是委托可以透明的使用，即在闭包中不再显式的采用 delegate. 前缀引用属性或方法，详情见下节委托策略 def nameToUpper_use_var = &#123; p.name.toUpperCase() &#125; println nameToUpper_use_var() // JOHN &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 闭包委托策略在闭包中，如果访问闭包内部未定义的属性或方法时，会涉及到委托策略，委托策略分为下面几种: Closure.OWNER_FIRST: 默认策略。优先在owner中查找，如果没有找到则在delegate中查找 Closure.DELEGATE_FIRST: 优先在delegate中查找, 如果没有找到则在owner中查找 Closure.OWNER_ONLY: 忽略delegate，只在owner中查找 Closure.DELEGATE_ONLY: 忽略owner, 只在delegate中查找 Closure.TO_SELF: 只有在实现自己的闭包子类时才有意义。在需要高级元编程(meta-programming)技术，希望实现自定义的解析策略: 属性或方法的解析既不使用owner也不使用delegate，only on the closure class itself. DELEGATE_FIRST 与 OWNER_FIRST1234567891011121314151617181920212223242526272829303132333435class ClosureTest &#123; class Person &#123; String name def output = &#123; "My name is $&#123;name&#125;" &#125; String outputstring() &#123; output() &#125; &#125; class Animal &#123; String name &#125; void run() &#123; def p = new Person(name: 'john') def a = new Animal(name: 'panda') println p.output.owner // ClosureTest$Person@3234f74a println p.output.delegate // ClosureTest$Person@3234f74a // 默认委托策略为owner_first所以从p中查找name属性 println p.outputstring() // My name is john p.output.delegate = a println p.output.owner // ClosureTest$Person@3234f74a println p.output.delegate // ClosureTest$Animal@65aa6596 // 只修改了delegate属性，但策略没变，仍然从p中查找name属性 println p.outputstring() // My name is john // 修改委托策略为delegate_first p.output.resolveStrategy = Closure.DELEGATE_FIRST // 从a中查找name属性 println p.outputstring() // My name is panda &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; DELEGATE_FIRST 与 DELEGATE_OWNER123456789101112131415161718192021222324252627282930313233class ClosureTest &#123; class Person &#123; String name int age def output = &#123; "$&#123;name&#125; age is $&#123;age&#125;" &#125; String outputstring() &#123; output() &#125; &#125; class Animal &#123; String name &#125; void run() &#123; def p = new Person(name: 'john', age: 18) def a = new Animal(name: 'panda') println p.outputstring() // john age is 18 p.output.delegate = a println p.outputstring() // john age is 18 p.output.resolveStrategy = Closure.DELEGATE_ONLY p.output.delegate = p println p.outputstring() // john age is 18 p.output.delegate = a // exception: // groovy.lang.MissingPropertyException: No such property: age for class: ClosureTest println p.outputstring() &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 闭包委托策略具有传递性闭包A内嵌与闭包B时，如果闭包A中的某个属性在闭包B中没有解析到会继续向闭包B的owner或delegate中查找。具体是向闭包的B的owner还是delegate中查找，由闭包B的委托策略决定 12345678910111213141516171819202122232425262728293031323334class ClosureTest &#123; class Person &#123; String name int age def outerClosure = &#123; // outerClosure为innerClosure的owner def name = "outer_$&#123;name&#125;" def innerClosure = &#123; // innerClosure闭包中的name和age属性都不在闭包内定义 // 默认从innerClosure.owner中查找 // outerClousre.name // p.age "$&#123;name&#125;'s age is $&#123;age&#125;" &#125; println innerClosure.owner // ClosureTest$Person$_closure1@26a4842b println innerClosure.delegate == innerClosure.owner // ture innerClosure() &#125; &#125; void run() &#123; def p = new Person(name: 'john', age: 18) println p // ClosureTest$Person@5ed731d0 // p.outerClosure的owner为 p println p.outerClosure // ClosureTest$Person$_closure1@26a4842b println p.outerClosure.delegate == p // true println p.outerClosure.owner == p // true println p.outerClosure() // outer_john's age is 18 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 1234567891011121314151617181920212223242526class ClosureTest &#123; class Person &#123; String name int age def outerClosure = &#123; def name = "outer_$&#123;name&#125;" def innerClosure = &#123; "$&#123;name&#125;'s age is $&#123;age&#125;" &#125; innerClosure() &#125; &#125; void run() &#123; def p = new Person(name: 'john', age: 18) def p2 = new Person(name: 'jessica', age: 3) println p.outerClosure() // outer_john's age is 18 p.outerClosure.resolveStrategy = Closure.DELEGATE_FIRST p.outerClosure.delegate = p2 println p.outerClosure() // outer_jessica's age is 3 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 闭包策略在Jenkins pipeline中的典型应用12345678910111213141516171819// vars/abc.groovydef call(body) &#123; def config = [:] // 修改body闭包的委托策略和delegate属性 body.resolveStrategy = Closure.DELEGATE_FIRST body.delegate = config // 闭包执行时，闭包中读取未定义的属性时都会从config中获取 // 闭包中设置未定义的属性时都也会设置到config中 body() // 后续就可以通过config.branch访问Jenkinsfile中定义并传给abc.groovy的值 println config // [branch: 'master']&#125;// Jenkinsfileabc &#123; // 通常设置某些属性值，可以实现传参效果 branch = 'master'&#125; 参考资料维基百科-闭包 闭包的概念、形式与应用 (IBM DeveloperWorks) Groovy-Closure]]></content>
      <tags>
        <tag>groovy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[groovy使用总结]]></title>
    <url>%2F2019%2F06%2F13%2Fgroovy%2Fgroovy-usage%2F</url>
    <content type="text"><![CDATA[Apache Groovy基于Java平台的一种功能强大、可选类型的动态语言。它的目的在于通过简洁、熟悉和易于学习的语法来提升开发人员的效率。Groovy代码动态地编译成运行于Java虚拟机（JVM）上的Java字节码，并可以与其他Java代码和库进行互操作。由于其运行在JVM上的特性，Groovy可以使用其他Java语言编写的库。 官网文档 闭包grape依赖管理动态替换yaml文件中的变量]]></content>
      <tags>
        <tag>总结</tag>
        <tag>groovy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd_introduce]]></title>
    <url>%2F2019%2F06%2F02%2Fetcd%2Fetcd-introduce%2F</url>
    <content type="text"><![CDATA[官网github 简介etcd官方定义为一个分布式的可信的键值存储服务，用于存储分布式系统中的一些关键数据。其主要特性包括: Simple 简单: 包含一套定义良好、面向用户的API(gRpc) Secure 安全: 支持可选择客户端证书认证的TLS Fast 快速: 基准测试可达10,000写每秒 Reliable 可靠: properly distributed using Raft etcd是使用Go语言编写，采用Raft共识算法管理高可用的replicated log。 安装 最简单的方式是在github的release中下载预编译(pre-built)好的二进制 源码安装a) etcd源码安装时对go版本通常都有要求，请参照github中说明b) 为了确保etcd编译正确，etcd提供了官方release版本的依赖。当然是否使用官方提供的依赖是可选的。 部署预置条件]]></content>
      <tags>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAVEN POM]]></title>
    <url>%2F2019%2F06%2F01%2Fmaven%2Fmaven-pom%2F</url>
    <content type="text"><![CDATA[Maven的超级POM(Project Object Model)位于${M2_HOME}/lib/maven-model-builder-xxx.jar构件中org.apache.maven.model.pom-4.0.0.xml其中包含了Maven用于构建项目有关的项目信息以及配置细节，它包含了大多数项目的默认值。超级POM是Maven的默认POM，除非显式设置(POM中的&lt;parent>配置)，否则所有的POM都会扩展超级POM，也就是说项目POM默认都会继承超级POM中的配置。 POM最小内容123456&lt;project&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1&lt;/version&gt;&lt;/project&gt; modelVersion内容要设置为4.0.0。groupId、artifactId和version三个元素定义了项目的坐标。 ### Super POM(3.6.1)内容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- START SNIPPET: superpom --&gt;&lt;project&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Maven Repository Switchboard&lt;/name&gt; &lt;url&gt;http://repo1.maven.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Maven Plugin Repository&lt;/name&gt; &lt;url&gt;http://repo1.maven.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;build&gt; &lt;directory&gt;$&#123;project.basedir&#125;/target&lt;/directory&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/classes&lt;/outputDirectory&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;-$&#123;project.version&#125;&lt;/finalName&gt; &lt;testOutputDirectory&gt;$&#123;project.build.directory&#125;/test-classes&lt;/testOutputDirectory&gt; &lt;sourceDirectory&gt;$&#123;project.basedir&#125;/src/main/java&lt;/sourceDirectory&gt; &lt;scriptSourceDirectory&gt;src/main/scripts&lt;/scriptSourceDirectory&gt; &lt;testSourceDirectory&gt;$&#123;project.basedir&#125;/src/test/java&lt;/testSourceDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/test/resources&lt;/directory&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;pluginManagement&gt; &lt;!-- NOTE: These plugins will be removed from future versions of the super POM --&gt; &lt;!-- They are kept for the moment as they are very unlikely to conflict with lifecycle mappings (MNG-4453) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;version&gt;1.3&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.2-beta-5&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-release-plugin&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; &lt;reporting&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/site&lt;/outputDirectory&gt; &lt;/reporting&gt; &lt;profiles&gt; &lt;!-- NOTE: The release profile will be removed from future versions of the super POM --&gt; &lt;profile&gt; &lt;id&gt;release-profile&lt;/id&gt; &lt;activation&gt; &lt;property&gt; &lt;name&gt;performRelease&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;/activation&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-javadocs&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;updateReleaseInfo&gt;true&lt;/updateReleaseInfo&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt;&lt;!-- END SNIPPET: superpom --&gt;]]></content>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pipeline并行任务配置]]></title>
    <url>%2F2019%2F05%2F30%2Fjenkins%2Fjenkins-pipeline-parallel%2F</url>
    <content type="text"><![CDATA[静态并行任务配置声明式 在stage中可以通过parallel块来嵌套多个stage实现并行运行 parallel块中的stage除了不能再次嵌套parallel外和普通stage一样，也可以通过stages包含一些列顺序执行的stage 每个stage中有且只能有一个steps、stages或者parallel 所有包含parallel的stage都不能包含agent和tools EXAMPLE-1 stage级别并行123456789101112131415161718192021222324252627282930313233pipeline &#123; agent any options &#123; timestamps() &#125; stages &#123; stage(&apos;init&apos;) &#123; steps &#123; echo &quot;init start&quot; sleep 5 echo &apos;init end&apos; &#125; &#125; stage(&apos;build&apos;) &#123; parallel &#123; stage(&apos;x86 build&apos;) &#123; steps &#123; echo &apos;x86 build start&apos; sleep 5 echo &apos;x86 build end&apos; &#125; &#125; stage(&apos;arm build&apos;) &#123; steps &#123; echo &apos;arm build start&apos; sleep 3 echo &apos;arm build end&apos; &#125; &#125; &#125; &#125; &#125;&#125; blueOcean如下图所示 EXAMPLE-2 并行stage中多个stage串行1234567891011121314151617181920212223242526272829303132333435363738394041424344454647pipeline &#123; agent any options &#123; timestamps() &#125; stages &#123; stage(&apos;init&apos;) &#123; steps &#123; echo &quot;init start&quot; sleep 5 echo &apos;init end&apos; &#125; &#125; stage(&apos;build&apos;) &#123; parallel &#123; stage(&apos;x86 build&apos;) &#123; agent &#123; label &apos;master&apos; &#125; steps &#123; echo &apos;x86 build start&apos; sleep 5 echo &apos;x86 build end&apos; &#125; &#125; stage(&apos;arm build&apos;) &#123; stages &#123; stage(&apos;arm-master build&apos;) &#123; steps &#123; echo &apos;arm master build start&apos; sleep 3 echo &apos;arm master build end&apos; &#125; &#125; stage(&apos;arm develop build&apos;) &#123; steps &#123; echo &apos;arm develop build start&apos; sleep 3 echo &apos;arm develop build end&apos; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; blueOcean如下图所示 EXAMPLE-4 step级别并行12345678910111213141516171819202122232425262728pipeline &#123; agent any options &#123; timestamps() &#125; stages &#123; stage(&apos;init&apos;) &#123; steps &#123; echo &quot;init start&quot; sleep 5 echo &apos;init end&apos; &#125; &#125; stage(&apos;build&apos;) &#123; steps &#123; parallel &apos;x86 build&apos;: &#123; echo &apos;x86 build start&apos; sleep 3 echo &apos;x86 build end&apos; &#125;, &apos;arm build&apos;: &#123; echo &apos;arm build start&apos; sleep 3 echo &apos;arm build end&apos; &#125; &#125; &#125; &#125;&#125; blueOcean如下图所示 脚本式EXAMPLE-312345678910111213141516171819202122232425script &#123; node(&apos;master&apos;) &#123; stage(&apos;init&apos;) &#123; echo &apos;init&apos; &#125; stage(&apos;build&apos;) &#123; parallel &apos;build x86&apos;: &#123; stage(&apos;build x86 step1&apos;) &#123; echo &apos;build x86 step1 start&apos; sleep 5 echo &apos;build x86 step1 end&apos; &#125; stage(&apos;build x86 step2&apos;) &#123; echo &apos;build x86 step 2 start&apos; sleep 5 echo &apos;build x86 step 2 end&apos; &#125; &#125;, &apos;build arm&apos;: &#123; echo &apos;build arm start&apos; sleep 6 echo &apos;build arm end&apos; &#125; &#125; &#125;&#125; blueOcean如下图所示 动态创建并行任务EXAMPLE-51234567891011121314151617181920212223242526272829303132333435363738def jobs = [&apos;jobA&apos;, &apos;jobB&apos;, &apos;jobC&apos;]def parallelStagesMap = jobs.collectEntries &#123; def jobName -&gt; [&quot;$&#123;jobName&#125;&quot;, generateJobStage(jobName)]&#125;def generateJobStage(String jobName) &#123; return &#123; node(&apos;master&apos;) &#123; stage(&quot;stage: $&#123;jobName&#125;&quot;) &#123; echo &quot;$&#123;jobName&#125; start&quot; sleep 5 echo &quot;job end&quot; &#125; &#125; &#125;&#125;pipeline &#123; agent any options &#123; timestamps() &#125; stages &#123; stage(&apos;non-parallel stage&apos;) &#123; steps &#123; echo &apos;this is non-parallel stage&apos; &#125; &#125; stage(&apos;parallel stage&apos;) &#123; steps &#123; script &#123; parallel parallelStagesMap &#125; &#125; &#125; &#125;&#125;]]></content>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven 使用总结]]></title>
    <url>%2F2019%2F05%2F23%2Fmaven%2Fmaven-usage%2F</url>
    <content type="text"><![CDATA[maven官方文档易百教程maven库查询 安装下载二进制包后解压即可，然后配置环境变量 12echo 'export M2_HOME=/usr/local/apache_maven_xxx' &gt;&gt; /etc/profileecho 'export PATH=$M2_HOME/bin:$PATH' &gt;&gt; /etc/profile 执行mvn -v查看版本，同时确认是否安装配置OK 配置超级POM配置文件maven的配置文件有三个级别 项目级，位于项目workspace目录下的pom.xml 用户级，位于~/.m2/settings.xml，通过mvn -s /path/to/settings.xml可以覆盖用户级配置文件 全局级，位于${M2_HOME}/conf/settings.xml，通过mvn -gs /path/to/settings.xml可以覆盖全局配置文件 配置项目 标签 类型 说明 localRepository String 本地仓库路径，默认位于~/.m2/repository mirrors List&lt;mirror> 配置仓库的下载镜像 mirrorOf配置 * = everything external:* = everything not on the localhost and not file based. repo,repo1 = repo or repo1 *,!repo1 = everything except repo1 镜像设置阿里镜像公共代理库使用文档 12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimavenpublic&lt;/id&gt; &lt;name&gt;aliyun maven public&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/repository/public&lt;/url&gt; &lt;mirrorOf&gt;central,jcenter&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;/mirrors&gt; 华为镜像12345&lt;mirror&gt; &lt;id&gt;huaweicloud&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;https://mirrors.huaweicloud.com/repository/maven/&lt;/url&gt;&lt;/mirror&gt; Maven仓库对于Maven来说，仓库只有两类: 本地仓库和远程仓库。当Maven根据坐标寻找构件时，首先查找本地仓库，如果本地仓库存在此构件，则直接使用；如果本地仓库没有此构件，或需要查看构件是否有更新，Maven会去远程仓库查找，找到后下载到本地仓库再使用，如果没有找到则报错。 对于远程仓库，根据仓库的提供者又可以分为: 中央仓库、其他公开库和私服中央仓库是Maven自带的远程仓库，它包含了绝大部分开源的构件。默认情况下，当本地仓库没有找到需要的构件时，Maven会尝试从中央仓库下载。 Maven常用命令Help命令查看某个插件的详情1mvn help:describe -Dplugin=xxx -Ddetail plugin可以使用下面三种方式指定: 插件前缀, 如 ‘help’ groupId:artifactId, 如 ‘org.apache.maven.plugins:maven-help-plugin’ groupId:artifactId:version, 如 ‘org.apache.maven.plugins:maven-help-plugin:2.0’ 查看某个插件的指定命令的帮助1mvn archetype:help -Ddetail -Dgoal=generate 使用archetype创建Maven项目12mvn archetype:generatemvn -U archetype:generate -Dfilter=io.jenkins.archetypes:]]></content>
      <tags>
        <tag>总结</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vm_network]]></title>
    <url>%2F2019%2F05%2F16%2Fvirtualbox%2Fvm-network%2F</url>
    <content type="text"><![CDATA[TODO1TODO2]]></content>
  </entry>
  <entry>
    <title><![CDATA[centos使用总结]]></title>
    <url>%2F2019%2F05%2F15%2Fcentos%2Fcentos-usage%2F</url>
    <content type="text"><![CDATA[如未特殊说明表示使用CentOS 7.6 1810 最小化安装IP配置修改 /etc/sysconfig/network-scripts/ifcfg-xxx 文件 123456789TYPE=EthernetBOOTPROTO=static #网卡引导方式 static/DHCPONBOOT=yes #网卡开机启动IPADDR=192.168.0.150NETMASK=255.255.255.0GATEWAY=192.168.0.1HWADDR=xx:xx:xx:xx:xx:xxDNS1=x.x.x.xDNS2=x.x.x.x 然后重启网络服务 systemctl restart network 配置国内镜像源12345cat /etc/centos-releasemv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bakwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repoyum clean allyum makecache epel扩展源yum命令工具安装与配置openjdk安装通过yum工具安装的位置为 /usr/lib/jvm/java-xxx 123yum install java-11-openjdk-devel.x86_64echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk" &gt;&gt; /etc/profileecho 'export PATH=$JAVA_HOME/bin:$PATH' &gt;&gt; /etc/profile docker安装]]></content>
      <tags>
        <tag>总结</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[makefile使用总结]]></title>
    <url>%2F2019%2F05%2F14%2Fmake%2Fmakefile-usage%2F</url>
    <content type="text"><![CDATA[常用链接跟我一起写Makefile重制版GUN Make手册 makefile中添加打印信息1234warn_msg="warning..."$(info "infomation output")$(warning "warn: $(warn_msg)")$(error "error message") 常用参数 -n, --just-print 打印make过程中执行的所有命令但是并不会真正执行 --print-data-base make过程中会显示GNU信息、执行的命令以及make的内部数据库。数据库里面的数据分为以下几类1) variables 会列出每个变量及描述性注释2) directories 列出了将会被make检查的目录3) implicit rules 包含了所有内置和用户自定义的模式规则4) pattern-specific variables 定义在makefile中的模式专属变量5) files(explicit rules) 与特定文件有关的自定义和后缀规则6) vpath search paths]]></content>
      <tags>
        <tag>总结</tag>
        <tag>make</tag>
        <tag>makefile</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lvm使用]]></title>
    <url>%2F2019%2F05%2F13%2Flinux%2Flvm%2F</url>
    <content type="text"><![CDATA[LVM(Logic Volume Manager)逻辑卷管理，它是linux环境下对磁盘分区进行管理的一种机制。 TODO 基本术语 PV: Physical Volume 物理卷 VG: Volume Group 卷组，由一个或多个PV组成。可以在其上创建一个或多个LV LV: Logical Volume 逻辑卷，在其上可以创建文件系统 PE: Physical Extent 物理扩展盘区，每个PV都会被划分成PE，它是可以被LVM寻址的最小单元 LE: Logical Extent 逻辑扩展盘区， 基本原理1) 物理磁盘被格式化为PV，空间被划分为一个个PE2) 不同的PV加入到同一个VG中，其对应的所有PE都进入VG的PE池中3) LVM从PE池中选择PE创建LV，不同物理盘中的PE可能会划分到同一个LV中4) 在LV上创建文件系统后就可以挂载使用了5) 对LV的扩容和缩减其实就是相应的增加或减少PE数量 创建逻辑卷时，定义了逻辑扩展盘区与物理扩展盘区的映射关系。 创建流程创建分区12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@localhost ~]# fdisk /dev/sdbWelcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Command (m for help): nPartition type: p primary (0 primary, 0 extended, 4 free) e extendedSelect (default p): pPartition number (1-4, default 1): First sector (2048-2097151, default 2048): Using default value 2048Last sector, +sectors or +size&#123;K,M,G&#125; (2048-2097151, default 2097151): +300MPartition 1 of type Linux and of size 300 MiB is setCommand (m for help): pDisk /dev/sdb: 1073 MB, 1073741824 bytes, 2097152 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x233e2ebd Device Boot Start End Blocks Id System/dev/sdb1 2048 616447 307200 83 LinuxCommand (m for help): tSelected partition 1Hex code (type L to list all codes): 8eChanged type of partition 'Linux' to 'Linux LVM'Command (m for help): pDisk /dev/sdb: 1073 MB, 1073741824 bytes, 2097152 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x233e2ebd Device Boot Start End Blocks Id System/dev/sdb1 2048 616447 307200 8e Linux LVMCommand (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. 创建pv12345678910111213141516[root@localhost ~]# pvcreate /dev/sdb1 Physical volume "/dev/sdb1" successfully created.[root@localhost ~]# pvs PV VG Fmt Attr PSize PFree /dev/sdb1 lvm2 --- 300.00m 300.00m[root@localhost ~]# pvdisplay /dev/sdb1 --- Physical volume --- PV Name /dev/sdb1 VG Name vg0 PV Size 300.00 MiB / not usable 4.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 74 Free PE 74 Allocated PE 0 PV UUID 8dqEi7-haMt-ciIM-ib2e-AUxp-f7ym-bCvlfw 创建vg1234567891011121314151617181920212223242526[root@localhost ~]# vgcreate vg0 /dev/sdb1 Volume group "vg0" successfully created[root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree vg0 1 0 0 wz--n- 296.00m 296.00m[root@localhost ~]# vgdisplay vg0 --- Volume group --- VG Name vg0 System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 1 VG Access read/write VG Status resizable MAX LV 0 Cur LV 0 Open LV 0 Max PV 0 Cur PV 1 Act PV 1 VG Size 296.00 MiB PE Size 4.00 MiB Total PE 74 Alloc PE / Size 0 / 0 #已分配的PE数量 Free PE / Size 74 / 296.00 MiB #剩余的PE数量 VG UUID 3FH6og-yXLt-NaL3-uehk-9lrJ-c4TD-r0z6Sa 创建lv12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@localhost ~]# lvcreate -L 100m -n lv0 vg0 Logical volume "lv0" created.[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv0 vg0 -wi-a----- 100.00m [root@localhost ~]# lvdisplay /dev/vg0/lv0 --- Logical volume --- LV Path /dev/vg0/lv0 LV Name lv0 VG Name vg0 LV UUID Plb1kl-JGcg-0UfR-W3Ue-tDBc-D5Tc-tj6X0n LV Write Access read/write LV Creation host, time localhost.localdomain, 2019-05-16 02:02:27 +0800 LV Status available # open 0 LV Size 100.00 MiB Current LE 25 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2[root@localhost ~]# pvdisplay /dev/sdb1 --- Physical volume --- PV Name /dev/sdb1 VG Name vg0 PV Size 300.00 MiB / not usable 4.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 74 Free PE 49 Allocated PE 25 # 可以看到已经有PE被分配出去了 PV UUID 8dqEi7-haMt-ciIM-ib2e-AUxp-f7ym-bCvlfw[root@localhost ~]# vgdisplay vg0 --- Volume group --- VG Name vg0 System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 2 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 0 Max PV 0 Cur PV 1 Act PV 1 VG Size 296.00 MiB PE Size 4.00 MiB Total PE 74 Alloc PE / Size 25 / 100.00 MiB # 可以看到已经有PE被分配出去了 Free PE / Size 49 / 196.00 MiB VG UUID 3FH6og-yXLt-NaL3-uehk-9lrJ-c4TD-r0z6Sa 创建LV时LV的大小有以下两种方式指定 通过-L参数，表示物理大小 通过-l参数，使用相关VG/LV或PV大小的百分比来指定 10%VG, 表示10%的VG总大小 20%FREE, 表示VG中剩余空间的20% 30%PVS, 表示PV集合中剩余空间的30% 该参数后面跟数值(非百分比)时，表示包含多少个PE大小。 12345678910111213[root@localhost ~]# lvremove /dev/vg0/lv0Do you really want to remove active logical volume vg0/lv0? [y/n]: y Logical volume "lv0" successfully removed[root@localhost ~]# lvcreate -l 30%VG -n lv1 vg0 Logical volume "lv1" created.[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-a----- 88.00m [root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- &lt;9.00g 0 vg0 1 1 0 wz--n- 296.00m 208.00m[root@localhost ~]# 格式化文件系统1234567891011121314151617181920212223242526272829303132333435[root@localhost ~]# mkfs.ext3 /dev/vg0/lv1mke2fs 1.42.9 (28-Dec-2013)Filesystem label=OS type: LinuxBlock size=1024 (log=0)Fragment size=1024 (log=0)Stride=0 blocks, Stripe width=0 blocks22528 inodes, 90112 blocks4505 blocks (5.00%) reserved for the super userFirst data block=1Maximum filesystem blocks=6737100811 block groups8192 blocks per group, 8192 fragments per group2048 inodes per groupSuperblock backups stored on blocks: 8193, 24577, 40961, 57345, 73729Allocating group tables: done Writing inode tables: done Creating journal (4096 blocks): doneWriting superblocks and filesystem accounting information: done [root@localhost ~]# fdisk -l /dev/vg0/lv1 Disk /dev/vg0/lv1: 92 MB, 92274688 bytes, 180224 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes[root@localhost ~]# mkdir /usr1[root@localhost ~]# mount /dev/vg0/lv1 /usr1[root@localhost ~]# df -haFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg0-lv1 82M 1.6M 76M 2% /usr1[root@localhost ~]# 扩容扩容LV1234567891011121314151617181920[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-ao---- 88.00m [root@localhost ~]# lvextend -L +100m /dev/vg0/lv1 Size of logical volume vg0/lv1 changed from 88.00 MiB (22 extents) to 188.00 MiB (47 extents). Logical volume vg0/lv1 successfully resized.[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-ao---- 188.00m [root@localhost ~]# df -haFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg0-lv1 82M 1.6M 76M 2% /usr1 # LV已经扩容但是文件系统大小还时原来大小[root@localhost ~]# resize2fs /dev/vg0/lv1 resize2fs 1.42.9 (28-Dec-2013)Filesystem at /dev/vg0/lv1 is mounted on /usr1; on-line resizing requiredold_desc_blocks = 1, new_desc_blocks = 1The filesystem on /dev/vg0/lv1 is now 192512 blocks long.[root@localhost ~]# df -haFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg0-lv1 178M 1.6M 169M 1% /usr1 # 已经扩容 12345678910111213141516[root@localhost ~]# lvs |grep lv1 lv1 vg0 -wi-ao---- 188.00m [root@localhost ~]# lvextend -l +50%FREE /dev/vg0/lv1 Size of logical volume vg0/lv1 changed from 188.00 MiB (47 extents) to 244.00 MiB (61 extents). Logical volume vg0/lv1 successfully resized.[root@localhost ~]# lvs |grep lv1 lv1 vg0 -wi-ao---- 244.00m [root@localhost ~]# df -ha |grep lv1/dev/mapper/vg0-lv1 178M 1.6M 169M 1% /usr1[root@localhost ~]# resize2fs /dev/mapper/vg0-lv1 resize2fs 1.42.9 (28-Dec-2013)Filesystem at /dev/mapper/vg0-lv1 is mounted on /usr1; on-line resizing requiredold_desc_blocks = 1, new_desc_blocks = 1The filesystem on /dev/mapper/vg0-lv1 is now 249856 blocks long.[root@localhost ~]# df -ha |grep lv1/dev/mapper/vg0-lv1 233M 2.1M 220M 1% /usr1 lvextend 中 -L 和 -l 参数中如果没有使用 + 号，则表示扩容到指定大小 扩容VG当VG中没有空闲资源时需要先扩容VG才能扩容LV 123456789101112131415161718192021222324252627[root@localhost ~]# pvs PV VG Fmt Attr PSize PFree /dev/sdb1 vg0 lvm2 a-- 296.00m 52.00m[root@localhost ~]# pvcreate /dev/sdc1 Physical volume "/dev/sdc1" successfully created.[root@localhost ~]# pvs PV VG Fmt Attr PSize PFree /dev/sdb1 vg0 lvm2 a-- 296.00m 52.00m /dev/sdc1 lvm2 --- 511.00m 511.00m[root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree vg0 1 1 0 wz--n- 296.00m 52.00m[root@localhost ~]# vgextend vg0 /dev/sdc1 Volume group "vg0" successfully extended[root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree vg0 2 1 0 wz--n- 804.00m 560.00m[root@localhost ~]# [root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-a----- 244.00m[root@localhost ~]# lvextend -l +100%FREE /dev/vg0/lv1 Size of logical volume vg0/lv1 changed from 244.00 MiB (61 extents) to 804.00 MiB (201 extents). Logical volume vg0/lv1 successfully resized.[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-a----- 804.00m 缩减容量 先umount设备 缩减文件系统大小 缩减LV大小 123456789101112131415161718192021222324252627282930313233[root@localhost ~]# umount -l /usr1[root@localhost ~]# resize2fs /dev/mapper/vg0-lv1 100Mresize2fs 1.42.9 (28-Dec-2013)Please run 'e2fsck -f /dev/mapper/vg0-lv1' first.[root@localhost ~]# e2fsck -f /dev/mapper/vg0-lv1 e2fsck 1.42.9 (28-Dec-2013)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary information/dev/mapper/vg0-lv1: 2369/206848 files (6.4% non-contiguous), 61211/823296 blocks[root@localhost ~]# [root@localhost ~]# resize2fs /dev/mapper/vg0-lv1 100Mresize2fs 1.42.9 (28-Dec-2013)Resizing the filesystem on /dev/mapper/vg0-lv1 to 102400 (1k) blocks.The filesystem on /dev/mapper/vg0-lv1 is now 102400 blocks long.[root@localhost ~]# lvreduce -L 100M /dev/mapper/vg0-lv1 WARNING: Reducing active logical volume to 100.00 MiB. THIS MAY DESTROY YOUR DATA (filesystem etc.)Do you really want to reduce vg0/lv1? [y/n]: y Size of logical volume vg0/lv1 changed from 804.00 MiB (201 extents) to 100.00 MiB (25 extents). Logical volume vg0/lv1 successfully resized.[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-a----- 100.00m [root@localhost /]# vgs VG #PV #LV #SN Attr VSize VFree vg0 2 1 0 wz--n- 804.00m 704.00m[root@localhost /]# pvs PV VG Fmt Attr PSize PFree /dev/sdb1 vg0 lvm2 a-- 296.00m 196.00m /dev/sdc1 vg0 lvm2 a-- 508.00m 508.00m 分区扩展123456789101112131415161718192021222324252627282930313233343536root@baoze:# pvs PV VG Fmt Attr PSize PFree /dev/sda3 ubuntu-vg lvm2 a-- &lt;28.00g 0 root@baoze:# lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTSloop1 7:1 0 62M 1 loop /snap/core20/1587loop2 7:2 0 79.9M 1 loop /snap/lxd/22923loop3 7:3 0 49.6M 1 loop /snap/snapd/17883loop4 7:4 0 63.3M 1 loop /snap/core20/1778loop5 7:5 0 103M 1 loop /snap/lxd/23541sda 8:0 0 80G 0 disk ### 当前sda总大小80G├─sda1 8:1 0 1M 0 part ├─sda2 8:2 0 2G 0 part /boot└─sda3 8:3 0 28G 0 part ### 但是sd3只有28G └─ubuntu--vg-ubuntu--lv 253:0 0 28G 0 lvm /sr0 11:0 1 1.4G 0 rom#### 把sda中空闲的区域扩展到sd3中root@baoze:# growpart /dev/sda 3CHANGED: partition=3 start=4198400 old: size=58714112 end=62912512 new: size=163573727 end=167772127root@baoze:# lsblkNAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINTSloop1 7:1 0 62M 1 loop /snap/core20/1587loop2 7:2 0 79.9M 1 loop /snap/lxd/22923loop3 7:3 0 49.6M 1 loop /snap/snapd/17883loop4 7:4 0 63.3M 1 loop /snap/core20/1778loop5 7:5 0 103M 1 loop /snap/lxd/23541sda 8:0 0 80G 0 disk ├─sda1 8:1 0 1M 0 part ├─sda2 8:2 0 2G 0 part /boot└─sda3 8:3 0 78G 0 part ### 当前sd3中的空间已经扩展到78G └─ubuntu--vg-ubuntu--lv 253:0 0 28G 0 lvm /sr0 11:0 1 1.4G 0 romroot@baoze:# pvs PV VG Fmt Attr PSize PFree /dev/sda3 ubuntu-vg lvm2 a-- &lt;78.00g 50.00g ### pvs中也可以看到空闲的PE了]]></content>
      <tags>
        <tag>lvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins使用总结]]></title>
    <url>%2F2019%2F05%2F13%2Fjenkins%2Fjenkins%2F</url>
    <content type="text"><![CDATA[常用链接 github pipeline steps reference pipeline scm step(checkout) apache groovy doc SAP shared lib repo Jenkins插件升级站点配置 https://updates.jenkins.io/update-center.json (默认) http://mirrors.huaweicloud.com/jenkins/updates/update-center.json groovy实现添加slave 官方wiki pipeline_demo_sharedlib pipeline_demo_jenkinsfile cloudbees_jenkins_script_sample 官方pipeline示例并行任务配置Jenkins pipeline控制并行执行job个数shared-libpipeline代码调试centos安装jenkinsJenkins中使用Grab下载第三方JarJenkins序列化Multijob不能调用pipeline任务升级Multijob插件到1.32及以上 slave中workspace出现@2slave的配置的executor的数量只有1个，但是某些情况下在任务日志日志中会发现slave的workspace出现了@2的情况。 Jenkins在slave上启动任务之前，会先检查当前应该使用的workspace是否处于lock状态，如果处于lock(lock的原因TODO)状态，jenkins会自动在workspace后面加上@x使用，x递增。 如果slave一直处于使用非期望的workspace目录(如执行器只有一个，期望使用指定的workspace)时，可以通过断链slave和master之间的连接然后重连解决。 admin密码丢失 初始密码: ${jenkins_home}/secrets/initialAdminPassword 修改过密码后忘记 将 ${jenkins_home}/config.xml 文件中以下内容修改为false 1&lt;useSecurity&gt;true&lt;/useSecurity&gt; 重启jenkins服务 系统管理 -&gt; 全局安全配置 中 启用安全 系统管理 -&gt; 管理用户 中 重置密码 jenkins执行shell脚本时/etc/profile中环境变量不能访问获取pipeline中的Script Path1def scriptPath = currentBuild.rawBuild.parent.definition.scriptPath 获取pipeline中stage和并行task中的分段日志查看Jenkins中JAVA相关的环境变量信息在Manage Jenkins -&gt; Script Console 中执行如下脚本 1System.getProperty("permissive-script-security.enabled") 获取jenkins中安装的所有插件123456789Jenkins.instance.pluginManager.plugins.each &#123; println("$&#123;it.getDisplayName()&#125; --- $&#123;it.getVersion()&#125;")&#125;// 根据名称排序显示List&lt;String&gt; jenkinsPlugins = new ArrayList&lt;String&gt;(Jenkins.instance.pluginManager.plugins)jenkinsPlugins.sort &#123; it.displayName &#125;.each &#123; plugin -&gt; println("$&#123;plugin.shortName&#125;:$&#123;plugin.version&#125;")&#125; 脚本式pipeline中failFast使用清理Jenkins Master中的所有Job的历史记录强制终止运行时间过长的构建记录ssh slave连接过程slave磁盘空间配置[]]]></content>
      <tags>
        <tag>总结</tag>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode使用总结]]></title>
    <url>%2F2019%2F05%2F13%2Fvscode-usage%2F</url>
    <content type="text"><![CDATA[vscode配置123456789101112131415161718&#123; "workbench.colorTheme": "One Dark Pro", "workbench.iconTheme": "vscode-icons", "editor.renderWhitespace": "all", "editor.renderControlCharacters": true, "window.zoomLevel": 0, "editor.fontSize": 16, "editor.formatOnSave": true, "C_Cpp.clang_format_fallbackStyle": "Google", "clang-format.fallbackStyle": "Google", "[c]": &#123; "editor.defaultFormatter": "xaver.clang-format" &#125;, "clang-format.executable": "C:\\Users\\xxx\\.vscode\\extensions\\ms-vscode.cpptools-0.26.0\\LLVM\\bin\\clang-format.exe", "files.exclude": &#123; "**/.git": false // 默认为true，默认配置表示不显示.git文件 &#125;,&#125; 快捷键 按键 说明 shift+alt+F 格式化 shift+ctl+b build ctrl+x 删除当前行 shift+alt+⬇ 拷贝当前行到下一行 shift+alt+⬆ 拷贝当前行到上一行 shift+ctl+k 删除当前行 alt+⬆ 移动当前行到上一行 alt+⬇ 移动当前行到下一行 vscode调试c/c++程序VS Code中更改C/C++代码格式样式clang-foramt格式化选项介绍]]></content>
      <tags>
        <tag>总结</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm使用总结]]></title>
    <url>%2F2019%2F05%2F13%2Fnpm-usage%2F</url>
    <content type="text"><![CDATA[npm使用淘宝镜像临时使用1npm --registry https://registry.npm.taobao.org 永久设置1npm config set registry https://registry.npm.taobao.org 该方式等同于在~/.npmrc文件中添加registry=https://registry.npm.taobao.org可以通过npm config get registry确认是否生效 使用cnpm1npm install cnpm -g --registry https://registry.npm.taobao.org cnpm和npm用法完全一致，只是在执行命令时将npm改为cnpm]]></content>
      <tags>
        <tag>npm</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo搭建blog]]></title>
    <url>%2F2019%2F05%2F12%2Fhexo-blog%2F</url>
    <content type="text"><![CDATA[Hexo是一个快速、简洁且高效的博客框架。具体内容请参考官网文档。 主题Next修改参考官方文档 依赖 nodejs 12.* (hexo 3.8) github个人仓库 git hexo安装12345npm install -g hexo-clihexo init blogcd blognpm installnpm install hexo-deployer-git --save _config.yml配置123456language: zh-CN # 网站使用的语言，取值参考themes下面的languages目录中的配置timezone: Asia/Shanghaideploy: type: git # path和username要一致，且git中repo的命令必须为name.github.io repo: git@github.com:path/username.github.io.git 常用hexo命令 hexo init [folder]新建一个网站，如果未指定folder，则默认在当前位置创建 hexo new [layout] 新建文章，如果未指定layout，则使用_config.yml中的default_layout代替 hexo generate [option]生成静态文件，可以简写为hexo g。option: -d,–deploy 文件生成后立即部署 -w,–watch 监视文件变化 hexo server启动服务器。默认访问路径为 http://localhost:4000。可以简写为`hexo s` hexo deploy部署网站。可以简写为hexo d。可以通过指定-g参数指定部署前先生成静态文件。 hexo clean清除缓存文件(db.json)和已生成的静态文件(public/*) Front-matter 参数 描述 备注 layout 布局 title 文章标题 data 创建时间 updated 更新时间 comments 开启评论 默认值:true tags 标签(不适用于分页) 配置多个时，标签没有顺序和层次 categories 分类(不适用于分页) 配置多个时，分类具有顺序和层次 Next增加站内搜索 安装插件 12npm install hexo-generator-search --savenpm install hexo-generator-searchdb --save 修改hexo配置 在hexo目录下的_config.yml中增加以下内容 12345search: path: search.xml field: post format: html limit: 10000 next主题增加搜索入口 在themes/next/_config.yml文件中打开local_search 1234local_search: enable: true trigger: auto top_n_per_article: 1]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
