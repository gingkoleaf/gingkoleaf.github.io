<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[jenkins的日志配置]]></title>
    <url>%2F2019%2F11%2F15%2Fjenkins%2Fjenkins-log-config%2F</url>
    <content type="text"><![CDATA[use a post initialization scriptjenkins支持在启动后立即运行指定脚本(${JENKINS_HOME/init.groovy} 或 ${JENKINS_HOME}/init.groovy.d/*.groovy)，脚本可以访问Jenins中的类和所有插件。可以利用这个特性来实现日志配置 12345import java.util.logging.Levelimport java.util.logging.LoggerLogger.getLogger("hudson.plugins.git.GitStatus").setLevel(Level.SEVERE)Logger.getLogger("hudson.security.csrf.CrumbFilter").setLevel(Level.SEVERE) use java.util.logging创建一个logging.properties文件，里面包含日志记录的配置，然后通过增加JVM选项-Djava.util.logging.config.file=&lt;pathTo&gt;/logging.properties 来生效配置 这种方式只支持使用了 java.util.logging 来记录日志的classes，如果某些classes使用了其他日志功能（如 org.apache.commons.logging）则不会生效 1234567891011handlers=java.util.logging.ConsoleHandler,java.util.logging.FileHandlerjava.util.logging.FileHandler.level=INFOjava.util.logging.FileHandler.formatter=java.util.logging.SimpleFormatterjava.util.logging.FileHandler.pattern=/var/log/jenkins/jenkins.logjava.util.logging.FileHandler.append=truejava.util.logging.FileHandler.limit=10000000java.util.logging.FileHandler.count=5java.util.logging.ConsoleHandler.level=INFOjava.util.logging.ConsoleHandler.formatter=java.util.logging.SimpleFormatter 使用linux的logrotatelogrotate是个十分有用的工具，它可以自动对日志进行截断（或轮循）、压缩以及删除旧的日志文件。 Logrotate是基于CRON来运行的，其脚本是/etc/cron.daily/logrotate。 logrotate的配置文件是/etc/logrotate.conf，通常不需要对它进行修改。日志文件的轮循设置在独立的配置文件中，它们放在/etc/logrotate.d/目录下。 /etc/logrotate.d/jenkins文件配置如下: 1234567891011121314/var/jenkins_home/logs/jenkins.log &#123; daily //日志文件轮循周期。可用值为‘daily’，‘weekly’或者‘yearly’ rotate 5 //最多将存储5个归档日志。对于第六个归档，时间最久的归档将被删除 dataext //旧日志文件以创建日期命名 compress //在轮循任务完成后，已轮循的归档将使用gzip进行压缩 delaycompress //总是与compress选项一起用，delaycompress选项指示logrotate不要将最近的归档压缩，压缩将在下一次轮循周期进行。这在你或任何软件仍然需要读取最新归档时很有用。 missingok //在日志轮循期间，任何错误将被忽略，例如“文件无法找到”之类的错误 notifempty //如果日志文件为空，轮循不会进行 size 100k //当日志文件到达指定的大小时才转储，log-size能指定bytes(缺省)及KB (sizek)或MB(sizem) create 644 root root //mode owner group 转储文件，使用指定的文件模式创建新的日志文件 postrotate //在logrotate转储之后需要执行的指令，例如重新启动 (kill -HUP) 某个服务 必须独立成行 /usr/bin/killall -HUP rsyslogd endscript&#125; 值得注意的一个配置是：copytruncate copytruncate 如果没有这个选项的话，操作方式：是将原log日志文件，移动成类似log.1的旧文件， 然后创建一个新的文件。 如果设置了，操作方式：拷贝原日志文件，并且将其变成大小为0的文件。 区别是如果进程,比如nginx 使用了一个文件写日志，没有copytruncate的话，切割日志时， 把旧日志log-&gt;log.1 ，然后创建新日志log。这时候nginx 打开的文件描述符依然时log.1，由没有信号通知nginx 要换日志描述符，所以它会继续向log.1写日志，这样就不符合我们的要求了。 因为我们想切割日志后，nginx 自动会向新的log 文件写日志，而不是旧的log.1文件 解决方法有两个： 1.向上面的nginx 切割日志配置，再postrotate里面写个脚本 postrotate [ -s /run/nginx.pid ] &amp;&amp; kill -USR1 cat /run/nginx.pidendscript 这样就是发信号给nginx ,让nginx 关闭旧日志文件描述符，重新打开新的日志文件描述，并写入日志 2.使用copytruncate参数，向上面说的，配置了它以后，操作方式是把log 复制一份 成为log.1，然后清空log的内容，使大小为0，那此时log依然时原来的旧log，对进程（nginx）来说，依然打开的是原来的文件描述符，可以继续往里面写日志，而不用发送信号给nginx copytruncate这种方式操作的时候， 拷贝和清空之间有一个时间差，可能会丢失部分日志数据。 nocopytruncate 备份日志文件不过不截断。]]></content>
      <categories>
        <category>tool</category>
        <category>持续集成</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改Jenkins Home]]></title>
    <url>%2F2019%2F11%2F14%2Fjenkins%2Fjenkins-change-home%2F</url>
    <content type="text"><![CDATA[修改 JENKINS_HOME 前必须先停止jenkins服务，修改后将原来 jenkins home目录中的数据copy到新目录，然后重启服务。 使用war启动jenkins直接通过 java -DJENKINS_HOME=/var/jenkins_home -jar jenkins.war 指定 -DJENKINS_HOME 选项即可 centos使用rpm安装或yum安装通过修改 /etc/sysconfig/jenkins 配置文件中的 JENKINS_HOME 配置 docker容器化安装通过在 docker run 中增加 -e JENKINS_HOME=xxxx 环境变量来修改]]></content>
      <categories>
        <category>tool</category>
        <category>持续集成</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker-restart-policies]]></title>
    <url>%2F2019%2F11%2F14%2Fdocker%2Fdocker-restart-policies%2F</url>
    <content type="text"><![CDATA[使用在 docker run 命令中通过指定 --restart=xxx 选项来指定容器在退出时的重启策略。 Docker容器的重启动作都是由Docker守护进程完成的。 重启策略 策略 说明 no 默认值，当容器退出时不会重启 on-failure[:max-retries] 在容器为非正常退出(退出状态为非0)时才会重启，可以指定最大重启次数 always 不管容器退出状态为什么，总是重启容器，当指定该值时，守护进程总是会在进程启动后启动容器 unless-stopped 无论退出状态如何，总是重启容器，除非容器在Docker守护进程停止之前进入了停止状态。 每次重启时，docker都会按照 100ms 200ms 400ms 800ms 1600ms … 的规律增加等待延时，直到达到on-failure的最大次数或者docker停止或通过docker rm -f 删除容器。 如果容器重新启动成功(容器启动并运行至少10秒)，则延迟将重置为其默认值100 ms。 可以通过docker inspect获得容器(尝试)重新启动的次数。例如，获取容器“my-container”的重启次数 1docker inspect -f "&#123;&#123; .RestartCount &#125;&#125;" my-container docker run 命令中 --restart=xxx 和 --rm 选项时互斥的，不能同时指定 容器只有在成功启动后restart policy才能生效。这里的”成功启动”是指容器处于up至少10秒且已经处于docker监管。这是避免没有成功启动的容器陷入restart的死循环。 如果手动stop一个容器，容器设置的restart policy将会被忽略，除非docker守护进程重启或者容器手动重启；这是避免了如果重启策略设置了always，如果不忽略policy那么容器无法手动停止。 更新重启策略1docker update --restart=no my-container 当需要彻底删除一个指定always策略的容器时，必须先更新重启策略为no，然后在停止和删除容器。]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker配置代理]]></title>
    <url>%2F2019%2F11%2F11%2Fdocker%2Fdocker-set-proxy%2F</url>
    <content type="text"><![CDATA[systemd中，创建 /etc/systemd/system/docker.service.d/http-proxy.conf 文件，增加如下配置 12[Service]Environment=&quot;HTTP_PROXY=http://proxy.example.com:80/&quot; &quot;HTTPS_PROXY=https://proxy.example.com:443/&quot; &quot;NO_PROXY=localhost,127.0.0.1,docker-registry.example.com,&quot;]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker配置文件常用配置]]></title>
    <url>%2F2019%2F11%2F11%2Fdocker%2Fdocker-config-file%2F</url>
    <content type="text"><![CDATA[默认配置文件为: /etc/docker/daemon.json, 如果该文件不存在，需要自己创建 官方配置文件说明 常用配置如下 12345678910&#123; "graph": "/data/docker_home", // 配置docker默认root目录，该配置19.03.0版本已废弃，计划19.09.0版本删除 "data-root": "/data/docker_home", // 配置docker默认root目录 "registry-mirrors": [ //配置docker镜像源 "https://registry.docker-cn.com", // Docker 官方镜像中国区 "http://hub-mirror.c.163.com", // 网易镜像源 "https://docker.mirrors.ustc.edu.cn"], // 中科大镜像源 "insecure-registries": [], // 配置非安全的镜像仓库(私有仓库)，通常公司内部镜像源配置在此处 "debug": true, //启动debug模式，默认为 false&#125; insecure-registries中定义的私有仓库如果端口号不为 80 , 则必须指定端口号使用 docker pull 拉取镜像时必须和 insecure-registers 中定义的完全一致(包括端口号)]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[修改docker默认root目录]]></title>
    <url>%2F2019%2F11%2F11%2Fdocker%2Fchange-docker-dir%2F</url>
    <content type="text"><![CDATA[方法一 停止服务 systemctl stop docker 修改docker服务配置文件/usr/lib/systemd/system/docker.service 12# 启动命令配置中，增加 --data-root 配置ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --data-root=/data/docker_home 同步原来的数据到新目录 rsync -aqxP /var/lib/docker/ /data/docker_home/ 删除原来目录 rm -rf /var/lib/docker/ 重新加载配置 systemctl daemon-reload 启动服务 systemctl start docker 方法二 停止服务 systemctl stop docker 修改配置文件 /etc/docker/daemon.json 12345678// 增加 graph 或 data-root 配置&#123; "graph": "/data/docker_home" // 不推荐使用, 该配置19.03.0版本已废弃，计划19.09.0版本删除&#125;&#123; "data-root": "/data/docker_home"&#125; 同步原来的数据到新目录 rsync -aqxP /var/lib/docker/ /data/docker_home/ 删除原来目录 rm -rf /var/lib/docker/ 重新加载配置 systemctl daemon-reload 启动服务 systemctl start docker]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker使用总结]]></title>
    <url>%2F2019%2F11%2F11%2Fdocker%2Fdocker-usage%2F</url>
    <content type="text"><![CDATA[官方文档CentOS下安装dockerdocker常见配置说明 docker可执行文件: /usr/bin/dockerd docker服务配置文件: /usr/lib/systemd/system/docker.service docker配置文件: /etc/docker/daemon.json docker存储默认目录: /var/lib/docker 修改docker存储的默认路径docker配置文件常用设置docker代理配置dockerd命令详解docker重启策略]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos下docker安装]]></title>
    <url>%2F2019%2F11%2F11%2Fcentos%2Fcentos-docker-install%2F</url>
    <content type="text"><![CDATA[CentOS7.6 卸载老版本 12345678yum remove docker \ docker-client \ docker-client-latest \ docker-common \ docker-latest \ docker-latest-logrotate \ docker-logrotate \ docker-engine 安装所需依赖 123yum install -y yum-utils \ device-mapper-persistent-data \ lvm2 配置repo 123yum-config-manager \ --add-repo \ https://download.docker.com/linux/centos/docker-ce.repo 安装docker 1yum install docker-ce docker-ce-cli containerd.io]]></content>
      <categories>
        <category>linux</category>
        <category>centos</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[清理Jenkins中所有任务的历史记录]]></title>
    <url>%2F2019%2F11%2F08%2Fjenkins%2Fjenkins-clear-jobs-history%2F</url>
    <content type="text"><![CDATA[123456789101112131415161718192021222324252627282930313233def jobRetain = 3 // job 保留的历史记录数量// Jenkins.instance.getClass(): hudson.model.Hudson// 获取所有freestyle的jobjobs = Jenkins.instance.getAllItems(AbstactProject.class)println(jobs)// 获取所有pipeline的jobjobs = Jenkins.instance.getAllItems(org.jenkinsci.plugins.workflow.job.WorkflowJob.class)println(jobs)// 获取所有的jobjobs = Jenkins.instance.getAllItems(hudson.model.Job.class())println(jobs)jobs.each &#123; job -&gt; def builds = job.getBuilds() println(builds) if(builds) &#123; def latestBuildNumber = job.getLastBuild().getNumber() def retainMaxNumber = latestBuildNumber - jobRetain println("$&#123;job.name&#125;'s last build number: $&#123;latestBuildNumber&#125;") if (retainMaxNumber &lt;= 0) &#123; println("$&#123;job.name&#125;'s last build is less than $&#123;jobRetain&#125;, skip...") return &#125; println(builds.getClass()) job.getBuilds().findAll&#123;it.number &lt;= retainMaxNumber&#125;.each &#123; // it.getClass(): org.jenkinsci.plugins.workflow.job.WorkflowRun println("delete $&#123;job.name&#125;'s $&#123;it.number&#125;") it.delete() &#125; &#125; else &#123; println("$&#123;job.name&#125; don't have builder, skip...") &#125;&#125; 执行日志如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677Started by user unknown or anonymousRunning in Durability level: MAX_SURVIVABILITY[Pipeline] Start of Pipeline[Pipeline] echo[hudson.model.FreeStyleProject@5aab9184[jenkins_shell_test], com.tikal.jenkins.plugins.multijob.MultiJobProject@ce9939f[multijob_test], hudson.model.FreeStyleProject@12b9358a[no_build_job]][Pipeline] echo[org.jenkinsci.plugins.workflow.job.WorkflowJob@10dabbd8[clear_history], org.jenkinsci.plugins.workflow.job.WorkflowJob@4e79153f[pipeline_shell_test]][Pipeline] echo[org.jenkinsci.plugins.workflow.job.WorkflowJob@10dabbd8[clear_history], hudson.model.FreeStyleProject@5aab9184[jenkins_shell_test], com.tikal.jenkins.plugins.multijob.MultiJobProject@ce9939f[multijob_test], hudson.model.FreeStyleProject@12b9358a[no_build_job], org.jenkinsci.plugins.workflow.job.WorkflowJob@4e79153f[pipeline_shell_test]][Pipeline] echo[clear_history #24, clear_history #23, clear_history #22, clear_history #21, clear_history #20, clear_history #19, clear_history #18, clear_history #17, clear_history #16, clear_history #15, clear_history #14][Pipeline] echoclear_history&apos;s last build number: 24[Pipeline] echoclass hudson.util.RunList[Pipeline] echodelete clear_history&apos;s 21[Pipeline] echodelete clear_history&apos;s 20[Pipeline] echodelete clear_history&apos;s 19[Pipeline] echodelete clear_history&apos;s 18[Pipeline] echodelete clear_history&apos;s 17[Pipeline] echodelete clear_history&apos;s 16[Pipeline] echodelete clear_history&apos;s 15[Pipeline] echodelete clear_history&apos;s 14[Pipeline] echo[jenkins_shell_test #7, jenkins_shell_test #6, jenkins_shell_test #5, jenkins_shell_test #4, jenkins_shell_test #3, jenkins_shell_test #2, jenkins_shell_test #1][Pipeline] echojenkins_shell_test&apos;s last build number: 7[Pipeline] echoclass hudson.util.RunList[Pipeline] echodelete jenkins_shell_test&apos;s 4[Pipeline] echodelete jenkins_shell_test&apos;s 3[Pipeline] echodelete jenkins_shell_test&apos;s 2[Pipeline] echodelete jenkins_shell_test&apos;s 1[Pipeline] echo[multijob_test #3, multijob_test #2, multijob_test #1][Pipeline] echomultijob_test&apos;s last build number: 3[Pipeline] echomultijob_test&apos;s last build is less than 3, skip...[Pipeline] echo[][Pipeline] echono_build_job don&apos;t have builder, skip...[Pipeline] echo[pipeline_shell_test #91, pipeline_shell_test #90, pipeline_shell_test #89, pipeline_shell_test #88, pipeline_shell_test #87, pipeline_shell_test #86, pipeline_shell_test #85, pipeline_shell_test #84, pipeline_shell_test #83, pipeline_shell_test #82][Pipeline] echopipeline_shell_test&apos;s last build number: 91[Pipeline] echoclass hudson.util.RunList[Pipeline] echodelete pipeline_shell_test&apos;s 88[Pipeline] echodelete pipeline_shell_test&apos;s 87[Pipeline] echodelete pipeline_shell_test&apos;s 86[Pipeline] echodelete pipeline_shell_test&apos;s 85[Pipeline] echodelete pipeline_shell_test&apos;s 84[Pipeline] echodelete pipeline_shell_test&apos;s 83[Pipeline] echodelete pipeline_shell_test&apos;s 82[Pipeline] End of PipelineFinished: SUCCESS]]></content>
      <categories>
        <category>tool</category>
        <category>持续集成</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态替换map中的变量]]></title>
    <url>%2F2019%2F11%2F02%2Fgroovy%2Fgroovy-repalce-param-in-yaml%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122232425262728def replaceVariableInMap(def oriValue, def key, def value) &#123; if (oriValue instanceof String) &#123; return oriValue.replace("\$&#123;$&#123;key&#125;&#125;", value.toString()) &#125; else if (oriValue instanceof List) &#123; def tmpList = [] oriValue.each &#123; cf -&gt; tmpList.add(replaceVariableInMap(cf, key, value)) &#125; return tmpList &#125; else if (oriValue instanceof Map) &#123; def tmpMap = [:] oriValue.each &#123; k, v-&gt; tmpMap.put(k, replaceVariableInMap(v, key, value)) &#125; return tmpMap &#125; else &#123; return oriValue &#125;&#125;def testMap = [general: [branch: "\$&#123;branch&#125;"], stages: [tasks: [repos: [url: "\$&#123;url&#125;", branch: "\$&#123;branch&#125;", id: "domain"]]]]def params = [branch: "test_branch", url: "https://git.test.com"]params.each &#123;k, v -&gt; testMap = replaceVariableInMap(testMap, k, v)&#125;println testMap]]></content>
      <categories>
        <category>language</category>
        <category>groovy</category>
      </categories>
      <tags>
        <tag>groovy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[脚本式pipeline中failFast使用]]></title>
    <url>%2F2019%2F11%2F02%2Fjenkins%2Fjenkins-script-pipeline-failfast%2F</url>
    <content type="text"><![CDATA[12345678910111213141516171819202122def generateJobStage(String jobName) &#123; return &#123; node('master') &#123; echo "$&#123;jobName&#125; start" sleep 5 sh "exit 1" echo "job end" &#125; &#125;&#125;script &#123; def jobs = ['jobA', 'jobB', 'jobC'] def parallelStagesMap = jobs.collectEntries &#123; def jobName -&gt; ["$&#123;jobName&#125;", generateJobStage(jobName)] &#125; parallelStagesMap.failFast = true println parallelStagesMap stage("test") &#123; parallel parallelStagesMap &#125;&#125;]]></content>
      <categories>
        <category>tool</category>
        <category>持续集成</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pipeline中任务分段日志获取]]></title>
    <url>%2F2019%2F10%2F22%2Fjenkins%2Fjenkins-pipeline-stage-log%2F</url>
    <content type="text"><![CDATA[脚本式pipeline12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182import hudson.model.Actionimport org.jenkinsci.plugins.workflow.cps.nodes.StepStartNodeimport org.jenkinsci.plugins.workflow.graph.FlowNodeimport org.jenkinsci.plugins.workflow.actions.LabelActiondef hasLabelAction(FlowNode flowNode) &#123; def actions = flowNode.getActions() for (Action action : actions) &#123; if (action instanceof LabelAction) &#123; return true &#125; &#125; return false&#125;def getStepStartNode(List&lt;FlowNode&gt; flowNodes, String stepNodeName, def depth) &#123; if (depth &lt; 0) &#123; return null &#125; for(FlowNode flowNode : flowNodes) &#123; def labelActionFlag = false if (flowNode instanceof StepStartNode) &#123; labelActionFlag = hasLabelAction(flowNode) &#125; if (labelActionFlag &amp;&amp; flowNode.getDisplayName().equals(stepNodeName)) &#123; return flowNode &#125; // 递归查询 def node = getStepStartNode(flowNode.getParents(), stepNodeName, depth) if(node) &#123; return node &#125; &#125; return null&#125;def getBlueOceanLogUrlByName(String stepNodeName) &#123; // currentBuild: class org.jenkinsci.plugins.workflow.support.steps.build.RunWrapper // build: class org.jenkinsci.plugins.workflow.job.WorkflowRun def build = currentBuild.getRawBuild() // execution: class org.jenkinsci.plugins.workflow.cps.CpsFlowExecution def execution = build.getExecution() // executionHeads: class java.util.ArrayList def executionHeads = execution.getCurrentHeads() def flowNode = getStepStartNode(executionHeads, stepNodeName, 10) if (flowNode) &#123; return Jenkins.instance.getRootUrl() + "blue/rest/organizations/jenkins/pipelines/$&#123;JOB_NAME&#125;/runs/$&#123;BUILD_NUMBER&#125;/nodes/" + flowNode.getId() + "/log" &#125; return ""&#125;def generateTask(def taskName) &#123; def taskBody = &#123; println getBlueOceanLogUrlByName("Branch: $&#123;taskName&#125;") node &#123; println("====&gt; $&#123;taskName&#125; start") sleep 3 println("====&gt; $&#123;taskName&#125; end") &#125; &#125; taskBody&#125;def createParallelTasks(def jobs) &#123; def pipelineConfig = [:] jobs.each &#123; def job -&gt; def taskBody = generateTask(job) pipelineConfig.put(job, taskBody) &#125; pipelineConfig&#125;script &#123; def jobs = ["job_a", "job_b", "job_c"] def pipelineConfig = createParallelTasks(jobs) stage('test') &#123; println getBlueOceanLogUrlByName("test") parallel pipelineConfig &#125;&#125;]]></content>
      <categories>
        <category>tool</category>
        <category>持续集成</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[free命令详解]]></title>
    <url>%2F2019%2F09%2F03%2Flinux%2Flinux-cmd-free%2F</url>
    <content type="text"><![CDATA[free命令显示了系统中已使用和空闲的物理内存和交换内存，以及内核使用的buffer和cache的大小。命令中的数据是通过解析/proc/meminfo文件获得的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@localhost ~]# free -w total used free shared buffers cache availableMem: 1014972 604816 65888 6880 164 344104 220752Swap: 1048572 264 1048308[root@localhost ~]# free -k total used free shared buff/cache availableMem: 1014972 605732 64932 6880 344308 219800Swap: 1048572 264 1048308[root@localhost ~]# cat /proc/meminfoMemTotal: 1014972 kBMemFree: 64916 kBMemAvailable: 219784 kBBuffers: 164 kBCached: 264984 kBSwapCached: 8 kBActive: 645456 kBInactive: 155036 kBActive(anon): 509284 kBInactive(anon): 32940 kBActive(file): 136172 kBInactive(file): 122096 kBUnevictable: 0 kBMlocked: 0 kBSwapTotal: 1048572 kBSwapFree: 1048308 kBDirty: 16 kBWriteback: 0 kBAnonPages: 535368 kBMapped: 44520 kBShmem: 6880 kBSlab: 79160 kBSReclaimable: 48748 kBSUnreclaim: 30412 kBKernelStack: 2704 kBPageTables: 6608 kBNFS_Unstable: 0 kBBounce: 0 kBWritebackTmp: 0 kBCommitLimit: 1556056 kBCommitted_AS: 778052 kBVmallocTotal: 34359738367 kBVmallocUsed: 27092 kBVmallocChunk: 34359707152 kBHardwareCorrupted: 0 kBAnonHugePages: 356352 kBCmaTotal: 0 kBCmaFree: 0 kBHugePages_Total: 0HugePages_Free: 0HugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kBDirectMap4k: 63424 kBDirectMap2M: 985088 kB[root@localhost ~]# 列内容说明: total: 系统中的内存总量，对应/proc/meminfo中的MemTotal和SwapTotal的内容 used: 已占用内存大小，通过total - free - buffers - cache计算得出 free: 空闲内存大小，对应/proc/meminfo中的MemFree和SwapFree的内容 shared: 共享内存占用大小，通过情况都是tmpfs占用，对应/proc/meminfo中的Shmem的内容，在2.6.32内核中开始提供该内容显示，在不支持的系统中显示为0 buffers: 内核buffers占用大小，对应/proc/meminfo中的Buffers内容 cache: page cache和slabs占用的大小，对应/proc/meminfo中的Cached和Slab内容之和 buff/cache: buffers和cache之和 available: 在不考虑交换内存的情况下，估算有多少内存可以用来启动新应用。不同于cache和free字段提供的数据，该字段考虑了page cache，同时并非所有的可回收的slabs内存由于在使用中并不一定能被回收，对应/proc/meminfo中的MemAvailable内容(在内核3.14上可用，在内核2.6.27+上模拟，否则与free内容相同) buffers与cachelinux缓存机制在系统运行过程中，内核会利用空闲的物理内存，划出一部分区域作为buffers/cache，将一些程序使用过的硬盘数据读入缓存区域的内存，利用高速的内存读写特性提升数据的访问效率。 针对应用程序来说，通常情况下buffers/cache占用的内存是可用的，当应用程序需要用到内存的时候，会回收buffers/cache内存。 buffers与cache的区别cache 指 page cache，它是针对文件系统的，是文件的缓存。当缓存中的文件被修改(写操作)后，linux不会立即执行写磁盘操作，而是把page cache中的页面标记为脏页，定期同步到存储设备中。 buffers 指 buffer cache，是磁盘块的缓存，是针对块设备的。直接对块设备的进行操作的数据会缓存到buffers中，例如，文件系统的元数据信息。 手动释放buffers和cache/proc/sys/vm文档 123456#释放page cacheecho 1 &gt; /proc/sys/vm/drop_caches#释放可回收的slab对象(包括dentries和iinodes)echo 2 &gt; /proc/sys/vm/drop_caches#释放page cache 和 slab 对象echo 3 &gt; /proc/sys/vm/drop_caches 通过写drop_caches文件是一个非破坏性(non-destructive)的操作，不会释放脏数据。在执行该命令前执行sync命令可以强制将一些脏数据刷盘，然后尽可能多的释放内存。 这个文件的内容并不能控制内核是否使用缓存机制。 是否需要手动清除缓存通常情况下，应用程序在系统上稳定运行之后，free的值也会保持在一个稳定的值，虽然看上去比较小，Linux内核会在内存将要耗尽的时候，触发内存回收的工作，以便释放出内存给急需内存的进程使用。一般情况下，这个操作中主要的内存释放都来自于对buffer／cache的释放。尤其是被使用更多的cache空间。既然它主要用来做缓存，只是在内存够用的时候加快进程对文件的读写速度，那么在内存压力较大的情况下，当然有必要清空释放cache，作为free空间分给相关进程使用。所以一般情况下，我们认为buffer/cache空间可以被释放，这个理解是正确的。 通常情况下，当发生内存不足，应用程序获取不到内存，OOM等错误时，需要排查应用程序是否存在内存泄露的情况。针对内存泄露/内存溢出等导致内存不足的情况，可以通过swap的使用情况来快速判断(free中swap的使用情况，vmstate中si/so的值等)。 但是并非所有的buffer/cache都能释放 如何控制linux清理cache机制–内存整理影响系统性能案例 linux内存分配与回收 Linux中Buffer/Cache清理Linux服务器Cache占用过多内存导致系统内存不足问题的排查解决Linux服务器Cache占用过多内存导致系统内存不足问题的排查解决-2 禁用buffer/cache功能可以在/etc/sysctl.conf中添加下面内容禁用buffer/cache功能 12345678910vm.dirty_ratio = 1vm.dirty_background_ratio=1 vm.dirty_writeback_centisecs=2 vm.dirty_expire_centisecs=3 vm.drop_caches=3 vm.swappiness =100 vm.vfs_cache_pressure=163 vm.overcommit_memory=2 vm.lowmem_reserve_ratio=32 32 8 kern.maxvnodes=3 /proc/sys/vm/dirty_ratio 这个参数表示文件系统的写缓冲区占用系统内存的百分比，即当写缓冲使用到系统内存多少的时候，开始向磁盘写数据。增大之会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时，应该降低其数值。 /proc/sys/vm/dirty_background_ratio 这个参数控制文件系统的pdflush进程，在何时刷新磁盘。单位是百分比，表示系统内存的百分比，意思是当写缓冲使用到系统内存多少的时候，pdflush开始向磁盘写数据。增大之会使用更多系统内存用于磁盘写缓冲，也可以极大提高系统的写性能。但是，当你需要持续、恒定的写入场合时， 应该降低其数值 /proc/sys/vm/dirty_writeback_centisecs 这个参数控制内核的脏数据刷新进程pdflush的运行间隔。单位是 1/100 秒。缺省数值是500，也就是 5 秒。如果你的系统是持续地写入动作，那么实际上还是降低这个数值比较好，这样可以把尖峰的写操作削平成多次写操 /proc/sys/vm/dirty_expire_centisecs 这个参数声明Linux内核写缓冲区里面的数据多“旧”了之后，pdflush进程就开始考虑写到磁盘中去。单位是 1/100秒。缺省是 30000，也就是 30 秒的数据就算旧了，将会刷新磁盘。对于特别重载的写操作来说，这个值适当缩小也是好的，但也不能缩小太多，因为缩小太多也会导致IO提高太快。建议设置为 1500，也就是15秒算旧。 /proc/sys/vm/drop_caches 释放已经使用的cache /proc/sys/vm/page-cluster 该文件表示在写一次到swap区的时候写入的页面数量，0表示1页，1表示2页，2表示4页。 /proc/sys/vm/swapiness 该文件表示系统进行交换行为的程度，数值（0-100）越高，越可能发生磁盘交换。 /proc/sys/vm/vfs_cache_pressure 该文件表示内核回收用于directory和inode cache内存的倾向]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>memory</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins-sh-read-env]]></title>
    <url>%2F2019%2F09%2F01%2Fjenkins%2Fjenkins-sh-read-env%2F</url>
    <content type="text"><![CDATA[FreeStyle的JenkinsJob在freestyle的job中配置执行shell命令后，job在运行时默认的执行方式为 /bin/bash -xe /tmp/jenkinsxxxx.sh 1234567Building in workspace /var/lib/jenkins/workspace/jenkins_shell_test[jenkins_shell_test] $ /bin/sh -xe /tmp/jenkins6138408577395354213.sh+ set -x+ exportexport BUILD_CAUSE=&quot;MANUALTRIGGER&quot;export BUILD_CAUSE_MANUALTRIGGER=&quot;true&quot;... 在执行机上查看对应的进程 1234[root@localhost ~]# ps -ef |grep -i jenkinsjenkins 12371 1 20 16:30 ? 00:03:55 /etc/alternatives/java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /usr/lib/jenkins/jenkins.war --logfile=/var/log/jenkins/jenkins.log --webroot=/var/cache/jenkins/war --daemon --httpPort=8080 --debug=5 --handlerCountMax=100 --handlerCountMaxIdle=20jenkins 27359 12371 0 16:48 ? 00:00:00 /bin/sh -xe /tmp/jenkins6138408577395354213.shjenkins 27360 27359 0 16:48 ? 00:00:00 sleep 30 /bin/sh -xe xxx.sh方式运行的shell为非交互式非登录的模式，这种模式下的shell在启动时不会读取/etc/profile中的内容，所以/etc/profile中定义的环境变量不能访问 解决方法: 在shell中添加 #!/bin/bash -ilex，将shell模式修改为交互登录模式即可。 12345[root@localhost ~]# ps -ef |grep -i jenkinsjenkins 12371 1 10 16:30 ? 00:04:43 /etc/alternatives/java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /usr/lib/jenkins/jenkins.war --logfile=/var/log/jenkins/jenkins.log --webroot=/var/cache/jenkins/war --daemon --httpPort=8080 --debug=5 --handlerCountMax=100 --handlerCountMaxIdle=20jenkins 15197 12371 0 17:13 ? 00:00:00 /bin/bash -liex /tmp/jenkins15271049705299428998.shjenkins 15211 15197 0 17:13 ? 00:00:00 sleep 30[root@localhost ~]# pipeline模式的JenkinsJobpipeline模式下的原因与解决方案与FreeStyle类似，只是pipeline模式下脚本运行的进程不是jenkins主进程直接fork出来的。 1234567[root@localhost ~]# ps -ef |grep -i jenkinsjenkins 12371 1 11 16:30 ? 00:05:13 /etc/alternatives/java -Dcom.sun.akuma.Daemon=daemonized -Djava.awt.headless=true -DJENKINS_HOME=/var/lib/jenkins -jar /usr/lib/jenkins/jenkins.war --logfile=/var/log/jenkins/jenkins.log --webroot=/var/cache/jenkins/war --daemon --httpPort=8080 --debug=5 --handlerCountMax=100 --handlerCountMaxIdle=20jenkins 17509 1 0 17:16 ? 00:00:00 sh -c (pid=$$; &#123; while [ \( -d /proc/$pid -o \! -d /proc/$$ \) -a -d '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf' -a \! -f '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt' ]; do touch '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-log.txt'; sleep 3; done &#125; &amp; jsc=durable-7a8937f3d4c335791e06262c93820f88; JENKINS_SERVER_COOKIE=$jsc 'sh' -xe '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/script.sh' &gt; '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-log.txt' 2&gt;&amp;1; echo $? &gt; '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt.tmp'; mv '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt.tmp' '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt'; wait) &gt;&amp;- 2&gt;&amp;- &amp;jenkins 17511 17509 0 17:16 ? 00:00:00 sh -c (pid=$$; &#123; while [ \( -d /proc/$pid -o \! -d /proc/$$ \) -a -d '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf' -a \! -f '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt' ]; do touch '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-log.txt'; sleep 3; done &#125; &amp; jsc=durable-7a8937f3d4c335791e06262c93820f88; JENKINS_SERVER_COOKIE=$jsc 'sh' -xe '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/script.sh' &gt; '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-log.txt' 2&gt;&amp;1; echo $? &gt; '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt.tmp'; mv '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt.tmp' '/var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/jenkins-result.txt'; wait) &gt;&amp;- 2&gt;&amp;- &amp;jenkins 17512 17509 0 17:16 ? 00:00:00 sh -xe /var/lib/jenkins/workspace/pipeline_shell_test@tmp/durable-da5871cf/script.shjenkins 17514 17512 0 17:16 ? 00:00:00 sleep 30jenkins 17786 17511 0 17:16 ? 00:00:00 sleep 3]]></content>
      <categories>
        <category>tool</category>
        <category>持续集成</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash参数说明]]></title>
    <url>%2F2019%2F09%2F01%2Flinux%2Fshell-parameter%2F</url>
    <content type="text"><![CDATA[特殊参数$$当前Shell进程ID。对于 Shell 脚本，就是这些脚本所在的进程ID。 12345678910111213#显示当前shell的PID[root@localhost ~]# echo $$7338[root@localhost ~]# cat test.shecho $$ # 此处打印 test.sh 脚本运行的 PIDsleep 10# 运行shell脚本程序test.sh时，系统将创建一个子shell，它的父shell为 7338[root@localhost ~]# /bin/bash test.sh &amp;[1] 16371[root@localhost ~]# 16371[root@localhost ~]# ps -ef |grep -i test.shroot 16371 7338 0 05:13 pts/0 00:00:00 /bin/bash test.sh]]></content>
      <categories>
        <category>linux</category>
        <category>bash</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash启动介绍]]></title>
    <url>%2F2019%2F08%2F30%2Flinux%2Fshell%2F</url>
    <content type="text"><![CDATA[概述0号/1号和2号进程 123UID PID PPID C STIME TTY TIME CMDroot 1 0 0 Aug08 ? 00:00:02 /usr/lib/systemd/systemd --switched-root --system --deserialize 22root 2 0 0 Aug08 ? 00:00:00 [kthreadd] 系统启动后，当用户登录到系统时，系统将启动一个用户态的shell进程。在shell进程中运行shell脚本程序时，系统将创建一个子shell，此时系统中将有两个shell，一个是登录时系统启动的shell，另一个是系统为运行脚本程序创建的shell。脚本执行运行完后，子shell将终止，并返回到执行脚本之前的shell。 tty终端的shell进程如下： 通过ssh连接到系统的shell进程如下: 12345678910[root@localhost ~]# echo $$7338[root@localhost ~]# ps -ef |grep -i 7338root 7338 7331 0 03:48 pts/0 00:00:00 -bash[root@localhost ~]# ps -ef |grep -i 7331root 7331 3329 0 03:48 ? 00:00:12 sshd: root@pts/0,pts/1root 7338 7331 0 03:48 pts/0 00:00:00 -bashroot 7344 7331 0 03:48 pts/1 00:00:00 -bash[root@localhost ~]# ps -ef |grep -i 3329root 3329 1 0 Aug08 ? 00:00:00 /usr/sbin/sshd -D shell分类交互式shell与非交互式shell区分方法 可以通过打印“$-”变量的值（代表着当前shell的选项标志），查看其中的“i”选项（表示interactive shell）来区分交互式与非交互式shell。 12345678910111213141516171819[root@localhost ~]# echo $$31991[root@localhost ~]# cat test.shecho $-case "$-" in*i*) echo This shell is interactive;;*) echo This shell is not interactive;;esac[root@localhost ~]# bash test.shhBThis shell is not interactive[root@localhost ~]# echo $$31991[root@localhost ~]# bash -i test.sh himBThis shell is interactive[root@localhost ~]# echo $$31991 通过检查$PS1的内容是否为空判断，在非交互式shell中不会设置该变量 123456789101112131415161718192021[root@localhost ~]# echo $$31991[root@localhost ~]# cat test.shecho $-if [[ -z "$PS1" ]];then echo This shell is not interactiveelse echo This shell is interactivefi[root@localhost ~]# bash test.shhBThis shell is not interactive[root@localhost ~]# echo $$31991[root@localhost ~]# bash -i test.shhimBThis shell is interactive[root@localhost ~]# echo $$31991[root@localhost ~]# echo $-himBH himBH解释 交互式shell顾名思义，shell等待用户输入，输入后系统立即执行并返回结果，并等待一下此输入。当退出后，shell也终止了。 启动交互式shell的方法 启动shell时不带任何选项参数 启动shell时指定-i选项参数 启动shell时指定了-s且没有指定-c参数 非交互式shell通常情况下，执行shell脚本文件时的子shell都是属于非交互式的。在这种场景下，shell读取存放在脚本文件中的内容然后执行，直到读到文件的结尾EOF，shell终止。 登录shell与非登录shell登录式shell需要用户名和密码登录后才能进入的shell，或者通过–login选项打开的shell。 非登录式shell不需要输入用户名和密码即可打开的Shell，例如：直接命令“bash”就是打开一个新的非登录shell，在Gnome或KDE中打开一个“终端”（terminal）窗口程序也是一个非登录shell。 执行exit命令，退出一个shell（登录或非登录shell）；执行logout命令，退出登录shell（不能退出非登录shell） 123456789101112[root@localhost ~]# echo $$2532[root@localhost ~]# bash[root@localhost ~]# echo $$2709[root@localhost ~]# logoutbash: logout: not login shell: use 'exit'[root@localhost ~]# exitexit[root@localhost ~]# exitlogout连接断开 bash是 login shell 时，其进程名为&quot;-bash&quot; 而不是&quot;bash&quot; 12345678910111213141516[root@localhost ~]# echo $$2995[root@localhost ~]# ps -ef |grep -i bashroot 2995 2985 0 08:55 pts/0 00:00:00 -bashroot 3001 2985 0 08:55 pts/1 00:00:00 -bash[root@localhost ~]# bash[root@localhost ~]# echo $$3689[root@localhost ~]# ps -ef |grep -i bashroot 2995 2985 0 08:55 pts/0 00:00:00 -bashroot 3001 2985 0 08:55 pts/1 00:00:00 -bashroot 3689 2995 0 08:56 pts/0 00:00:00 bash[root@localhost ~]# exitexit[root@localhost ~]# echo $$2995 shell分类组合情况 登录式 非登录式 交互式 1.登录系统时获得的顶层shell，无论是通过本地终端登录，还是通过网络ssh登录2.使用bash –login命令启动的shell3.使用su [-/-l/–login] [user]切换到其他用户时 1.使用bash命令启动的shell2.使用su [user]切换到其他用户时 非交互式 在脚本中使用–login选项调用bash（比如在脚本第一行做如下指定：#!/bin/bash –login） 通常情况下执行bash脚本时运行脚本的子shell bash启动时执行的启动文件 登录式 非登录式 交互式 如果/etc/profile存在，则首先执行该文件依次查找存在并可读的~/.bash_profile, ~/.bash_login, ~/.profile中的第一个执行如果启动时指定了--noprofile选项，则不执行上述两个步骤退出时，如果~/.bash_logout存在则执行 如果~/.bashrc存在则执行如果指定了--norc参数则不执行上述步骤可以通过指定--rcfile file指定其他文件替代~/.bashrc 非交互式 同上 查找环境变量BASH_ENV，读取并执行BASH_ENV指向的文件中的内容 shell启动选项参数-i 选项强制子shell使用交互式方式运行 -c cmd_string 选项表示子shell从字符串中读入命令，如果字符串后还有变量就被设定为从$0开始的位置参数 1234[root@localhost ~]# /bin/bash -c 'echo hello world'hello world[root@localhost ~]# /bin/bash -c 'echo $0 $1' hello kittyhello kitty ssh执行远程命令和bash -c string的用法 -s 选项如果指定-s参数，那么表示子shell从标准输入中读入命令，直到输入exit。 该参数允许指定位置参数并将其传入子shell中。 12345678910111213141516171819202122232425262728[root@localhost ~]# echo $$9051# 进入子shell中，未指定-c参数时，子shell为交互式shell[root@localhost ~]# bash -s hello new world[root@localhost ~]# echo $$11211[root@localhost ~]# echo $-himBHs[root@localhost ~]# echo $1hello[root@localhost ~]# echo $2new[root@localhost ~]# echo $3world[root@localhost ~]# exitexit# 退回父shell[root@localhost ~]# echo $$9051# 如果指定-c参数，子shell为非交互式shell[root@localhost ~]# bash -s -c 'echo $0' hellohello[root@localhost ~]# echo $$9051[root@localhost ~]# bash -s -c 'echo $-'hBcs[root@localhost ~]# echo $$9051]]></content>
      <categories>
        <category>linux</category>
        <category>bash</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash中字典使用]]></title>
    <url>%2F2019%2F08%2F08%2Flinux%2Fbash-dict%2F</url>
    <content type="text"><![CDATA[bash版本号 12bash --versionGNU bash, version 4.2.46(2)-release bash中字典使用举例 字典声明赋值 与数组不同，字典使用前必须先声明 12345# Declare dict person 必须先声明declare -A person# 使用 () 赋值person=([name]="john" [age]="18") 字典读取及遍历12345678910111213141516171819202122declare -A person# 根据key读取字典内容person=([name]="lucy" [age]="22")echo $&#123;person["name"]&#125; # lucy# 读取不存在的key时，返回为空if [[ $&#123;person["phone"]&#125; =~ "" ]]; then echo "empty"; else echo "not empty"; fi # empty# 打印字典中的所有value, 返回值为数组echo $&#123;person[@]&#125; #lucy 22echo $&#123;person[@]:0:1&#125; #lucy# 打印字典中的所有key，返回值为数组echo $&#123;!person[@]&#125; #name age# 读取字典中键值对的数量echo $&#123;#person[@]&#125; # 2# for循环遍历字典for key in $&#123;!person[@]&#125;;do echo "key: $&#123;key&#125;, value: $&#123;person[$key]&#125;"; done#key: name, value: lucy#key: age, value: 22 字典中增加删除元素123456789101112131415161718192021222324#增加字典元素两种方式declare -A personperson=([name]="hanmeimei" [age]="23")person+=([phoneNumber]="13920380998")echo $&#123;person[@]&#125; # hanmeimei 23 13920380998echo $&#123;!person[@]&#125; # name age phoneNumberperson[addr]="shanghai"echo $&#123;person[@]&#125; #hanmeimei 23 shanghai 13920380998echo $&#123;!person[@]&#125; #name age addr phoneNumber#删除字典元素unset person[phoneNumber]echo $&#123;person[@]&#125; #hanmeimei 23 shanghaiecho $&#123;!person[@]&#125; #name age addr#删除不存在的字典元素时无影响unset person[phoneNumber]echo $&#123;person[@]&#125; #hanmeimei 23 shanghaiecho $&#123;!person[@]&#125; #name age addr#删除整个字典unset personif [[ $&#123;person&#125; =~ "" ]]; then echo "empty"; else echo "not empty"; fi #empty 字典元素值替换12345declare -A personperson=([name]="lilei" [age]="12")echo $&#123;person[name]&#125; #lileiperson[name]="lucy"echo $&#123;person[name]&#125; #lucy]]></content>
      <categories>
        <category>linux</category>
        <category>bash</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过shell实现yaml目标变量替换]]></title>
    <url>%2F2019%2F08%2F08%2Flinux%2Fshell-replace-yaml-template%2F</url>
    <content type="text"><![CDATA[yaml的模板build_template.yaml如下 123repos: - url: "$&#123;REPO_URL&#125;" branch: "$&#123;BRANCH&#125;" REPO_URL和BRANCH定义在环境变量中或写入config.ini文件 123# cat config.iniREPO_URL="https://github.com/etcd-io/etcd.git"BRANCH="master' 替换脚本如下 123configContent=$(cat config.ini)yamlTemplate=$(cat build_template.yaml)printf "$configContent\ncat &lt;&lt; EOF\n$&#123;yamlTemplate&#125;\nEOF" |bash &gt; ./build.yaml 生成的build.yaml文件内容如下: 123repos: - url: "https://github.com/etcd-io/etcd.git" branch: "master"]]></content>
      <categories>
        <category>linux</category>
        <category>bash</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
        <tag>yaml</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash数组]]></title>
    <url>%2F2019%2F07%2F23%2Flinux%2Fbash-array%2F</url>
    <content type="text"><![CDATA[bash版本号 12bash --versionGNU bash, version 4.2.46(2)-release bash数组使用举例 数组声明赋值1234567891011# Declare array namesdeclare -a names # 也可以不用声明，直接采用数组的赋值方式赋值，bash能自动识别为数组# 使用 [] 赋值names[0]="john"names[1]="lucy"# 使用 () 赋值names=("john" "lucy")names=([0]="john" [1]="lucy")names=([1]="jessica" [3]="hanmeimei") # 可以指定下标不连续 数组读取及遍历1234567891011121314151617181920# 根据下标读取数组内容names=([0]="lily" [1]="lucy" [3]="hanmeimei")echo $&#123;names[1]&#125; # lucyif [[ $&#123;names[2]&#125; =~ "" ]]; then echo "empty"; else echo "not empty"; fi # empty# 打印数组中所有元素， 此时打印出来的内容的是字符串列表echo $&#123;names[@]&#125; #lily lucy hanmeimei# 打印数组中元素的索引列表echo $&#123;!names[@]&#125; # 0 1 3# 读取数组长度# 上面定义的数组下标虽然不连续，但是数组长度仍为 3echo $&#123;#names[@]&#125; # 3# 遍历数组for name in $&#123;names[@]&#125;;do echo $name; done# lily# lucy# hanmeimei 数组截取及组合123456789101112131415161718names=('lilei' 'jack' 'hanmeimei' 'lily' 'lucy')# 截取从索引 1 开始（包含索引 1）的后面 3 个元素echo $&#123;names[@]:1:3&#125; # jack hanmeimei lily# 如果未指定元素个数，则表示后面所有元素echo $&#123;names[@]:2&#125; # hanmeimei lily lucy# 两个数组组合names1=('name1_1' 'name1_2')names2=('name2_1' 'name2_2' 'name2_3')names=($&#123;names1[@]&#125; $&#123;names2[@]&#125;)echo $&#123;names[@]&#125; # name1_1 name1_2 name2_1 name2_2 name2_3# 数组中增加元素names=('lily' 'lucy')names=("$&#123;names[@]&#125;" "hanmeimei")echo $&#123;names[@]&#125; # lily lucy hanmeimei 删除数据中元素1234567891011121314151617181920names=('lily' 'lucy' 'hanmeimei' 'lilei' 'jack')# 删除数组中索引为 1 的元素unset names[1]echo $&#123;names[@]&#125; # lily hanmeimei lilei jackecho $&#123;!names[@]&#125; # 0 2 3 4# 删除整个数组unset names# 使用数组截取然后重新组合方式删除元素names=('lily' 'lucy' 'hanmeimei' 'lilei' 'jack')names=($&#123;names[@]:0:1&#125; $&#123;names[@]:2&#125;)echo $&#123;names[@]&#125; # lily hanmeimei lilei jackecho $&#123;!names[@]&#125; # 0 1 2 3# 使用模式操作符删除数组中的元素names=('lily' 'lucy' 'hanmeimei' 'lilei' 'jack')names=(@&#123;names[@]/lucy/&#125;)echo $&#123;names[@]&#125; # lily hanmeimei lilei jackecho $&#123;!names[@]&#125; # 0 1 2 3 数组元素值替换123456789# 使用数组下标赋值names=('lilei' 'hanmeimei' 'lucy' 'lily')names[1]='jessica'echo $&#123;names[@]&#125; # lilei jessica lucy lily#使用模式操作符进行内容替换names=('lilei' 'hanmeimei' 'lucy' 'lily')names=($&#123;names[@]/hanmeimei/jessica&#125;)echo $&#123;names[@]&#125; # lilei jessica lucy lily]]></content>
      <categories>
        <category>linux</category>
        <category>bash</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bash使用总结]]></title>
    <url>%2F2019%2F07%2F23%2Flinux%2Fbash-usage%2F</url>
    <content type="text"><![CDATA[bash启动简介bash参数 Bash官网 Bash数组Bash字典 通过shell实现yaml模板变量替换]]></content>
      <categories>
        <category>linux</category>
        <category>bash</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>linux</tag>
        <tag>bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pipeline序列化问题]]></title>
    <url>%2F2019%2F07%2F22%2Fjenkins%2Fjenkins-serialization%2F</url>
    <content type="text"><![CDATA[Jenkins支持所有运行的job都可以在服务重启时中断、暂停在服务重启后恢复运行。为了实现这一点，Jenkins pipeline中定义的所有变量都必须是可序列化的。类似的，Jenkins也必须能序列化构建中节点和子job之间的全局变量的状态。 遇到java.io.NotSerializableException问题的一般方法 将不可序列化的代码封装在一个用@NonCPS注释的函数中。这告诉Jenkins函数包含不可序列化的部分，必须在不可中断的情况下执行。使用NonCPS的函数中不能调用任何jenkins steps或其他CPS-transformed的代码。 尝试取消不可序列化变量的定义 更多详细信息参见链接 json解析 12345678910111213import groovy.json.JsonSlurperClassic @NonCPSdef jsonParse(def json) &#123; new groovy.json.JsonSlurperClassic().parseText(json)&#125;node('master') &#123; def config = jsonParse(readFile("config.json")) def db = config["database"]["address"] ...&#125; 参考1参考2参考3]]></content>
      <categories>
        <category>tool</category>
        <category>持续集成</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-log命令]]></title>
    <url>%2F2019%2F07%2F22%2Fgit%2Fgit-cmd-log%2F</url>
    <content type="text"><![CDATA[命令格式1git log [&lt;options&gt;] [&lt;revision range&gt;] [[--] &lt;path&gt;…​] 命令参数选项 选项 说明 -p 以补丁格式显示每次提交之间的差异 –stat 显示每次提交的文件修改统计信息 –shortstat 只显示 –stat 中最后的行数修改添加移除统计 –name-only 仅在提交信息后显示已修改的文件清单 –name-status 显示新增、修改、删除的文件清单 –abbrev-commit 仅显示 SHA-1 的前几个字符，而非所有的 40 个字符 –relative-date 使用较短的相对时间显示（比如”2 weeks ago”） –graph 显示 ASCII 图形表示的分支合并历史 –pretty 使用其他格式显示历史提交信息。可用的选项包括 oneline，short，full，fuller 和 format（后跟指定格式，格式见下表） –oneline –pretty=oneline –abbrev-commit 的简化用法 -(n) 仅显示最近的 n 条提交 –since, –after 仅显示指定时间之后的提交, 可以使用各种时间格式，比如说具体的某一天（”2008-01-15”），或者是多久以前（”2 years 1 day 3 minutes ago”） –until, –before 仅显示指定时间之前的提交 –author 仅显示指定作者相关的提交 –committer 仅显示指定提交者相关的提交 format常用的格式占位符写法及其代表的意义。 选项 说明 %H 提交对象（commit）的完整哈希字串 %h 提交对象的简短哈希字串 %T 树对象（tree）的完整哈希字串 %t 树对象的简短哈希字串 %P 父对象（parent）的完整哈希字串 %p 父对象的简短哈希字串 %an 作者（author）的名字 %ae 作者的电子邮件地址 %ad 作者修订日期（可以用 -date= 选项定制格式） %ar 作者修订日期，按多久以前的方式显示 %cn 提交者(committer)的名字 ce 提交者的电子邮件地址 %cd 提交日期 %cr 提交日期，按多久以前的方式显示 %s 提交说明]]></content>
      <categories>
        <category>tool</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos下jenkins的安装]]></title>
    <url>%2F2019%2F07%2F16%2Fcentos%2Fcentos-jenkins-install%2F</url>
    <content type="text"><![CDATA[非docker安装通过设置jenkins官方repo仓库下载1234sudo wget -O /etc/yum.repos.d/jenkins.repo https://pkg.jenkins.io/redhat-stable/jenkins.reposudo rpm --import https://pkg.jenkins.io/redhat-stable/jenkins.io.keyyum install jenkinscat /etc/rc.d/init.d/jenkins 安装后，jenkins.war默认地址为JENKINS_WAR=”/usr/lib/jenkins/jenkins.war” jenkins的config地址为JENKINS_CONFIG=/etc/sysconfig/jenkins jenkins服务的启动/停止/重启脚本为/etc/init.d/jenkins 下载rpm安装12wget https://pkg.jenkins.io/redhat-stable/jenkins-2.176.1-1.1.noarch.rpmrpm -ivh jenkins-2.176.1-1.1.noarch.rpm 下载war包12wget http://mirrors.jenkins.io/war-stable/latest/jenkins.warjava -jar jenkins.war 常用的启动参数为: 1234567891011121314151617java -Duser.timezone=GMT+08 \ -Djava.util.logging.config.file=/var/jenkins_home/jenkins.logging.properties \ -Dgroovy.grape.report.downloads=true -Divy.message.logger.level=4 \ -Dhudson.model.ParametersAction.keepUndefinedParameters=true \ -Dhudson.security.ArtifactsPermission=true -Djava.awt.headless=true \ -Dorg.apache.commons.jelly.tags.fmt.timeZone=Asia/Shanghai \ -Dfile.encoding=UTF-8 -Dsun.jnu.encoding=UTF-8 \ -Dhudson.slaves.NodeProvisioner.MARGIN=50 \ -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 \ -Dhudson.slaves.NodeProvisioner.initialDelay=0 \ -Dhudson.slaves.NodeProvisioner.recurrencePeriod=2 \ -Dhudson.model.LoadStatistics.clock=2 \ -Dhudson.model.LoadStatistics.decay=0.1 \ -server -Xms10g -Xmx32g -XX:MaxPermSize=4g -XX:+HeapDumpOnOutOfMemoryError \ -Xloggc:/var/jenkins_home/jenkins_gc.log \ -DJENKINS_HOME=/var/jenkins_home \ -jar jenkins.war --logfile=/var/jenkins_home/jenkins.log jenkins.logging.properties 的内容参见说明 虚拟机中启动jenkins后不能访问 关闭防火墙 123systemctl status firewalldsystemctl stop firewalldsystemctl disable firewalld 配置防火墙开放jinkins使用的端口 123456789101112# 检查当前防火墙开放的端口[root@localhost ~]# firewall-cmd --list-ports# 配置防火墙开放端口[root@localhost ~]# firewall-cmd --permanent --zone=public --add-port=8080/tcpsuccess[root@localhost ~]# firewall-cmd --list-ports# 重启防火墙[root@localhost ~]# systemctl reload firewalld[root@localhost ~]# firewall-cmd --list-ports8080/tcp docker安装docker hub中有两种jenkins的镜像，jenkins官方推荐使用 jenkinsci/blueocean 镜像，该镜像中包含了blueocean插件，该镜像会在blueocean发布新版本时同步发布。还有一个镜像 jenkins/jenkins, 为jenkins的纯净版本。 jenkins/jenkins的github地址 容器化安装时，支持配置下面三个环境变量，来定义jenkins的配置 JAVA_OPTS JENKINS_HOME JENKINS_OPTS JENKINS_SLAVE_AGENT_PORT 123456789101112docker run \ --restart=always \ -d \ -p 80:8080 \ -p 31281:31281 \ -e JENKINS_SLAVE_AGENT_PORT=31281 \ -e JENKINS_HOME="/var/jenkins_home" \ -e JAVA_OPTS="-Duser.timezone=GMT+08 -Dgroovy.grape.report.downloads=true -Divy.message.logger.level=4 -Djava.util.logging.config.file=/var/jenkins_home/jenkins.logging.properties -Dhudson.model.ParametersAction.keepUndefinedParameters=true -Dhudson.security.ArtifactsPermission=true -Djava.awt.headless=true -Dorg.apache.commons.jelly.tags.fmt.timeZone=Asia/Shanghai -Dfile.encoding=UTF-8 -Dsun.jnu.encoding=UTF-8 -Dhudson.slaves.NodeProvisioner.MARGIN=50 -Dhudson.slaves.NodeProvisioner.MARGIN0=0.85 -Dhudson.slaves.NodeProvisioner.initialDelay=0 -Dhudson.slaves.NodeProvisioner.recurrencePeriod=2 -Dhudson.model.LoadStatistics.clock=2 -Dhudson.model.LoadStatistics.decay=0.1 -server -Xms10g -Xmx32g -XX:MaxPermSize=4g -XX:+HeapDumpOnOutOfMemoryError -Xloggc:/var/jenkins_home/jenkins_gc.log" \ -e JENKINS_OPTS="--logfile=/var/jenkins_home/logs/jenkins.log" \ -v /data/jenkins_home:/var/jenkins_home \ -v /var/run/docker.sock:/var/run/docker.sock \ jenkins/jenkins jenkins.logging.properties 的内容参见说明]]></content>
      <categories>
        <category>linux</category>
        <category>centos</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins通过Grab下载依赖失败]]></title>
    <url>%2F2019%2F07%2F16%2Fgroovy%2Fjenkins-groovy-grape%2F</url>
    <content type="text"><![CDATA[官方文档极客学院翻译 问题描述在使用Jenkins的 pipeline as code 特性时，遇到使用第三方jar的情况，使用了@Grab(group=&#39;org.restlet&#39;, module=&#39;org.restlet&#39;, version=&#39;1.1.6&#39;)注解，但是在Jenkins job运行时下载依赖失败。 解决方法grape默认时采用maven的 mvnrepository.com 来搜索依赖包，出问题的Jenkins master上是不能访问该仓库的，所以下载依赖失败。 在${user.home}/.groovy/目录下新增文件grapeConfig.xml，指定仓库地址为内网仓库或可访问的maven镜像仓库。 12345678&lt;ivysettings&gt; &lt;settings defaultResolver="downloadGrapes"/&gt; &lt;resolvers&gt; &lt;chain name="downloadGrapes"&gt; &lt;ibiblio name="public" root="https://mirrors.huaweicloud.com/repository/maven/" m2compatible="true"/&gt; &lt;/chain&gt; &lt;/resolvers&gt;&lt;/ivysettings&gt; grapeConfig.xml的默认配置为 123456789101112131415&lt;ivysettings&gt; &lt;settings defaultResolver="downloadGrapes"/&gt; &lt;resolvers&gt; &lt;chain name="downloadGrapes" returnFirst="true"&gt; &lt;filesystem name="cachedGrapes"&gt; &lt;ivy pattern="$&#123;user.home&#125;/.groovy/grapes/[organisation]/[module]/ivy-[revision].xml"/&gt; &lt;artifact pattern="$&#123;user.home&#125;/.groovy/grapes/[organisation]/[module]/[type]s/[artifact]-[revision](-[classifier]).[ext]"/&gt; &lt;/filesystem&gt; &lt;ibiblio name="localm2" root="file:$&#123;user.home&#125;/.m2/repository/" checkmodified="true" changingPattern=".*" changingMatcher="regexp" m2compatible="true"/&gt; &lt;!-- todo add 'endorsed groovy extensions' resolver here --&gt; &lt;ibiblio name="jcenter" root="https://jcenter.bintray.com/" m2compatible="true"/&gt; &lt;ibiblio name="ibiblio" m2compatible="true"/&gt; &lt;/chain&gt; &lt;/resolvers&gt;&lt;/ivysettings&gt; Jenkins中grape下载的第三方jar默认是缓存在${user.home}/.groovy/grapes/目录下。可以通过添加Jenkins的启动参数-Dgroovy.grape.report.downloads=true 和 -Divy.message.logger.level=4，在jenkins的日志中观察第三方依赖的下载过程。 如果jenkins master采用docker方式安装时，使用jenkins用户登录，同时设置jenkins的user.home为JENKINS_HOME即可。]]></content>
      <categories>
        <category>language</category>
        <category>groovy</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>groovy</tag>
        <tag>grape</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-commit命令]]></title>
    <url>%2F2019%2F07%2F16%2Fgit%2Fgit-cmd-commit%2F</url>
    <content type="text"><![CDATA[git commit –amend建议 git commit –amend 命令使用在未push到远端的场景。 提交还未push到远端在某次修改时，修改了README.md文件，同时新增了amendTest文件。但是在commit的时候，只提交了README.md，忘记了amendTest文件。 1234567891011121314151617181920212223242526272829303132333435363738[root@localhost gitTest]# git statusOn branch masterYour branch is up to date with 'origin/master'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git checkout -- &lt;file&gt;..." to discard changes in working directory) modified: README.mdUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) amendTestno changes added to commit (use "git add" and/or "git commit -a")[root@localhost gitTest]# git commit -am 'add amendTest file'[master ce1e058] add amendTest file 1 file changed, 1 insertion(+)[root@localhost gitTest]# git statusOn branch masterYour branch is ahead of 'origin/master' by 1 commit. (use "git push" to publish your local commits)Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) amendTestnothing added to commit but untracked files present (use "git add" to track)[root@localhost gitTest]# git log -n 3 --onelinea889479 (HEAD -&gt; master) add amendTest file11843d7 (origin/master, origin/HEAD) updatebf2a12f update[root@localhost gitTest]# git diff --stat HEAD~1 HEAD README.md | 1 + 1 file changed, 1 insertion(+)[root@localhost gitTest]# 此时，如果想将amendTest文件提交，同时不产生新的commit记录(即新提交内容合并到上一次提交中)，可以使用git commit --amend命令 123456789101112131415161718192021222324252627[root@localhost gitTest]# git add .[root@localhost gitTest]# git commit --amendadd amendTest file# Please enter the commit message for your changes. Lines starting# with '#' will be ignored, and an empty message aborts the commit.## Date: Sun Jun 30 15:00:20 2019 +0800## On branch master# Your branch is ahead of 'origin/master' by 1 commit.# (use "git push" to publish your local commits)## Changes to be committed:# modified: README.md# new file: amendTest Date: Sun Jun 30 15:00:20 2019 +0800 2 files changed, 2 insertions(+) create mode 100644 amendTest[root@localhost gitTest]# git log -n 3 --onelined2a42e9 (HEAD -&gt; master) add amendTest file11843d7 (origin/master, origin/HEAD) updatebf2a12f update[root@localhost gitTest]# git diff --stat HEAD~1 HEAD README.md | 1 + amendTest | 1 + 2 files changed, 2 insertions(+) 使用该git commit --amend命令后，会生成一个新的commitid，合并本次提交与上一次提交内容。 提交已经push到远端如果上一次commit已经push到远端，使用git commit --amend提交后，在push到远端时会被拒绝，通过git status提示发现当前分支与origin/master已经分叉 通过git pull将origin/master代码merge过来后，重新push可以推送成功 但是通过git log可以发现远端仍是有两次提交记录。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485[root@localhost gitTest]# git log -n 3 --onelinee30f084 (HEAD -&gt; master) add amendTest file11843d7 (origin/master, origin/HEAD) updatebf2a12f update[root@localhost gitTest]# git push origin masterEnumerating objects: 5, done.Counting objects: 100% (5/5), done.Compressing objects: 100% (3/3), done.Writing objects: 100% (3/3), 404 bytes | 202.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)To github.com:daybreakgx/gitTest.git 11843d7..e30f084 master -&gt; master[root@localhost gitTest]# git log -n 3 --onelinee30f084 (HEAD -&gt; master, origin/master, origin/HEAD) add amendTest file11843d7 updatebf2a12f update[root@localhost gitTest]# git add .[root@localhost gitTest]# git commit --amend[master 7e0656c] add amendTest file add 2 Date: Sun Jun 30 15:25:00 2019 +0800 2 files changed, 2 insertions(+) create mode 100644 amendTest[root@localhost gitTest]# git statusOn branch masterYour branch and 'origin/master' have diverged,and have 1 and 1 different commits each, respectively. (use "git pull" to merge the remote branch into yours)nothing to commit, working tree clean[root@localhost gitTest]# git log -n 3 --oneline7e0656c (HEAD -&gt; master) add amendTest file add 211843d7 updatebf2a12f update[root@localhost gitTest]# git push origin masterTo github.com:daybreakgx/gitTest.git ! [rejected] master -&gt; master (non-fast-forward)error: failed to push some refs to 'git@github.com:daybreakgx/gitTest.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details.[root@localhost gitTest]# git pullMerge made by the 'recursive' strategy.[root@localhost gitTest]# git statusOn branch masterYour branch is ahead of 'origin/master' by 2 commits. (use "git push" to publish your local commits)nothing to commit, working tree clean[root@localhost gitTest]# git push origin masterEnumerating objects: 6, done.Counting objects: 100% (6/6), done.Compressing objects: 100% (3/3), done.Writing objects: 100% (4/4), 437 bytes | 218.00 KiB/s, done.Total 4 (delta 2), reused 0 (delta 0)remote: Resolving deltas: 100% (2/2), completed with 1 local object.To github.com:daybreakgx/gitTest.git e30f084..bef9cc4 master -&gt; master[root@localhost gitTest]# git log --graph* commit bef9cc49c27913ca9924378dd50c0ef50f6d8d48 (HEAD -&gt; master, origin/master, origin/HEAD)|\ Merge: 7e0656c e30f084| | Author: daybreakgx &lt;daybreak.gx@gmail.com&gt;| | Date: Sun Jun 30 15:27:59 2019 +0800| | | | Merge branch 'master' of github.com:daybreakgx/gitTest| | | * commit e30f08487acfe730bfa241e0042a55503d41b791| | Author: daybreakgx &lt;daybreak.gx@gmail.com&gt;| | Date: Sun Jun 30 15:25:00 2019 +0800| | | | add amendTest file| | * | commit 7e0656c521428142bd248153050918a7a5f5d0ab|/ Author: daybreakgx &lt;daybreak.gx@gmail.com&gt;| Date: Sun Jun 30 15:25:00 2019 +0800| | add amendTest file add 2| * commit 11843d78157ea67dc2d4768366c1f6c446d93071| Author: daybreakgx &lt;daybreak.gx@gmail.com&gt;| Date: Sun Jun 30 14:58:02 2019 +0800| | update 撤销git commit –amend]]></content>
      <categories>
        <category>tool</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-ls-files命令]]></title>
    <url>%2F2019%2F07%2F08%2Fgit%2Fgit-cmd-ls-files%2F</url>
    <content type="text"><![CDATA[该命令用于显示暂存区(index)或工作区(working tree)的文件信息 命令格式git ls-files [-z] [-t] [-v] [-f] (–[cached|deleted|others|ignored|stage|unmerged|killed|modified]) (-[c|d|o|i|s|u|k|m]) [–eol] [-x &lt;pattern>|–exclude=&lt;pattern>] [-X &lt;file>|–exclude-from=&lt;file>] [–exclude-per-directory=&lt;file>] [–exclude-standard] [–error-unmatch] [–with-tree=&lt;tree-ish>] [–full-name] [–recurse-submodules] [–abbrev] [–] [&lt;file>…​] 命令参数选项 -c, –cached: 显示暂存区中的文件 -d, –deleted: 显示删除了的文件 -m, –modified: 显示修改了的文件 -i, –ignored: 显示忽略了的文件(满足忽略模式的) -o, –others: 显示其他类型的文件(如未追踪的) -s, –stage: 按照如下格式显示文件内容[&lt;tag\&gt;] &lt;mode\&gt; &lt;object\&gt; &lt;stage\&gt; &lt;file\&gt;]]></content>
      <categories>
        <category>tool</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-update-index命令]]></title>
    <url>%2F2019%2F07%2F07%2Fgit%2Fgit-cmd-update-index%2F</url>
    <content type="text"><![CDATA[通常该命令用于将工作区(working tree)中的内容注册到暂存区(index) 命令格式git update-index [–add] [–remove | –force-remove] [–replace] [–refresh] [-q] [–unmerged] [–ignore-missing] [(–cacheinfo &lt;mode>,&lt;object>,&lt;file>)…​] [–chmod=(+|-)x] [–[no-]assume-unchanged] [–[no-]skip-worktree] [–[no-]fsmonitor-valid] [–ignore-submodules] [–[no-]split-index] [–[no-|test-|force-]untracked-cache] [–[no-]fsmonitor] [–really-refresh] [–unresolve] [–again | -g] [–info-only] [–index-info] [-z] [–stdin] [–index-version &lt;n>] [–verbose] [–] [&lt;file>…​] 命令参数选项 –add: 如果指定的文件不在暂存区(index)中，则将其加入暂存区。 例子增加工作区新文件到暂存区123456789101112131415161718192021222324252627282930[root@localhost git_update_index]# git initInitialized empty Git repository in /root/git_update_index/.git/[root@localhost git_update_index]# find .git/objects/ -type f[root@localhost git_update_index]# echo 'version 1' &gt; text.txt[root@localhost git_update_index]# git statusOn branch masterNo commits yetUntracked files: (use "git add &lt;file&gt;..." to include in what will be committed) text.txtnothing added to commit but untracked files present (use "git add" to track)[root@localhost git_update_index]# git update-index --add text.txt[root@localhost git_update_index]# git statusOn branch masterNo commits yetChanges to be committed: (use "git rm --cached &lt;file&gt;..." to unstage) new file: text.txt[root@localhost git_update_index]# find .git/objects/ -type f.git/objects/83/baae61804e65cc73a7201a7252750c76066a30[root@localhost git_update_index]# git cat-file -p 83baae6version 1]]></content>
      <categories>
        <category>tool</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-cat-file 命令]]></title>
    <url>%2F2019%2F07%2F07%2Fgit%2Fgit-cmd-cat-file%2F</url>
    <content type="text"><![CDATA[该命令用于显示指定对象的信息 命令格式12git cat-file (-t [--allow-unknown-type]| -s [--allow-unknown-type]| -e | -p | &lt;type&gt; | --textconv | --filters ) [--path=&lt;path&gt;] &lt;object&gt;git cat-file (--batch | --batch-check) [ --textconv | --filters ] [--follow-symlinks] 命令参数选项 -t: 显示对象类型 -s: 显示对象大小(bytes) -e: 如果对象存在且是有效的，则命令正常返回0；如果对象无效，则命令返回非零值，并在标准错误输入打印错误信息 -p: 显示对象内容 –batch: 从标准输入读取对象id，显示对象信息(类型、大小)和对象内容 –batch-check: 从标准输入读取对象id，显示对象信息(类型、大小) 例子12345678910111213141516171819202122232425262728293031323334[root@localhost gitNewTest]# find .git/objects/ -type f.git/objects/3b/18e512dba79e4c8300dd08aeb37f8e728b8dad[root@localhost gitNewTest]# git cat-file -p 3b18e512hello world[root@localhost gitNewTest]# git cat-file -s 3b18e51212[root@localhost gitNewTest]# git cat-file -t 3b18e512blob[root@localhost gitNewTest]# git cat-file -e 3b18e512[root@localhost gitNewTest]# echo $?0[root@localhost gitNewTest]# git cat-file -e 3b18e513fatal: Not a valid object name 3b18e513[root@localhost gitNewTest]# echo $?128[root@localhost gitNewTest]# git cat-file -t 3b18e513fatal: Not a valid object name 3b18e513[root@localhost gitNewTest]# echo $?128[root@localhost gitNewTest]# git cat-file --batch3b18e5123b18e512dba79e4c8300dd08aeb37f8e728b8dad blob 12hello world3333333333 missing^C[root@localhost gitNewTest]# git cat-file --batch-check3b18e5123b18e512dba79e4c8300dd08aeb37f8e728b8dad blob 12adcesadces missing^C[root@localhost gitNewTest]#]]></content>
      <categories>
        <category>tool</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-hash-object 命令]]></title>
    <url>%2F2019%2F07%2F07%2Fgit%2Fgit-cmd-hash-object%2F</url>
    <content type="text"><![CDATA[该命令可以计算指定对象的object ID，并且通过指定参数(-w)将指定对象写入数据库中。该ID是个SHA-1哈希值，通过将待存储的数据内容(指定对象内容)加一个头部信息(header)一起做SHA-1校验运算得到的校验和。 命令格式12git hash-object [-t &lt;type&gt;] [-w] [--path=&lt;file&gt;|--no-filters] [--stdin [--literally]] [--] &lt;file&gt;…​git hash-object [-t &lt;type&gt;] [-w] --stdin-paths [--no-filters] 命令参数选项 -t &lt;type>: 对象类型， 默认为数据对象blob object -w: 设置该参数表示要将对象内容写入数据库 –stdin: 表示从标准输入读取对象内容 –stdin-paths: 表示从标准输入读取保存对象内容的文件名，每行表示一个文件 –: 标记后续参数类型，即 – 后面的参数会被解析为file 例子123456789101112131415161718192021[root@localhost gitNewTest]# find .git/objects -type f# 从标准输入读取内容写入数据库[root@localhost gitNewTest]# echo "hello world" |git hash-object -w --stdin3b18e512dba79e4c8300dd08aeb37f8e728b8dad[root@localhost gitNewTest]# find .git/objects -type f.git/objects/3b/18e512dba79e4c8300dd08aeb37f8e728b8dad[root@localhost gitNewTest]# tree .git/objects/.git/objects/├── 3b # SHA-1哈希值前两个字符做目录│ └── 18e512dba79e4c8300dd08aeb37f8e728b8dad # SHA-1哈希值剩余38个字符做文件名├── info└── pack3 directories, 1 file# 从文件中读取内容写入数据库[root@localhost gitNewTest]# echo 'version 1' &gt; text.txt[root@localhost gitNewTest]# cat text.txtversion 1[root@localhost gitNewTest]# git hash-object -w text.txt83baae61804e65cc73a7201a7252750c76066a30]]></content>
      <categories>
        <category>tool</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum源优先级配置]]></title>
    <url>%2F2019%2F06%2F30%2Fcentos%2Fyum-priorities%2F</url>
    <content type="text"></content>
      <categories>
        <category>linux</category>
        <category>centos</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>yum</tag>
        <tag>TODO</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[epel配置与使用]]></title>
    <url>%2F2019%2F06%2F30%2Fcentos%2Fepel%2F</url>
    <content type="text"><![CDATA[为了保证稳定性，RHEL及其衍生版本Centos等的官方rpm repository中提供的软件版本都相对比较滞后。为了能使用相对较新的软件版本，可以使用EPEL扩展源。 EPEL(Extra Packages for Enterprise Linux)，是由Fedora社区维护的，为RHEL系列操作系统提供高质量软件包的项目。 yum命令安装1yum -y install epel-release rpm包安装根据系统CPU架构及操作系统版本，到 https://dl.fedoraproject.org/pub/epel/ 下载对应的rpm进行安装。 12wget wget https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpmrpm -ivh epel-release-latest-7.noarch.rpm 或 1yum -y install http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm 验证12345678910111213$ yum clean all; yum makecache$ yum repolistLoading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: mirrors.tuna.tsinghua.edu.cn * extras: mirrors.aliyun.com * updates: mirrors.aliyun.comrepo id repo name statusbase/7/x86_64 CentOS-7 - Base - mirrors.aliyun.com 10,019epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 13,242extras/7/x86_64 CentOS-7 - Extras - mirrors.aliyun.com 419updates/7/x86_64 CentOS-7 - Updates - mirrors.aliyun.com 2,137repolist: 25,817]]></content>
      <categories>
        <category>linux</category>
        <category>centos</category>
      </categories>
      <tags>
        <tag>epel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git内部原理]]></title>
    <url>%2F2019%2F06%2F30%2Fgit%2Fgit-internals%2F</url>
    <content type="text"><![CDATA[概述Git从根本上说是一个基于内容寻址(content-addressable)的文件系统，并在此之上提供一个VCS的用户界面。 最初git只是为VCS提供的一套工具集，而不是一个完成的VCS，所以git存在一系列命令能完成一些底层操作，这些命令被设计为能以Unix-style连接(chained)在一起，或者可以被脚本调用。这些命令被称为底层(plumbing)命令。相对应的那些更友好(user-friendly)的命令被称为高层(porcelain)命令。 通常情况下，不会在命令行中直接使用这些底层命令，它们更多被用于构建新的命令或用于自定义的脚本。 .git目录在执行完git init命令后，会生成一个.git目录。该目录里面包含了几乎所有的git存储和操作的对象。如果你想备份或克隆一个你的repo，只需要将copy该目录即可。 一个已经有提交记录的.git目录内容如下: 123456789101112131415161718192021222324252627282930313233[root@localhost .git]# tree -F ..├── branches/├── config # 包含所有特有(project-specific)的配置项├── description # 该文件仅用于GitWeb程序，无需关注├── HEAD # imp├── hooks/ # 保存服务端和客户端的git钩子脚本├── index # imp├── info/ # 该目录下的exclude文件用于保存不希望配置在.gitignore文件中的忽略模式│ └── exclude├── logs/│ ├── HEAD│ └── refs/│ ├── heads/│ │ └── master│ └── remotes/│ └── origin/│ └── HEAD├── objects/ # imp, 存储所有的数据内容，包括所有文件的历史版本和commit信息│ ├── info/│ └── pack/│ ├── pack-de504965c4952729b475b8075c814b171ef83bf8.idx│ └── pack-de504965c4952729b475b8075c814b171ef83bf8.pack├── packed-refs└── refs/ # imp ├── heads/ │ └── master ├── remotes/ │ └── origin/ │ └── HEAD └── tags/16 directories, 24 files 文件HEAD、index和目录objects、refs是git系统的核心组成部分。 git初始化时的.git目录如下： 123456789101112131415[root@localhost .git]# tree -F ..├── branches/├── config├── description├── HEAD├── hooks/├── info/│ └── exclude├── objects/│ ├── info/│ └── pack/└── refs/ ├── heads/ └── tags/ git对象数据对象(blob object)通过 git hash-object 将文件内容写入数据库，生成的就是数据对象，可以通过 git cat-file -t 查看对象类型 123456789101112131415161718192021222324252627# 创建一个新文件，将文件内容写入数据库[root@localhost gitNewTest]# echo 'version 1' &gt; text.txt[root@localhost gitNewTest]# cat text.txtversion 1# 将文件内容写入数据库，生成一个数据对象[root@localhost gitNewTest]# git hash-object -w text.txt83baae61804e65cc73a7201a7252750c76066a30[root@localhost gitNewTest]# find .git/objects -type f.git/objects/83/baae61804e65cc73a7201a7252750c76066a30# 修改文件内容，将修改后的文件再次写入数据库，又会生成一个数据对象[root@localhost gitNewTest]# echo 'version 2' &gt; text.txt[root@localhost gitNewTest]# git hash-object -w text.txt1f7a7a472abf3dd9643fd615f6da379c4acb3e3a[root@localhost gitNewTest]# find .git/objects -type f.git/objects/83/baae61804e65cc73a7201a7252750c76066a30.git/objects/1f/7a7a472abf3dd9643fd615f6da379c4acb3e3a[root@localhost gitNewTest]# cat text.txtversion 2# 将第一个版本的内容从数据库中读出再次写回文件[root@localhost gitNewTest]# git cat-file -p 83baae6 &gt; text.txt[root@localhost gitNewTest]# cat text.txtversion 1# 查看对象内容均为数据对象[root@localhost gitNewTest]# git cat-file -t 83baae6blob[root@localhost gitNewTest]# git cat-file -t 1f7a7a4blob 使用上述方式，只能保存文件内容，不能保存文件名称。可以使用下面的树对象实现文件名保存。 树对象(tree object)git以一种类似Unix文件系统的方式存储内容。所有内容均以树对象和数据对象的形式存储，树对象对应了Unix中的目录项，数据对象大致对应了inodes或文件内容。 一个树对象包含了一条或多条树对象记录(tree entry)，每条记录对应一个指向数据对象或子树对象的SHA-1指针，以及对应的模式、类型、文件名信息。 提交对象(commit object)标签对象(tag object)参考资料 ProGit]]></content>
      <categories>
        <category>tool</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>TODO</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git-diff命令]]></title>
    <url>%2F2019%2F06%2F29%2Fgit%2Fgit-cmd-diff%2F</url>
    <content type="text"><![CDATA[命令格式12345678git diff [&lt;options&gt;] [--] [&lt;path&gt;..] # 默认表示比较工作区与暂存区git diff [&lt;options&gt;] HEAD [--] [&lt;path&gt;..] # 表示比较工作区与本地版本库最新版本git diff [&lt;options&gt;] commitid [--] [&lt;path&gt;..] # 表示比较工作区与指定commit id版本git diff [&lt;options&gt;] --cached [--] [&lt;path&gt;..] # 表示比较暂存区与本地库最新版本git diff [&lt;options&gt;] --cached commitid [--] [&lt;path&gt;..] # 表示比较暂存区与指定commit id版本git diff [&lt;options&gt;] commitid commitid [--] [&lt;path&gt;..] # 表示比较两次commitid之间的差异 命令参数选项 –raw: 显示原始的差异格式，如下: 123[root@localhost gitTest]# git diff --cached --raw:000000 100644 0000000 31d115c A addfile:100644 100644 389cecf 1f09c93 M newfile2 –stat: 显示差异统计结果，如下： 1234[root@localhost gitTest]# git diff --cached --stataddfile | 5 +++++newfile2 | 3 +--2 files changed, 6 insertions(+), 2 deletions(-) –shortstat: 只显示--stat的最后一行内容 12[root@localhost gitTest]# git diff --cached --shortstat2 files changed, 6 insertions(+), 2 deletions(-) –numstat: 只显示增加和删除的行数统计 123[root@localhost gitTest]# git diff --cached --numstat5 0 addfile1 2 newfile2 –name-only: 只显示哪些文件有差异 123[root@localhost gitTest]# git diff --cached --name-onlyaddfilenewfile2 使用git diff打补丁将工作区与本地仓库的差异做成补丁git diff &gt; patch_name 检验补丁是否能使用，如果没有任何输出表示可以顺利接受该补丁git apply –check patch_name 在另外一个地方应用补丁git apply patch_name 命令回显说明git diff命令的回显采用的时GNU diff命令合并格式的变体 linux下通过diff -u file_a file_b来显示diff的合并格式 内容增删12345678910111213141516171819202122232425262728293031&gt; git diff HEAD~1 HEADdiff --git a/README.md b/README.md # 表示显示内容为git格式的diffindex ae50fdb..54e2aab 100644 # ae50fab..54e2aab表示两个版本对象的哈希值 # 100644表示对象的模式(普通文件， 644权限)--- a/README.md # --- 表示变动前的版本+++ b/README.md # +++ 表示变动后的版本@@ -5,6 +5,7 @@ # 该行表示变动的位置，由两个@表示开头和结尾 # - 表示 文件a/README.md， + 表示文件b/README.md # 5,6 表示下方显示内容为a/README.md的第5行开始，连续6行 # 5,7 表示下方显示内容为b/README.md的第5行开始，连续7行 b c d+new line e f gdiff --git a/newfile b/newfileindex fd54aa0..2d3a259 100644--- a/newfile+++ b/newfile@@ -1,5 +1,7 @@ add new file 1-2-3++ds+honda+toyta 新增文件1234567891011diff --git a/newfile3 b/newfile3new file mode 100644index 0000000..d4afdcc--- /dev/null+++ b/newfile3@@ -0,0 +1,5 @@+add new file3++new file++new file end 删除文件12345678910111213diff --git a/newfile b/newfiledeleted file mode 100644index 2d3a259..0000000--- a/newfile+++ /dev/null@@ -1,7 +0,0 @@-add new file-1--ds-honda-toyta- 重命名文件12345678910111213141516diff --git a/deletefile b/newfile2similarity index 89%rename from deletefilerename to newfile2index 08cb754..389cecf 100644--- a/deletefile+++ b/newfile2@@ -1,8 +1,6 @@ file tobe rename 1 2-3-4 5 6 7]]></content>
      <categories>
        <category>tool</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用总结]]></title>
    <url>%2F2019%2F06%2F29%2Fgit%2Fgit-usage%2F</url>
    <content type="text"><![CDATA[githubProGit 常用术语 VCS: Version Control System 版本控制系统 DVCS: Distributed Version Control System 分布式版本控制系统 CVCS: Centralized Version Control System 中心式版本控制系统 源码安装安装依赖 123yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel asciidoc xmlto docbook2xatp-get install libcurl4-gnutls-dev libexpat1-dev gettext libz-dev libssl-dev asciidoc xmlto docbook2x 编码编译安装 1234567wget https://github.com/git/git/archive/v2.22.0.tar.gztar xvf v2.22.0.tar.gzcd git-2.22.0make configure./configure --prefix=/usrmake all doc infomake install install-doc install-html install-info Git内部原理Git命令高层命令git diffgit commitgit log底层命令git最核心部分是一个key-value的数据库。 hash-object命令cat-object命令update-index命令ls-files命令]]></content>
      <categories>
        <category>tool</category>
        <category>git</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[groovy闭包]]></title>
    <url>%2F2019%2F06%2F13%2Fgroovy%2Fgroovy-closure%2F</url>
    <content type="text"><![CDATA[闭包定义在计算机科学中，闭包（英语：Closure），又称词法闭包（Lexical Closure）或函数闭包（function closures），是引用了自由变量的函数。这个被引用的自由变量将和这个函数一同存在，即使已经离开了创造它的环境也不例外。所以，有另一种说法认为闭包是由函数和与其相关的引用环境组合而成的实体。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。 彼得·兰丁在1964年将术语“闭包”定义为一种包含环境成分和控制成分的实体。用来指代某些其开放绑定（自由变量）已经由其语法环境完成闭合（或者绑定）的lambda表达式，从而形成了闭合的表达式，或称闭包。 闭包只是在形式和表现上像函数，但实际上不是函数。函数是一些可执行的代码，这些代码在函数被定义后就确定了，不会在执行时发生变化，所以一个函数只有一个实例。闭包在运行时可以有多个实例，不同的引用环境和相同的函数组合可以产生不同的实例。所谓引用环境是指在程序执行中的某个点所有处于活跃状态的约束所组成的集合。其中的约束是指一个变量的名字和其所代表的对象之间的联系。 在函数定义时捕获当时的引用环境，并与函数代码组合成一个整体。当把这个整体当作函数调用时，先把其中的引用环境覆盖到当前的引用环境上，然后执行具体代码，并在调用结束后恢复原来的引用环境。这样就保证了函数定义和执行时的引用环境是相同的。这种由引用环境与函数代码组成的实体就是闭包。 自由变量是指除局部变量以外的变量。 Groovy闭包定义Groovy中的闭包是一个开放的、匿名代码块，它可以接收参数，定义返回值，也可以将闭包复制给变量，闭包还可以引用定义在其周围范围(in its surrounding scope)中的变量。与闭包的正式定义相反，Groovy语言中的闭包还可以包含定义在其周围范围之外(outside of its surrounding scope)的自由变量。 Groovy闭包语法1234567891011121314151617181920212223242526272829303132333435363738&#123; [closureParameters -&gt;] statements&#125;// examples&#123; item++ &#125; // 引用变量item// 默认参数it// 如果闭包执行时未指定参数，则it为null，类型class org.codehaus.groovy.runtime.NullObject&#123; println it&#125;//显示指定参数&#123;name -&gt; println name&#125;//指定多个具有类型的参数def body = &#123;String name, int age -&gt; println "name: $&#123;name&#125;, age:$&#123;age&#125;"&#125;//闭包是groovy.lang.Closure类型的实例assert body instanceof Closure//参数可以指定默认值def sum = &#123; int a, int b=2 -&gt; a+b &#125;//可以指定闭包的返回值类型Closure&lt;Boolean&gt; isTextFile = &#123; File it -&gt; it.name.endsWith('.txt')&#125;//如果要明确指定闭包不包含参数，需要显示的指定空参数列表def magicNumber = &#123; -&gt; 42 &#125;// this call will fail because the closure doesn't accept any argumentmagicNumber(11)//闭包的可以指定最后一个参数的长度是可变的或定义为数组def concat1 = &#123;String... args -&gt; args.join('')&#125;assert concat1('abc', 'def') == 'abcdef'def concat2 = &#123;String[] args -&gt; args.join('')&#125;assert concat2('aaa', 'bbb') == 'aaabbb'//闭包的执行也可以使用call()def multiConcat = &#123;int n, String... args -&gt; args.join('')*n&#125;assert multiConcat.call(3, 'ab', 'cd') == 'abcdabcdabcd' closureParameters是可选的逗号分隔的参数列表，参数可以指定类型(typed)也可不指定类型(untyped)。如果指定了参数，参数后面必须有 -&gt;，用于分割参数和闭包内语句。 闭包执行时，总是会有返回值。 Groovy闭包委托策略(Delegation strategy)委托(Delegation)是Groovy闭包中的一个关键特性(key concept)，闭包委托策略的可修改使得在Groovy中设计漂亮的领域特定语言(dsl, domain specific language)成为可能。 this、owner、delegate闭包内有三个内置对象: this 对应于定义闭包的封闭类(the enclosing class where the closure is defined),可以在闭包内通过getThisObject()获取 owner 对应于定义闭包的封闭对象(the enclosing object where the closure is defined)，可以是类也可以是闭包，可以在闭包内通过getOwner()获取 delegate 对应于一个第三方对象(where methods calls or properties are resolved whenever the receiver of the message is not defined)，可以在闭包内通过(getDelegate())获取 通过这三个内置对象，闭包可以调用对应对象的属性和方法。 this对应于定义闭包的封闭类12345678910111213141516171819202122// 在TestThis类中定义闭包body，并返回闭包的this对象class TestThis&#123; void run() &#123; def body = &#123;getThisObject()&#125; // 调用闭包会返回TestThis类的实例 assert body() == this // 在闭包中直接使用this对象与调用getThisObject等价 def body2 = &#123; this &#125; assert body2 == this &#125;&#125;class ClosureTest &#123; static void main(String... args) &#123; def body = &#123; this &#125; println body() == this // true println this // class ClosureTest println(this.getClass().toString()) // class java.lang.Class println(body.getClass().toString()) // class ClosureTest$_main_closure1 println body instanceof Closure // true &#125;&#125; 如果闭包在内部类中定义，那么闭包中的 this 对象返回的是内部类的实例对象1234567891011121314151617class ClosureTest &#123; class InnerClass &#123; def body = &#123; this &#125; &#125; void run()&#123; InnerClass inner = new InnerClass() println inner == inner.body() // true println this == inner.body() // false println this.getClass().toString() // class ClosureTest println inner.getClass().toString() // class ClosureTest$InnerClass println inner.body.getClass().toString() // class ClosureTest$InnerClass$_closure1 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 如果闭包A嵌入在类的某个闭包B中时，闭包A中的 this 表示的仍然是类的实例对象12345678910111213141516class ClosureTest &#123; void run()&#123; def body_b = &#123; def body_a = &#123; this &#125; body_a() &#125; println body_b() // ClosureTest@25748410 println this // ClosureTest@25748410 println body_b() == this // true println this.getClass().toString() // class ClosureTest &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; owner返回闭包定义所在的封闭对象，可以是类也可以是闭包。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 普通类class ClosureTest &#123; void run()&#123; def body_b = &#123; owner &#125; println body_b() // ClosureTest@55b5f5d2 println body_b // ClosureTest$_run_closure1@5bfa8cc5 println this // ClosureTest@55b5f5d2 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125;// 内部类class ClosureTest &#123; class InnerClass &#123; def body = &#123; owner &#125; &#125; void run() &#123; def inner = new InnerClass() println inner // ClosureTest$InnerClass@553f1d75 println inner.body() // ClosureTest$InnerClass@553f1d75 println this // ClosureTest@47404bea &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125;// 嵌套闭包class ClosureTest &#123; void run()&#123; def body_b = &#123; def body_a = &#123; owner &#125; println body_a // ClosureTest$_run_closure1$_closure2@5bfa8cc5 println body_a() // ClosureTest$_run_closure1@16ecee1 body_a() &#125; println body_b() // ClosureTest$_run_closure1@16ecee1 println body_b // ClosureTest$_run_closure1@16ecee1 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; delegate委托是Groovy语言能够构建DSL的关键特性(It is a powerful concept for building domain specific languages in groovy)。delegate是一个用户自定义的对象。 默认情况下， delegate 等同于 owner123456789101112131415161718192021222324252627class ClosureTest &#123; class InnerClass &#123; def body = &#123; delegate &#125; &#125; void run() &#123; def inner = new InnerClass() println inner // ClosureTest$InnerClass@4f071df8 println inner.body() // ClosureTest$InnerClass@4f071df8 println this // ClosureTest@29e6eb25 def body_b = &#123; def body_a = &#123; delegate &#125; body_a() &#125; println body_b() // ClosureTest$_run$_closure1@38be305c println body_b // ClosureTest$_run$_closure1@38be305c def body_c = &#123; delegate &#125; println body_c() // ClosureTest@29e6eb25 println body_c // ClosureTest$_run$_closure2@5ed731d0 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 闭包中的delegate属性可以被修改为任何对象123456789101112131415161718192021222324252627282930class ClosureTest &#123; class Person &#123; String name &#125; class Animal &#123; String name &#125; void run() &#123; def p = new Person(name: 'john') def a = new Animal(name: 'panda') def nameToUpper = &#123; delegate.name.toUpperCase() &#125; nameToUpper.delegate = p println nameToUpper() // JOHN nameToUpper.delegate = a println nameToUpper() // PANDA println p.name // john println a.name // panda // nameToUpper_use_var引用外部的局部变量p，能够达成和前面使用delegate一样的效果 // 但是委托可以透明的使用，即在闭包中不再显式的采用 delegate. 前缀引用属性或方法，详情见下节委托策略 def nameToUpper_use_var = &#123; p.name.toUpperCase() &#125; println nameToUpper_use_var() // JOHN &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 闭包委托策略在闭包中，如果访问闭包内部未定义的属性或方法时，会涉及到委托策略，委托策略分为下面几种: Closure.OWNER_FIRST: 默认策略。优先在owner中查找，如果没有找到则在delegate中查找 Closure.DELEGATE_FIRST: 优先在delegate中查找, 如果没有找到则在owner中查找 Closure.OWNER_ONLY: 忽略delegate，只在owner中查找 Closure.DELEGATE_ONLY: 忽略owner, 只在delegate中查找 Closure.TO_SELF: 只有在实现自己的闭包子类时才有意义。在需要高级元编程(meta-programming)技术，希望实现自定义的解析策略: 属性或方法的解析既不使用owner也不使用delegate，only on the closure class itself. DELEGATE_FIRST 与 OWNER_FIRST1234567891011121314151617181920212223242526272829303132333435class ClosureTest &#123; class Person &#123; String name def output = &#123; "My name is $&#123;name&#125;" &#125; String outputstring() &#123; output() &#125; &#125; class Animal &#123; String name &#125; void run() &#123; def p = new Person(name: 'john') def a = new Animal(name: 'panda') println p.output.owner // ClosureTest$Person@3234f74a println p.output.delegate // ClosureTest$Person@3234f74a // 默认委托策略为owner_first所以从p中查找name属性 println p.outputstring() // My name is john p.output.delegate = a println p.output.owner // ClosureTest$Person@3234f74a println p.output.delegate // ClosureTest$Animal@65aa6596 // 只修改了delegate属性，但策略没变，仍然从p中查找name属性 println p.outputstring() // My name is john // 修改委托策略为delegate_first p.output.resolveStrategy = Closure.DELEGATE_FIRST // 从a中查找name属性 println p.outputstring() // My name is panda &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; DELEGATE_FIRST 与 DELEGATE_OWNER123456789101112131415161718192021222324252627282930313233class ClosureTest &#123; class Person &#123; String name int age def output = &#123; "$&#123;name&#125; age is $&#123;age&#125;" &#125; String outputstring() &#123; output() &#125; &#125; class Animal &#123; String name &#125; void run() &#123; def p = new Person(name: 'john', age: 18) def a = new Animal(name: 'panda') println p.outputstring() // john age is 18 p.output.delegate = a println p.outputstring() // john age is 18 p.output.resolveStrategy = Closure.DELEGATE_ONLY p.output.delegate = p println p.outputstring() // john age is 18 p.output.delegate = a // exception: // groovy.lang.MissingPropertyException: No such property: age for class: ClosureTest println p.outputstring() &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 闭包委托策略具有传递性闭包A内嵌与闭包B时，如果闭包A中的某个属性在闭包B中没有解析到会继续向闭包B的owner或delegate中查找。具体是向闭包的B的owner还是delegate中查找，由闭包B的委托策略决定 12345678910111213141516171819202122232425262728293031323334class ClosureTest &#123; class Person &#123; String name int age def outerClosure = &#123; // outerClosure为innerClosure的owner def name = "outer_$&#123;name&#125;" def innerClosure = &#123; // innerClosure闭包中的name和age属性都不在闭包内定义 // 默认从innerClosure.owner中查找 // outerClousre.name // p.age "$&#123;name&#125;'s age is $&#123;age&#125;" &#125; println innerClosure.owner // ClosureTest$Person$_closure1@26a4842b println innerClosure.delegate == innerClosure.owner // ture innerClosure() &#125; &#125; void run() &#123; def p = new Person(name: 'john', age: 18) println p // ClosureTest$Person@5ed731d0 // p.outerClosure的owner为 p println p.outerClosure // ClosureTest$Person$_closure1@26a4842b println p.outerClosure.delegate == p // true println p.outerClosure.owner == p // true println p.outerClosure() // outer_john's age is 18 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 1234567891011121314151617181920212223242526class ClosureTest &#123; class Person &#123; String name int age def outerClosure = &#123; def name = "outer_$&#123;name&#125;" def innerClosure = &#123; "$&#123;name&#125;'s age is $&#123;age&#125;" &#125; innerClosure() &#125; &#125; void run() &#123; def p = new Person(name: 'john', age: 18) def p2 = new Person(name: 'jessica', age: 3) println p.outerClosure() // outer_john's age is 18 p.outerClosure.resolveStrategy = Closure.DELEGATE_FIRST p.outerClosure.delegate = p2 println p.outerClosure() // outer_jessica's age is 3 &#125; static void main(String... args) &#123; new ClosureTest().run() &#125;&#125; 闭包策略在Jenkins pipeline中的典型应用12345678910111213141516171819// vars/abc.groovydef call(body) &#123; def config = [:] // 修改body闭包的委托策略和delegate属性 body.resolveStrategy = Closure.DELEGATE_FIRST body.delegate = config // 闭包执行时，闭包中读取未定义的属性时都会从config中获取 // 闭包中设置未定义的属性时都也会设置到config中 body() // 后续就可以通过config.branch访问Jenkinsfile中定义并传给abc.groovy的值 println config // [branch: 'master']&#125;// Jenkinsfileabc &#123; // 通常设置某些属性值，可以实现传参效果 branch = 'master'&#125; 参考资料维基百科-闭包 闭包的概念、形式与应用 (IBM DeveloperWorks) Groovy-Closure]]></content>
      <categories>
        <category>language</category>
        <category>groovy</category>
      </categories>
      <tags>
        <tag>groovy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[groovy使用总结]]></title>
    <url>%2F2019%2F06%2F13%2Fgroovy%2Fgroovy-usage%2F</url>
    <content type="text"><![CDATA[Apache Groovy基于Java平台的一种功能强大、可选类型的动态语言。它的目的在于通过简洁、熟悉和易于学习的语法来提升开发人员的效率。Groovy代码动态地编译成运行于Java虚拟机（JVM）上的Java字节码，并可以与其他Java代码和库进行互操作。由于其运行在JVM上的特性，Groovy可以使用其他Java语言编写的库。 官网文档 闭包grape依赖管理动态替换yaml文件中的变量]]></content>
      <categories>
        <category>language</category>
        <category>groovy</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>groovy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[etcd_introduce]]></title>
    <url>%2F2019%2F06%2F02%2Fetcd%2Fetcd-introduce%2F</url>
    <content type="text"><![CDATA[官网github 简介etcd官方定义为一个分布式的可信的键值存储服务，用于存储分布式系统中的一些关键数据。其主要特性包括: Simple 简单: 包含一套定义良好、面向用户的API(gRpc) Secure 安全: 支持可选择客户端证书认证的TLS Fast 快速: 基准测试可达10,000写每秒 Reliable 可靠: properly distributed using Raft etcd是使用Go语言编写，采用Raft共识算法管理高可用的replicated log。 安装 最简单的方式是在github的release中下载预编译(pre-built)好的二进制 源码安装a) etcd源码安装时对go版本通常都有要求，请参照github中说明b) 为了确保etcd编译正确，etcd提供了官方release版本的依赖。当然是否使用官方提供的依赖是可选的。 部署预置条件]]></content>
      <categories>
        <category>DB</category>
        <category>etcd</category>
      </categories>
      <tags>
        <tag>etcd</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAVEN POM]]></title>
    <url>%2F2019%2F06%2F01%2Fmaven%2Fmaven-pom%2F</url>
    <content type="text"><![CDATA[Maven的超级POM(Project Object Model)位于${M2_HOME}/lib/maven-model-builder-xxx.jar构件中org.apache.maven.model.pom-4.0.0.xml其中包含了Maven用于构建项目有关的项目信息以及配置细节，它包含了大多数项目的默认值。超级POM是Maven的默认POM，除非显式设置(POM中的&lt;parent>配置)，否则所有的POM都会扩展超级POM，也就是说项目POM默认都会继承超级POM中的配置。 POM最小内容123456&lt;project&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;com.mycompany.app&lt;/groupId&gt; &lt;artifactId&gt;my-app&lt;/artifactId&gt; &lt;version&gt;1&lt;/version&gt;&lt;/project&gt; modelVersion内容要设置为4.0.0。groupId、artifactId和version三个元素定义了项目的坐标。 ### Super POM(3.6.1)内容123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!-- START SNIPPET: superpom --&gt;&lt;project&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;repositories&gt; &lt;repository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Maven Repository Switchboard&lt;/name&gt; &lt;url&gt;http://repo1.maven.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;/repository&gt; &lt;/repositories&gt; &lt;pluginRepositories&gt; &lt;pluginRepository&gt; &lt;id&gt;central&lt;/id&gt; &lt;name&gt;Maven Plugin Repository&lt;/name&gt; &lt;url&gt;http://repo1.maven.org/maven2&lt;/url&gt; &lt;layout&gt;default&lt;/layout&gt; &lt;snapshots&gt; &lt;enabled&gt;false&lt;/enabled&gt; &lt;/snapshots&gt; &lt;releases&gt; &lt;updatePolicy&gt;never&lt;/updatePolicy&gt; &lt;/releases&gt; &lt;/pluginRepository&gt; &lt;/pluginRepositories&gt; &lt;build&gt; &lt;directory&gt;$&#123;project.basedir&#125;/target&lt;/directory&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/classes&lt;/outputDirectory&gt; &lt;finalName&gt;$&#123;project.artifactId&#125;-$&#123;project.version&#125;&lt;/finalName&gt; &lt;testOutputDirectory&gt;$&#123;project.build.directory&#125;/test-classes&lt;/testOutputDirectory&gt; &lt;sourceDirectory&gt;$&#123;project.basedir&#125;/src/main/java&lt;/sourceDirectory&gt; &lt;scriptSourceDirectory&gt;src/main/scripts&lt;/scriptSourceDirectory&gt; &lt;testSourceDirectory&gt;$&#123;project.basedir&#125;/src/test/java&lt;/testSourceDirectory&gt; &lt;resources&gt; &lt;resource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/main/resources&lt;/directory&gt; &lt;/resource&gt; &lt;/resources&gt; &lt;testResources&gt; &lt;testResource&gt; &lt;directory&gt;$&#123;project.basedir&#125;/src/test/resources&lt;/directory&gt; &lt;/testResource&gt; &lt;/testResources&gt; &lt;pluginManagement&gt; &lt;!-- NOTE: These plugins will be removed from future versions of the super POM --&gt; &lt;!-- They are kept for the moment as they are very unlikely to conflict with lifecycle mappings (MNG-4453) --&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-antrun-plugin&lt;/artifactId&gt; &lt;version&gt;1.3&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt; &lt;version&gt;2.2-beta-5&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt; &lt;version&gt;2.1&lt;/version&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-release-plugin&lt;/artifactId&gt; &lt;version&gt;2.0&lt;/version&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/pluginManagement&gt; &lt;/build&gt; &lt;reporting&gt; &lt;outputDirectory&gt;$&#123;project.build.directory&#125;/site&lt;/outputDirectory&gt; &lt;/reporting&gt; &lt;profiles&gt; &lt;!-- NOTE: The release profile will be removed from future versions of the super POM --&gt; &lt;profile&gt; &lt;id&gt;release-profile&lt;/id&gt; &lt;activation&gt; &lt;property&gt; &lt;name&gt;performRelease&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;/activation&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-javadocs&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;inherited&gt;true&lt;/inherited&gt; &lt;artifactId&gt;maven-deploy-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;updateReleaseInfo&gt;true&lt;/updateReleaseInfo&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; &lt;/profile&gt; &lt;/profiles&gt;&lt;/project&gt;&lt;!-- END SNIPPET: superpom --&gt;]]></content>
      <categories>
        <category>tool</category>
        <category>构建工具</category>
        <category>maven</category>
      </categories>
      <tags>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pipeline并行任务配置]]></title>
    <url>%2F2019%2F05%2F30%2Fjenkins%2Fjenkins-pipeline-parallel%2F</url>
    <content type="text"><![CDATA[静态并行任务配置声明式 在stage中可以通过parallel块来嵌套多个stage实现并行运行 parallel块中的stage除了不能再次嵌套parallel外和普通stage一样，也可以通过stages包含一些列顺序执行的stage 每个stage中有且只能有一个steps、stages或者parallel 所有包含parallel的stage都不能包含agent和tools EXAMPLE-1 stage级别并行123456789101112131415161718192021222324252627282930313233pipeline &#123; agent any options &#123; timestamps() &#125; stages &#123; stage(&apos;init&apos;) &#123; steps &#123; echo &quot;init start&quot; sleep 5 echo &apos;init end&apos; &#125; &#125; stage(&apos;build&apos;) &#123; parallel &#123; stage(&apos;x86 build&apos;) &#123; steps &#123; echo &apos;x86 build start&apos; sleep 5 echo &apos;x86 build end&apos; &#125; &#125; stage(&apos;arm build&apos;) &#123; steps &#123; echo &apos;arm build start&apos; sleep 3 echo &apos;arm build end&apos; &#125; &#125; &#125; &#125; &#125;&#125; blueOcean如下图所示 EXAMPLE-2 并行stage中多个stage串行1234567891011121314151617181920212223242526272829303132333435363738394041424344454647pipeline &#123; agent any options &#123; timestamps() &#125; stages &#123; stage(&apos;init&apos;) &#123; steps &#123; echo &quot;init start&quot; sleep 5 echo &apos;init end&apos; &#125; &#125; stage(&apos;build&apos;) &#123; parallel &#123; stage(&apos;x86 build&apos;) &#123; agent &#123; label &apos;master&apos; &#125; steps &#123; echo &apos;x86 build start&apos; sleep 5 echo &apos;x86 build end&apos; &#125; &#125; stage(&apos;arm build&apos;) &#123; stages &#123; stage(&apos;arm-master build&apos;) &#123; steps &#123; echo &apos;arm master build start&apos; sleep 3 echo &apos;arm master build end&apos; &#125; &#125; stage(&apos;arm develop build&apos;) &#123; steps &#123; echo &apos;arm develop build start&apos; sleep 3 echo &apos;arm develop build end&apos; &#125; &#125; &#125; &#125; &#125; &#125; &#125;&#125; blueOcean如下图所示 EXAMPLE-4 step级别并行12345678910111213141516171819202122232425262728pipeline &#123; agent any options &#123; timestamps() &#125; stages &#123; stage(&apos;init&apos;) &#123; steps &#123; echo &quot;init start&quot; sleep 5 echo &apos;init end&apos; &#125; &#125; stage(&apos;build&apos;) &#123; steps &#123; parallel &apos;x86 build&apos;: &#123; echo &apos;x86 build start&apos; sleep 3 echo &apos;x86 build end&apos; &#125;, &apos;arm build&apos;: &#123; echo &apos;arm build start&apos; sleep 3 echo &apos;arm build end&apos; &#125; &#125; &#125; &#125;&#125; blueOcean如下图所示 脚本式EXAMPLE-312345678910111213141516171819202122232425script &#123; node(&apos;master&apos;) &#123; stage(&apos;init&apos;) &#123; echo &apos;init&apos; &#125; stage(&apos;build&apos;) &#123; parallel &apos;build x86&apos;: &#123; stage(&apos;build x86 step1&apos;) &#123; echo &apos;build x86 step1 start&apos; sleep 5 echo &apos;build x86 step1 end&apos; &#125; stage(&apos;build x86 step2&apos;) &#123; echo &apos;build x86 step 2 start&apos; sleep 5 echo &apos;build x86 step 2 end&apos; &#125; &#125;, &apos;build arm&apos;: &#123; echo &apos;build arm start&apos; sleep 6 echo &apos;build arm end&apos; &#125; &#125; &#125;&#125; blueOcean如下图所示 动态创建并行任务EXAMPLE-51234567891011121314151617181920212223242526272829303132333435363738def jobs = [&apos;jobA&apos;, &apos;jobB&apos;, &apos;jobC&apos;]def parallelStagesMap = jobs.collectEntries &#123; def jobName -&gt; [&quot;$&#123;jobName&#125;&quot;, generateJobStage(jobName)]&#125;def generateJobStage(String jobName) &#123; return &#123; node(&apos;master&apos;) &#123; stage(&quot;stage: $&#123;jobName&#125;&quot;) &#123; echo &quot;$&#123;jobName&#125; start&quot; sleep 5 echo &quot;job end&quot; &#125; &#125; &#125;&#125;pipeline &#123; agent any options &#123; timestamps() &#125; stages &#123; stage(&apos;non-parallel stage&apos;) &#123; steps &#123; echo &apos;this is non-parallel stage&apos; &#125; &#125; stage(&apos;parallel stage&apos;) &#123; steps &#123; script &#123; parallel parallelStagesMap &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>tool</category>
        <category>持续集成</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[maven 使用总结]]></title>
    <url>%2F2019%2F05%2F23%2Fmaven%2Fmaven-usage%2F</url>
    <content type="text"><![CDATA[maven官方文档易百教程maven库查询 安装下载二进制包后解压即可，然后配置环境变量 12echo 'export M2_HOME=/usr/local/apache_maven_xxx' &gt;&gt; /etc/profileecho 'export PATH=$M2_HOME/bin:$PATH' &gt;&gt; /etc/profile 执行mvn -v查看版本，同时确认是否安装配置OK 配置超级POM配置文件maven的配置文件有三个级别 项目级，位于项目workspace目录下的pom.xml 用户级，位于~/.m2/settings.xml，通过mvn -s /path/to/settings.xml可以覆盖用户级配置文件 全局级，位于${M2_HOME}/conf/settings.xml，通过mvn -gs /path/to/settings.xml可以覆盖全局配置文件 配置项目 标签 类型 说明 localRepository String 本地仓库路径，默认位于~/.m2/repository mirrors List&lt;mirror> 配置仓库的下载镜像 mirrorOf配置 * = everything external:* = everything not on the localhost and not file based. repo,repo1 = repo or repo1 *,!repo1 = everything except repo1 镜像设置阿里镜像公共代理库使用文档 12345678&lt;mirrors&gt; &lt;mirror&gt; &lt;id&gt;alimavenpublic&lt;/id&gt; &lt;name&gt;aliyun maven public&lt;/name&gt; &lt;url&gt;http://maven.aliyun.com/repository/public&lt;/url&gt; &lt;mirrorOf&gt;central,jcenter&lt;/mirrorOf&gt; &lt;/mirror&gt;&lt;/mirrors&gt; 华为镜像12345&lt;mirror&gt; &lt;id&gt;huaweicloud&lt;/id&gt; &lt;mirrorOf&gt;*&lt;/mirrorOf&gt; &lt;url&gt;https://mirrors.huaweicloud.com/repository/maven/&lt;/url&gt;&lt;/mirror&gt; Maven仓库对于Maven来说，仓库只有两类: 本地仓库和远程仓库。当Maven根据坐标寻找构件时，首先查找本地仓库，如果本地仓库存在此构件，则直接使用；如果本地仓库没有此构件，或需要查看构件是否有更新，Maven会去远程仓库查找，找到后下载到本地仓库再使用，如果没有找到则报错。 对于远程仓库，根据仓库的提供者又可以分为: 中央仓库、其他公开库和私服中央仓库是Maven自带的远程仓库，它包含了绝大部分开源的构件。默认情况下，当本地仓库没有找到需要的构件时，Maven会尝试从中央仓库下载。 Maven常用命令Help命令查看某个插件的详情1mvn help:describe -Dplugin=xxx -Ddetail plugin可以使用下面三种方式指定: 插件前缀, 如 ‘help’ groupId:artifactId, 如 ‘org.apache.maven.plugins:maven-help-plugin’ groupId:artifactId:version, 如 ‘org.apache.maven.plugins:maven-help-plugin:2.0’ 查看某个插件的指定命令的帮助1mvn archetype:help -Ddetail -Dgoal=generate 使用archetype创建Maven项目12mvn archetype:generatemvn -U archetype:generate -Dfilter=io.jenkins.archetypes:]]></content>
      <categories>
        <category>tool</category>
        <category>构建工具</category>
        <category>maven</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vm_network]]></title>
    <url>%2F2019%2F05%2F16%2Fvm-network%2F</url>
    <content type="text"><![CDATA[TODO1TODO2]]></content>
  </entry>
  <entry>
    <title><![CDATA[centos使用总结]]></title>
    <url>%2F2019%2F05%2F15%2Fcentos%2Fcentos-usage%2F</url>
    <content type="text"><![CDATA[最小化安装IP配置修改 /etc/sysconfig/network-scripts/ifcfg-xxx 文件 123456789TYPE=EthernetBOOTPROTO=static #网卡引导方式 static/DHCPONBOOT=yes #网卡开机启动IPADDR=192.168.0.150NETMASK=255.255.255.0GATEWAY=192.168.0.1HWADDR=xx:xx:xx:xx:xx:xxDNS1=x.x.x.xDNS2=x.x.x.x 然后重启网络服务 systemctl restart network 配置国内镜像源12345cat /etc/centos-releasemv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.bakwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repoyum clean allyum makecache epel扩展源yum源优先级yum命令搜索命令属于哪些包 yum search xxx yum provides xxx yum list 命令 描述 yum list [all] 所有已安装和可以安装的包 yum list available 所有可以安装的包 yum list installed 所有已经安装的包 yum list updates 所有可以升级的包 yum list extra 所有已经安装但不在repository的包 查看软件包详情 yum info wget 查看软件包依赖 yum deplist wget 工具安装与配置openjdk安装通过yum工具安装的位置为 /usr/lib/jvm/java-xxx 123yum install java-11-openjdk-devel.x86_64echo "export JAVA_HOME=/usr/lib/jvm/java-11-openjdk" &gt;&gt; /etc/profileecho 'export PATH=$JAVA_HOME/bin:$PATH' &gt;&gt; /etc/profile docker安装]]></content>
      <categories>
        <category>linux</category>
        <category>centos</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[makefile使用总结]]></title>
    <url>%2F2019%2F05%2F14%2Fmakefile-usage%2F</url>
    <content type="text"><![CDATA[常用链接跟我一起写Makefile重制版GUN Make手册 makefile中添加打印信息1234warn_msg="warning..."$(info "infomation output")$(warning "warn: $(warn_msg)")$(error "error message") 常用参数 -n, --just-print 打印make过程中执行的所有命令但是并不会真正执行 --print-data-base make过程中会显示GNU信息、执行的命令以及make的内部数据库。数据库里面的数据分为以下几类1) variables 会列出每个变量及描述性注释2) directories 列出了将会被make检查的目录3) implicit rules 包含了所有内置和用户自定义的模式规则4) pattern-specific variables 定义在makefile中的模式专属变量5) files(explicit rules) 与特定文件有关的自定义和后缀规则6) vpath search paths]]></content>
      <categories>
        <category>tool</category>
        <category>构建工具</category>
        <category>makefile</category>
      </categories>
      <tags>
        <tag>make</tag>
        <tag>makefile</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lvm使用]]></title>
    <url>%2F2019%2F05%2F13%2Flinux%2Flvm%2F</url>
    <content type="text"><![CDATA[LVM(Logic Volume Manager)逻辑卷管理，它是linux环境下对磁盘分区进行管理的一种机制。 TODO 基本术语 PV: Physical Volume 物理卷 VG: Volume Group 卷组，由一个或多个PV组成。可以在其上创建一个或多个LV LV: Logical Volume 逻辑卷，在其上可以创建文件系统 PE: Physical Extent 物理扩展盘区，每个PV都会被划分成PE，它是可以被LVM寻址的最小单元 LE: Logical Extent 逻辑扩展盘区， 基本原理1) 物理磁盘被格式化为PV，空间被划分为一个个PE2) 不同的PV加入到同一个VG中，其对应的所有PE都进入VG的PE池中3) LVM从PE池中选择PE创建LV，不同物理盘中的PE可能会划分到同一个LV中4) 在LV上创建文件系统后就可以挂载使用了5) 对LV的扩容和缩减其实就是相应的增加或减少PE数量 创建逻辑卷时，定义了逻辑扩展盘区与物理扩展盘区的映射关系。 创建流程创建分区12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[root@localhost ~]# fdisk /dev/sdbWelcome to fdisk (util-linux 2.23.2).Changes will remain in memory only, until you decide to write them.Be careful before using the write command.Command (m for help): nPartition type: p primary (0 primary, 0 extended, 4 free) e extendedSelect (default p): pPartition number (1-4, default 1): First sector (2048-2097151, default 2048): Using default value 2048Last sector, +sectors or +size&#123;K,M,G&#125; (2048-2097151, default 2097151): +300MPartition 1 of type Linux and of size 300 MiB is setCommand (m for help): pDisk /dev/sdb: 1073 MB, 1073741824 bytes, 2097152 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x233e2ebd Device Boot Start End Blocks Id System/dev/sdb1 2048 616447 307200 83 LinuxCommand (m for help): tSelected partition 1Hex code (type L to list all codes): 8eChanged type of partition 'Linux' to 'Linux LVM'Command (m for help): pDisk /dev/sdb: 1073 MB, 1073741824 bytes, 2097152 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytesDisk label type: dosDisk identifier: 0x233e2ebd Device Boot Start End Blocks Id System/dev/sdb1 2048 616447 307200 8e Linux LVMCommand (m for help): wThe partition table has been altered!Calling ioctl() to re-read partition table.Syncing disks. 创建pv12345678910111213141516[root@localhost ~]# pvcreate /dev/sdb1 Physical volume "/dev/sdb1" successfully created.[root@localhost ~]# pvs PV VG Fmt Attr PSize PFree /dev/sdb1 lvm2 --- 300.00m 300.00m[root@localhost ~]# pvdisplay /dev/sdb1 --- Physical volume --- PV Name /dev/sdb1 VG Name vg0 PV Size 300.00 MiB / not usable 4.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 74 Free PE 74 Allocated PE 0 PV UUID 8dqEi7-haMt-ciIM-ib2e-AUxp-f7ym-bCvlfw 创建vg1234567891011121314151617181920212223242526[root@localhost ~]# vgcreate vg0 /dev/sdb1 Volume group "vg0" successfully created[root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree vg0 1 0 0 wz--n- 296.00m 296.00m[root@localhost ~]# vgdisplay vg0 --- Volume group --- VG Name vg0 System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 1 VG Access read/write VG Status resizable MAX LV 0 Cur LV 0 Open LV 0 Max PV 0 Cur PV 1 Act PV 1 VG Size 296.00 MiB PE Size 4.00 MiB Total PE 74 Alloc PE / Size 0 / 0 #已分配的PE数量 Free PE / Size 74 / 296.00 MiB #剩余的PE数量 VG UUID 3FH6og-yXLt-NaL3-uehk-9lrJ-c4TD-r0z6Sa 创建lv12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@localhost ~]# lvcreate -L 100m -n lv0 vg0 Logical volume "lv0" created.[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv0 vg0 -wi-a----- 100.00m [root@localhost ~]# lvdisplay /dev/vg0/lv0 --- Logical volume --- LV Path /dev/vg0/lv0 LV Name lv0 VG Name vg0 LV UUID Plb1kl-JGcg-0UfR-W3Ue-tDBc-D5Tc-tj6X0n LV Write Access read/write LV Creation host, time localhost.localdomain, 2019-05-16 02:02:27 +0800 LV Status available # open 0 LV Size 100.00 MiB Current LE 25 Segments 1 Allocation inherit Read ahead sectors auto - currently set to 8192 Block device 253:2[root@localhost ~]# pvdisplay /dev/sdb1 --- Physical volume --- PV Name /dev/sdb1 VG Name vg0 PV Size 300.00 MiB / not usable 4.00 MiB Allocatable yes PE Size 4.00 MiB Total PE 74 Free PE 49 Allocated PE 25 # 可以看到已经有PE被分配出去了 PV UUID 8dqEi7-haMt-ciIM-ib2e-AUxp-f7ym-bCvlfw[root@localhost ~]# vgdisplay vg0 --- Volume group --- VG Name vg0 System ID Format lvm2 Metadata Areas 1 Metadata Sequence No 2 VG Access read/write VG Status resizable MAX LV 0 Cur LV 1 Open LV 0 Max PV 0 Cur PV 1 Act PV 1 VG Size 296.00 MiB PE Size 4.00 MiB Total PE 74 Alloc PE / Size 25 / 100.00 MiB # 可以看到已经有PE被分配出去了 Free PE / Size 49 / 196.00 MiB VG UUID 3FH6og-yXLt-NaL3-uehk-9lrJ-c4TD-r0z6Sa 创建LV时LV的大小有以下两种方式指定 通过-L参数，表示物理大小 通过-l参数，使用相关VG/LV或PV大小的百分比来指定 10%VG, 表示10%的VG总大小 20%FREE, 表示VG中剩余空间的20% 30%PVS, 表示PV集合中剩余空间的30% 该参数后面跟数值(非百分比)时，表示包含多少个PE大小。 12345678910111213[root@localhost ~]# lvremove /dev/vg0/lv0Do you really want to remove active logical volume vg0/lv0? [y/n]: y Logical volume "lv0" successfully removed[root@localhost ~]# lvcreate -l 30%VG -n lv1 vg0 Logical volume "lv1" created.[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-a----- 88.00m [root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree centos 1 2 0 wz--n- &lt;9.00g 0 vg0 1 1 0 wz--n- 296.00m 208.00m[root@localhost ~]# 格式化文件系统1234567891011121314151617181920212223242526272829303132333435[root@localhost ~]# mkfs.ext3 /dev/vg0/lv1mke2fs 1.42.9 (28-Dec-2013)Filesystem label=OS type: LinuxBlock size=1024 (log=0)Fragment size=1024 (log=0)Stride=0 blocks, Stripe width=0 blocks22528 inodes, 90112 blocks4505 blocks (5.00%) reserved for the super userFirst data block=1Maximum filesystem blocks=6737100811 block groups8192 blocks per group, 8192 fragments per group2048 inodes per groupSuperblock backups stored on blocks: 8193, 24577, 40961, 57345, 73729Allocating group tables: done Writing inode tables: done Creating journal (4096 blocks): doneWriting superblocks and filesystem accounting information: done [root@localhost ~]# fdisk -l /dev/vg0/lv1 Disk /dev/vg0/lv1: 92 MB, 92274688 bytes, 180224 sectorsUnits = sectors of 1 * 512 = 512 bytesSector size (logical/physical): 512 bytes / 512 bytesI/O size (minimum/optimal): 512 bytes / 512 bytes[root@localhost ~]# mkdir /usr1[root@localhost ~]# mount /dev/vg0/lv1 /usr1[root@localhost ~]# df -haFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg0-lv1 82M 1.6M 76M 2% /usr1[root@localhost ~]# 扩容扩容LV1234567891011121314151617181920[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-ao---- 88.00m [root@localhost ~]# lvextend -L +100m /dev/vg0/lv1 Size of logical volume vg0/lv1 changed from 88.00 MiB (22 extents) to 188.00 MiB (47 extents). Logical volume vg0/lv1 successfully resized.[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-ao---- 188.00m [root@localhost ~]# df -haFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg0-lv1 82M 1.6M 76M 2% /usr1 # LV已经扩容但是文件系统大小还时原来大小[root@localhost ~]# resize2fs /dev/vg0/lv1 resize2fs 1.42.9 (28-Dec-2013)Filesystem at /dev/vg0/lv1 is mounted on /usr1; on-line resizing requiredold_desc_blocks = 1, new_desc_blocks = 1The filesystem on /dev/vg0/lv1 is now 192512 blocks long.[root@localhost ~]# df -haFilesystem Size Used Avail Use% Mounted on/dev/mapper/vg0-lv1 178M 1.6M 169M 1% /usr1 # 已经扩容 12345678910111213141516[root@localhost ~]# lvs |grep lv1 lv1 vg0 -wi-ao---- 188.00m [root@localhost ~]# lvextend -l +50%FREE /dev/vg0/lv1 Size of logical volume vg0/lv1 changed from 188.00 MiB (47 extents) to 244.00 MiB (61 extents). Logical volume vg0/lv1 successfully resized.[root@localhost ~]# lvs |grep lv1 lv1 vg0 -wi-ao---- 244.00m [root@localhost ~]# df -ha |grep lv1/dev/mapper/vg0-lv1 178M 1.6M 169M 1% /usr1[root@localhost ~]# resize2fs /dev/mapper/vg0-lv1 resize2fs 1.42.9 (28-Dec-2013)Filesystem at /dev/mapper/vg0-lv1 is mounted on /usr1; on-line resizing requiredold_desc_blocks = 1, new_desc_blocks = 1The filesystem on /dev/mapper/vg0-lv1 is now 249856 blocks long.[root@localhost ~]# df -ha |grep lv1/dev/mapper/vg0-lv1 233M 2.1M 220M 1% /usr1 lvextend 中 -L 和 -l 参数中如果没有使用 + 号，则表示扩容到指定大小 扩容VG当VG中没有空闲资源时需要先扩容VG才能扩容LV 123456789101112131415161718192021222324252627[root@localhost ~]# pvs PV VG Fmt Attr PSize PFree /dev/sdb1 vg0 lvm2 a-- 296.00m 52.00m[root@localhost ~]# pvcreate /dev/sdc1 Physical volume "/dev/sdc1" successfully created.[root@localhost ~]# pvs PV VG Fmt Attr PSize PFree /dev/sdb1 vg0 lvm2 a-- 296.00m 52.00m /dev/sdc1 lvm2 --- 511.00m 511.00m[root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree vg0 1 1 0 wz--n- 296.00m 52.00m[root@localhost ~]# vgextend vg0 /dev/sdc1 Volume group "vg0" successfully extended[root@localhost ~]# vgs VG #PV #LV #SN Attr VSize VFree vg0 2 1 0 wz--n- 804.00m 560.00m[root@localhost ~]# [root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-a----- 244.00m[root@localhost ~]# lvextend -l +100%FREE /dev/vg0/lv1 Size of logical volume vg0/lv1 changed from 244.00 MiB (61 extents) to 804.00 MiB (201 extents). Logical volume vg0/lv1 successfully resized.[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-a----- 804.00m 缩减容量 先umount设备 缩减文件系统大小 缩减LV大小 123456789101112131415161718192021222324252627282930313233[root@localhost ~]# umount -l /usr1[root@localhost ~]# resize2fs /dev/mapper/vg0-lv1 100Mresize2fs 1.42.9 (28-Dec-2013)Please run 'e2fsck -f /dev/mapper/vg0-lv1' first.[root@localhost ~]# e2fsck -f /dev/mapper/vg0-lv1 e2fsck 1.42.9 (28-Dec-2013)Pass 1: Checking inodes, blocks, and sizesPass 2: Checking directory structurePass 3: Checking directory connectivityPass 4: Checking reference countsPass 5: Checking group summary information/dev/mapper/vg0-lv1: 2369/206848 files (6.4% non-contiguous), 61211/823296 blocks[root@localhost ~]# [root@localhost ~]# resize2fs /dev/mapper/vg0-lv1 100Mresize2fs 1.42.9 (28-Dec-2013)Resizing the filesystem on /dev/mapper/vg0-lv1 to 102400 (1k) blocks.The filesystem on /dev/mapper/vg0-lv1 is now 102400 blocks long.[root@localhost ~]# lvreduce -L 100M /dev/mapper/vg0-lv1 WARNING: Reducing active logical volume to 100.00 MiB. THIS MAY DESTROY YOUR DATA (filesystem etc.)Do you really want to reduce vg0/lv1? [y/n]: y Size of logical volume vg0/lv1 changed from 804.00 MiB (201 extents) to 100.00 MiB (25 extents). Logical volume vg0/lv1 successfully resized.[root@localhost ~]# lvs LV VG Attr LSize Pool Origin Data% Meta% Move Log Cpy%Sync Convert lv1 vg0 -wi-a----- 100.00m [root@localhost /]# vgs VG #PV #LV #SN Attr VSize VFree vg0 2 1 0 wz--n- 804.00m 704.00m[root@localhost /]# pvs PV VG Fmt Attr PSize PFree /dev/sdb1 vg0 lvm2 a-- 296.00m 196.00m /dev/sdc1 vg0 lvm2 a-- 508.00m 508.00m 快照]]></content>
      <categories>
        <category>linux</category>
        <category>tool</category>
        <category>lvm</category>
      </categories>
      <tags>
        <tag>lvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jenkins使用总结]]></title>
    <url>%2F2019%2F05%2F13%2Fjenkins%2Fjenkins%2F</url>
    <content type="text"><![CDATA[常用链接 github pipeline steps reference pipeline scm step(checkout) apache groovy doc SAP shared lib repo Jenkins插件升级站点配置 https://updates.jenkins.io/update-center.json (默认) http://mirrors.huaweicloud.com/jenkins/updates/update-center.json groovy实现添加slave 官方wiki pipeline_demo_sharedlib pipeline_demo_jenkinsfile cloudbees_jenkins_script_sample 官方pipeline示例并行任务配置Jenkins pipeline控制并行执行job个数shared-libpipeline代码调试centos安装jenkinsJenkins中使用Grab下载第三方JarJenkins序列化Multijob不能调用pipeline任务升级Multijob插件到1.32及以上 admin密码丢失 初始密码: ${jenkins_home}/secrets/initialAdminPassword 修改过密码后忘记1) 将 ${jenkins_home}/config.xml 文件中以下内容修改为false 1&lt;useSecurity&gt;true&lt;/useSecurity&gt; 2) 重启jenkins服务3) 系统管理 -&gt; 全局安全配置 中 启用安全4) 系统管理 -&gt; 管理用户 中 重置密码 jenkins执行shell脚本时/etc/profile中环境变量不能访问获取pipeline中的Script Path1def scriptPath = currentBuild.rawBuild.parent.definition.scriptPath 获取pipeline中stage和并行task中的分段日志获取jenkins中安装的所有插件123456789Jenkins.instance.pluginManager.plugins.each &#123; println("$&#123;it.getDisplayName()&#125; --- $&#123;it.getVersion()&#125;")&#125;// 根据名称排序显示List&lt;String&gt; jenkinsPlugins = new ArrayList&lt;String&gt;(Jenkins.instance.pluginManager.plugins)jenkinsPlugins.sort &#123; it.displayName &#125;.each &#123; plugin -&gt; println("$&#123;plugin.shortName&#125;:$&#123;plugin.version&#125;")&#125; 脚本式pipeline中failFast使用清理Jenkins Master中的所有Job的历史记录]]></content>
      <categories>
        <category>tool</category>
        <category>持续集成</category>
        <category>jenkins</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>jenkins</tag>
        <tag>pipeline</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode使用总结]]></title>
    <url>%2F2019%2F05%2F13%2Fvscode-usage%2F</url>
    <content type="text"><![CDATA[vscode配置123456789101112131415&#123; "workbench.colorTheme": "One Dark Pro", "workbench.iconTheme": "vscode-icons", "editor.renderWhitespace": "all", "editor.renderControlCharacters": true, "window.zoomLevel": 0, "editor.fontSize": 16, "editor.formatOnSave": true, "C_Cpp.clang_format_fallbackStyle": "Google", "clang-format.fallbackStyle": "Google", "[c]": &#123; "editor.defaultFormatter": "xaver.clang-format" &#125;, "clang-format.executable": "C:\\Users\\xxx\\.vscode\\extensions\\ms-vscode.cpptools-0.26.0\\LLVM\\bin\\clang-format.exe",&#125; 快捷键 按键 说明 shift+alt+F 格式化 shift+ctl+b build ctrl+x 删除当前行 shift+alt+⬇ 拷贝当前行到下一行 shift+alt+⬆ 拷贝当前行到上一行 shift+ctl+k 删除当前行 alt+⬆ 移动当前行到上一行 alt+⬇ 移动当前行到下一行 vscode调试c/c++程序VS Code中更改C/C++代码格式样式clang-foramt格式化选项介绍]]></content>
      <categories>
        <category>tool</category>
        <category>vscode</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[npm使用总结]]></title>
    <url>%2F2019%2F05%2F13%2Fnpm-usage%2F</url>
    <content type="text"><![CDATA[npm使用淘宝镜像临时使用1npm --registry https://registry.npm.taobao.org 永久设置1npm config set registry https://registry.npm.taobao.org 该方式等同于在~/.npmrc文件中添加registry=https://registry.npm.taobao.org可以通过npm config get registry确认是否生效 使用cnpm1npm install cnpm -g --registry https://registry.npm.taobao.org cnpm和npm用法完全一致，只是在执行命令时将npm改为cnpm]]></content>
      <categories>
        <category>tool</category>
        <category>npm</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>npm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo搭建blog]]></title>
    <url>%2F2019%2F05%2F12%2Fhexo-blog%2F</url>
    <content type="text"><![CDATA[Hexo是一个快速、简洁且高效的博客框架。具体内容请参考官网文档。 主题Next修改参考官方文档 依赖 nodejs github个人仓库 git hexo安装12345npm install -g hexo-clihexo init blogcd blognpm installnpm install hexo-deployer-git --save _config.yml配置123456language: zh-CN # 网站使用的语言，取值参考themes下面的languages目录中的配置timezone: Asia/Shanghaideploy: type: git # path和username要一致，且git中repo的命令必须为name.github.io repo: git@github.com:path/username.github.io.git 常用hexo命令 hexo init [folder]新建一个网站，如果未指定folder，则默认在当前位置创建 hexo new [layout] 新建文章，如果未指定layout，则使用_config.yml中的default_layout代替 hexo generate [option]生成静态文件，可以简写为hexo g。option: -d,–deploy 文件生成后立即部署 -w,–watch 监视文件变化 hexo server启动服务器。默认访问路径为 http://localhost:4000。可以简写为`hexo s` hexo deploy部署网站。可以简写为hexo d。可以通过指定-g参数指定部署前先生成静态文件。 hexo clean清除缓存文件(db.json)和已生成的静态文件(public/*) Front-matter 参数 描述 备注 layout 布局 title 文章标题 data 创建时间 updated 更新时间 comments 开启评论 默认值:true tags 标签(不适用于分页) 配置多个时，标签没有顺序和层次 categories 分类(不适用于分页) 配置多个时，分类具有顺序和层次 Next增加站内搜索 安装插件 12npm install hexo-generator-search --savenpm install hexo-generator-searchdb --save 修改hexo配置 在hexo目录下的_config.yml中增加以下内容 12345search: path: search.xml field: post format: html limit: 10000 next主题增加搜索入口 在themes/next/_config.yml文件中打开local_search 1234local_search: enable: true trigger: auto top_n_per_article: 1]]></content>
      <categories>
        <category>framework</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
